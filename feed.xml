<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://xli7654321.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://xli7654321.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-28T11:16:27+00:00</updated><id>https://xli7654321.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">Deep Learning Notes</title><link href="https://xli7654321.github.io/blog/2024/DL/" rel="alternate" type="text/html" title="Deep Learning Notes"/><published>2024-04-15T12:00:00+00:00</published><updated>2024-04-15T12:00:00+00:00</updated><id>https://xli7654321.github.io/blog/2024/DL</id><content type="html" xml:base="https://xli7654321.github.io/blog/2024/DL/"><![CDATA[<style>h1,h2,h3,h4,h5,h6{color:var(--global-theme-color)}table{width:100%;margin:.5rem 0}th,td{padding:.5rem}</style> <h2 id="introduction-to-generative-ai---coursera"><a href="https://www.coursera.org/learn/introduction-to-generative-ai">Introduction to Generative AI - Coursera</a></h2> <p><strong>Generative AI can input only one modality and output multiple modalities.</strong></p> <p>DL can process more complex patterns than traditional ML.</p> <p>\(y = f(x)\) | \(x\) is input data, \(y\) is model output and \(f\) is model.</p> <p>Pre-Training: 1) Large amount of data; 2) Billions of parameters; 3) Unsupervised Learning</p> <p>Transformer Challenges: 1) The model is not trained on enough data; 2) is trained on noisy or dirty data; 3) is not given enough context; 4) is not given enough constraints.</p> <p>Prompt is given to the LLMs as input and it can be used to control the output of the model. (The quality of the input determines the quality of the output)</p> <hr/> <h2 id="hung-yi-lee-2021-spring-ml"><a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">Hung-yi Lee 2021 Spring ML</a></h2> <h3 id="1-introduction">1. Introduction</h3> <blockquote> <p>对一个模型的修改往往基于对问题的理解，也就是 domain knowledge</p> </blockquote> <h4 id="ml-framework-3-steps">ML Framework (3 Steps)</h4> <p><a href="https://www.youtube.com/watch?v=Ye018rCVvOo"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <ol> <li> <p><strong>Function with Unknown</strong>: \(y = b + wx_1\), \(w\) and \(b\) are unknown parameters (weight and bias), \(x_1\) is feature. \(\leftarrow\) <strong>Linear Model</strong></p> </li> <li> <p><strong>Define Loss Function from Training Data</strong>: is a function of parameters \(L(b, w)\), \(L = \frac{1}{N} \sum_{n}^{}e_n\) and is from training data.</p> <blockquote> <p>MAE (Mean Absolute Error): \(e = \vert y - \hat{y} \vert\)</p> </blockquote> <blockquote> <p>MSE (Mean Square Error): \(e = (y - \hat{y})^2\)</p> </blockquote> </li> <li> <p><strong>Optimization</strong>: \(w^*, b^* = \arg \min\limits_{w, b} L\)</p> <blockquote> <p>Gradient Descent: \(w^1 \leftarrow w^0 - \eta\frac{\partial L}{\partial w}\vert_{w = w^0,\ b = b^0}\), \(w^0\) is randomly picked and \(\eta\) is learning rate (a hyperparameter that dictates the speed at which the model adjusts its parameters during training). If gradient is negative (gradient guides the direction), increase \(w\) can decrease loss.</p> </blockquote> </li> </ol> <h4 id="step-into-dl-bulb">Step into DL :bulb:</h4> <p><a href="https://www.youtube.com/watch?v=bHcJCp2Fyxs"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <ol> <li> <p><strong>Function with Unknown</strong></p> <blockquote> <p>sigmoid: \(\frac{1}{1 + e^{-x}}\), \(y = c \ \frac{1}{1 + e^{-(b + wx_1)}} = c \ \text{sigmoid}(b + wx_1)\) 通过改变 \(w\)、\(b\) 和 \(c\)（constant），就可以得到各种不同形状的 sigmoid 函数。\(w\) changes slopes, \(b\) changes shifts and \(c\) changes heights.</p> </blockquote> <p>利用 sigmoid 函数来替代阶跃函数作为非线性函数，可以组合各种不同的 linear model，得到 piecewise linear model，从而可以近似各种不同的 <strong>continuous function (non-Linear Model)</strong>，即</p> \[y = b + \sum\limits_i c_i \ \text{sigmoid}(b_i + w_i x_1)\] <p>如果对于不同的 feature 有不同的权重 \(w\)，那么公式就会变成</p> \[y = b + \sum\limits_i c_i \ \text{sigmoid}(b_i + \sum\limits_j{w_{ij} x_j})\] <p>\(i\): no. of sigmoid, \(j\): no. of features</p> <p>用线代的形式可以表示为（<a href="https://www.youtube.com/watch?v=bHcJCp2Fyxs">Timestamp - 17:23</a>）</p> \[y = b + \boldsymbol{c^T} \sigma(\boldsymbol{b} + \boldsymbol{WX})\] <p>\(c\) 为 transpose 的原因是：矩阵乘法要求前一个矩阵的列数是后一个矩阵的行数。</p> </li> </ol> <hr/> <p>Using \(\boldsymbol{\theta}\) to represent the unknown parameters \(\boldsymbol{W}, \boldsymbol{b}, \boldsymbol{c^T}, b\), so the function with unknown can be written as \(f_{\boldsymbol{\theta}}\).</p> <ol> <li> <p><strong>Define Loss Function from Training Data</strong></p> <p>Loss \(L(\boldsymbol{\theta})\) is a function of parameters \(\boldsymbol{\theta}\)，将训练数据经过 \(f_{\boldsymbol{\theta}}\) 得到的输出与 ground truth 比较计算出距离（例如 cross-entropy），将每个样本的距离加起来就作为 loss function \(L(\boldsymbol{\theta}) = \sum^N_{n=1}e_n\)。</p> </li> <li> <p><strong>Optimization</strong>: 对于 \(\boldsymbol{\theta} = \begin{bmatrix}\theta_1\\\theta_2\\\theta_3\\\vdots\end{bmatrix}\)，要找到 \(\boldsymbol{\theta^*} = \arg \min\limits_{\boldsymbol{\theta}} L\)，最终 \(f_{\boldsymbol{\theta^*}}\) 就是我们想要的那个 function。对于随机选择的初始值 \(\boldsymbol{\theta}^0\)，计算出 gradient \(\boldsymbol{g} = \nabla{L(\boldsymbol{\theta}^0)}\) 后用 gradient descent 就可以更新所有的参数，即 \(\boldsymbol{\theta}^1 \leftarrow \boldsymbol{\theta}^0 - \eta\boldsymbol{g}\)，通常不会有所有的训练数据去一次又一次地更新参数，而是将训练数据划分成多个 batch，<strong>用每一个 batch 去做每一次的 update</strong>（called it iteration），比如第一个 batch 得到一个 loss \(L^1\)，用这个 loss 计算得到的梯度去更新 \(\boldsymbol{\theta}^0\) 得到 \(\boldsymbol{\theta}^1\)，再用第二个 batch 更新得到 \(\boldsymbol{\theta}^2\)，以此类推，把所有 batch 都看过一遍后叫做一个 <span id="epoch"><strong>epoch</strong></span>。</p> <blockquote> <p>Rectified Linear Unit (ReLU): \(c\max(0, b + wx_1)\)</p> </blockquote> <p>如果使用 ReLU 代替 sigmoid，需要两个 ReLU 才可以得到一个 hard sigmoid，则</p> \[y = b + \sum\limits_{2i} c_i \max(0, b_i + \sum\limits_j{w_{ij} x_j})\] <p>这里的 sigmoid 和 ReLU 在 ML 中被称之为 <strong>Activation function</strong></p> <blockquote> <p>Neuron and Neural Network == hidden layer and Deep Learning</p> </blockquote> <blockquote> <p>Overfitting: Better on training data, worse on unseen data.</p> </blockquote> </li> </ol> <h3 id="2-dl">2. DL</h3> <h4 id="backpropagation">Backpropagation</h4> <p><a href="https://www.youtube.com/watch?v=ibJpTrp5mcE"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>神经网络通常有多层且每层有大量的 neuron，因此它会有上百万个参数，用 Backpropagation 就可以有效地计算这些参数的 gradient</p> <ol> <li> <p>Forward Pass: \(z = x_1w_1 + x_2w_2 + b \rightarrow \frac{\partial{z}}{\partial{w}}\)</p> </li> <li> <p>Backward Pass: Function \(C\) determines the distance between \(\hat{y}\) (prediction value) and \(y\) (ground truth). \(\frac{\partial{\hat{y}}}{\partial{z}}\frac{\partial{C}}{\partial{\hat{y}}} \rightarrow \frac{\partial{C}}{\partial{z}}\)</p> </li> <li> <p>Then, we will get the gradient of parameter \(w\) with respect to Function \(C\). \(\frac{\partial{z}}{\partial{w}} \times \frac{\partial{C}}{\partial{z}} \rightarrow \frac{\partial{C}}{\partial{w}}\)</p> </li> </ol> <h4 id="general-guide">General Guide</h4> <p><a href="https://www.youtube.com/watch?v=WeHM2xpYQpw"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Training: \(y = f_{\boldsymbol{\theta}}(\boldsymbol{x}), \ L(\boldsymbol{\theta}), \ \boldsymbol{\theta}^* = \arg \min\limits_{\boldsymbol{\theta}} L\)</p> <p>Testing: \(y = f_{\boldsymbol{\theta}^*}(\boldsymbol{x}')\)</p> <div class="md-img"><img src="/assets/img/DL-img/guide.png" alt="guide" style="zoom:30%;"/></div> <p><strong><span class="my-yellow-text">The loss on the training data is important and must be recorded. Before checking the test results, ensure that the loss on the training data is sufficiently small.</span></strong></p> <ul> <li> <p>Training loss is large</p> <ol> <li> <p>Model Bias: model is too simple</p> <p><strong>Solution:</strong> Redesign the model to make it more flexible (more features, more complex architecture)</p> </li> <li> <p><strong>Optimization Issue</strong> <a href="https://www.youtube.com/watch?v=QW6uINn7uGk"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p><strong>Problem:</strong> <a href="#critical-point">Critical point</a>, <a href="#Adaptive Learning Rate">Learning rate</a>, <a href="#Classification">Loss function</a></p> <p><strong>Solution:</strong> More powerful optimization technology, like Mini-batch, Momentum; AdaGrad, RMSProp, Adam, AdamW; Learning rate scheduling; Choose appropriate loss function</p> <blockquote> <p>Taylor Series Approximation: 能够将任意光滑函数近似为多项式函数，其利用函数在某一点的值及其在该点的所有阶导数来构建一个多项式，这个多项式在该点附近与原函数的值非常接近。</p> <div class="math-scroller"> $$ f(x) = f(a) + \frac{f'(a)}{1!}(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + \cdots \ or \ f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n $$ </div> </blockquote> <blockquote> <p>Hessian Matrix: 对于一个高维函数 \(f(x_1, x_2, \ldots, x_n)\)，矩阵中将包含所有变量对之间的二阶偏导数，即对于 \(i\) 个 row 和 \(j\) 个 column 的 \(x_i\) 和 \(x_j\) 来说：</p> \[H = \begin{bmatrix} \frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\ \frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_n^2} \end{bmatrix} \ or \ H_{ij} = \frac{\partial^2f}{\partial{x_i}\partial{x_j}}\] <p>P.S. 相对应的 Gradient 为 \(\boldsymbol{g} = \begin{bmatrix} \frac{\partial{f}}{\partial{x_1}} \\ \frac{\partial{f}}{\partial{x_2}} \\ \vdots \\ \frac{\partial{f}}{\partial{x_n}} \end{bmatrix}\)</p> </blockquote> <blockquote> <p>Saddle Point: 对于多变量函数的函数图像，在 Saddle Point 上，函数在某些方向上局部最小，而在其他方向上局部最大。</p> </blockquote> <div class="md-img"><img src="/assets/img/DL-img/optimization1.png" alt="optimization1" style="zoom:30%;"/></div> <p><span id="critical-point">Gradient is close to zero (<strong>training loss did not decrease or is not small enough</strong>) caused by meeting <strong>critical point</strong> (local minima or saddle point)</span></p> </li> </ol> <hr/> \[L(\boldsymbol{\theta}) \approx L(\boldsymbol{\theta'}) + (\boldsymbol{\theta} - \boldsymbol{\theta'})^T\boldsymbol{g} + \frac{1}{2} (\boldsymbol{\theta} - \boldsymbol{\theta'})^T H (\boldsymbol{\theta} - \boldsymbol{\theta'})\] <p>这里的零阶项是损失函数在 \(\boldsymbol{\theta'}\) 点的值，一阶项反映的是损失函数在 \(\boldsymbol{\theta'}\) 点的线性变化（Gradient/一阶微分），二阶项反映的是损失函数的局部曲率（Hessian/二阶微分）。在 critical point 上，Gradient 项为零，所以要根据 Hessian matrix 来判断。如果二阶项大于零，则在 \(\boldsymbol{\theta'}\) 附近有 \(L(\boldsymbol{\theta}) &gt; L(\boldsymbol{\theta'})\)，即说明 \(\boldsymbol{\theta'}\) 点是一个 local minima，计算上只需要算出 Hessian matrix 的 eigenvalue，应有所有的 eigenvalue 都是正的。同理，如果所有的 eigenvalue 都是负的，则为 local maxima。如果 eigenvalue 有正有负，则为 saddle point。</p> <blockquote> <p>L2 Norm (Euclidean Norm): \(\Vert\boldsymbol{x}\Vert_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}\)</p> </blockquote> <blockquote> <p>L1 Norm (Manhattan Norm): \(\Vert\boldsymbol{x}\Vert_1 = \vert x_1 \vert + \vert x_2 \vert + \cdots + \vert x_n \vert\)</p> </blockquote> <blockquote> <p>L-infinity Norm: \(\Vert \boldsymbol{x} \Vert_\infty = \max(\vert x_1 \vert, \vert x_2 \vert, \ldots, \vert x_n \vert)\)，常被用来限制向量的最大变化量。在对抗性机器学习中，常用于衡量对抗性扰动的强度，确保这些扰动在每个维度上的最大改变不会超过某个预设的阈值。</p> </blockquote> <p><em>计算量大，不会这么做！</em>如果遇到 saddle point，只需要找出负的 eigenvalue（\(\lambda &lt; 0\)），再找到相对应 \(H\) 的 eigenvector \(\boldsymbol{u}\)，然后得到新的点 \(\boldsymbol{\theta} = \boldsymbol{\theta'} + \boldsymbol{u}\)，这个点的 loss \(L\) 就会更小（\(\frac{1}{2} (\boldsymbol{\theta} - \boldsymbol{\theta'})^T H (\boldsymbol{\theta} - \boldsymbol{\theta'}) = \boldsymbol{u}^TH\boldsymbol{u} = \boldsymbol{u}^T(\lambda\boldsymbol{u}) = \lambda\Vert\boldsymbol{u}\Vert_2^2 &lt; 0 \rightarrow L(\boldsymbol{\theta}) &lt; L(\boldsymbol{\theta'})\)）。</p> <p>When you have lots of parameters, perhaps local minima is rare？ 在低维度看起来是 local minima，但是在更高维度上更有可能是 saddle point，即 local minima 需要满足在各个维度上都是最小（很难做到）。所以当 Training loss 卡在某一个位置时，往往是遇到了 saddle point，而不是 local minima。</p> <p><strong><a href="#Mini-batch">Mini-batch</a> and <a href="#Momentum">Momentum</a> can help escape critical points.</strong></p> </li> </ul> <hr/> <h4 id="mini-batch">Mini-batch</h4> <p><a href="#epoch">epoch</a></p> <p>将 Training data 划分 batch 的时候需要做 shuffle，一个常见的做法是在每个 epoch 开始之前进行划分，使得每一个 epoch 的 batch 都不一样。</p> <p>在使用 GPU 并行运算的条件下，smaller batch requires longer time for one epoch (seeing all data once)</p> <div class="md-img"><img src="/assets/img/DL-img/batch1.png" alt="batch1" style="zoom: 32%;"/></div> <p>But smaller batch has better performance on training data and testing data (below is one of the explanations)</p> <div class="md-img"><img src="/assets/img/DL-img/batch2.png" alt="batch2" style="zoom: 35%;"/></div> <div class="md-img"><img src="/assets/img/DL-img/batch3.png" alt="batch3" style="zoom: 30%;"/></div> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">Small Batch</th> <th style="text-align: center">Large Batch</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Time for one epoch</td> <td style="text-align: center">Slower</td> <td style="text-align: center">Faster</td> </tr> <tr> <td style="text-align: center">Gradient</td> <td style="text-align: center">Noisy</td> <td style="text-align: center">Stable</td> </tr> <tr> <td style="text-align: center">Optimization</td> <td style="text-align: center">Better</td> <td style="text-align: center">Worse</td> </tr> <tr> <td style="text-align: center">Generalization</td> <td style="text-align: center">Better</td> <td style="text-align: center">Worse</td> </tr> </tbody> </table> <p>总的来说，就是要调整 batch size 这个超参数来做取舍以达到想要的效果（当然也有可能做到鱼与熊掌兼得）。</p> <h4 id="momentum">Momentum</h4> <p><a href="https://www.youtube.com/watch?v=zzbr1h9sF54">Timestamp - 24:45</a></p> <p>Optimization is not just based on gradient, but previous movement (movement is movement of the last step minus gradient at present).</p> <p>Movement \(\boldsymbol{m^i}\) is the weighted sum of all the previous gradient: \(\boldsymbol{m^0} = 0, \ \boldsymbol{m^1} = \lambda\boldsymbol{m^0} -\eta\boldsymbol{g^0} = -\eta\boldsymbol{g^0}, \ \boldsymbol{m^2} = \lambda\boldsymbol{m^1} - \eta\boldsymbol{g^1} = -\lambda\eta\boldsymbol{g^0} - \eta\boldsymbol{g^1}\) (\(\lambda\) is also a hyperparameter) and parameter \(\boldsymbol{\theta}\) updated by</p> \[\begin{gather*} \boldsymbol{m^i} = \lambda\boldsymbol{m^{i-1}} - \eta\boldsymbol{g^{i-1}} \\ \boldsymbol{\theta^i} = \boldsymbol{\theta^{i-1}} + \boldsymbol{m^i} \end{gather*}\] <p>因此，参数的更新方向不是完全按照当前 iteration 的 gradient 的方向，而是按照过去所有 gradient 的方向的总和作为更新的方向。</p> <p>P.S. 这里的 momentum \(\boldsymbol{m}\) 写作是 gradient \(\boldsymbol{g}\) 的反方向，但是像 Adam 论文中写的是 \(\boldsymbol{m}\) 与 \(\boldsymbol{g}\) 同方向，所以更新参数 \(\boldsymbol{\theta}\) 时要减去 \(\boldsymbol{m}\)。</p> <h4 id="adaptive-learning-rate">Adaptive Learning Rate</h4> <p><a href="https://www.youtube.com/watch?v=HYUXEeh3kwY"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <blockquote> <p>Convex error surface (Error Surface describes the relation between loss and parameters) is an ideal situation that has a clear global minima.</p> </blockquote> <p>训练停滞不一定是由于 critical point (small gradient)，也可能是 learning rate 的原因。</p> <p>Different parameters needs different learning rate, <strong>if gradient is small, learning rate needs to be larger, vice versa.</strong></p> <ul> <li> <p><strong>AdaGrad:</strong> Add a <strong>parameter dependent</strong> parameter \(\sigma\) to adjust learning rate in gradient descent formulation. For \(i\)-th parameter \(\boldsymbol{\theta_i^t}\), if gradient is small in \(i\)-th iteration, then \(\sigma_i^t\) is also small, so learning rate will be larger. Hence, learning rate can be adjusted automatically.</p> \[\begin{gather*} \boldsymbol{\theta_i^{t + 1}} \leftarrow \boldsymbol{\theta_i^t} - \frac{\eta}{\sigma_i^t}\boldsymbol{g_i^t} \\ \sigma_i^t = \sqrt{\frac{1}{t + 1}\sum\limits^t_{i=0}(\boldsymbol{g_i^t})^2} \end{gather*}\] </li> </ul> <blockquote> <p>Root Mean Square (RMS): \(\text{RMS} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} x_i^2}\)</p> </blockquote> <ul> <li> <p><strong>RMSProp:</strong> AdaGrad 默认每一个 gradient 都有同等的重要性（且会记住过去所有的梯度），在此基础上 RMSProp 做出改进在参数 \(\sigma_i^t\) 中引入另一个超参数 \(\alpha\)，从而可以<strong>调整当前 iteration 的 gradient 的重要性</strong>（选择性地遗忘过去的梯度）。<sup id="fnref:book" role="doc-noteref"><a href="#fn:book" class="footnote" rel="footnote">1</a></sup></p> \[\sigma_i^t = \sqrt{\alpha(\sigma_i^{t-1})^2 + (1 - \alpha)(\boldsymbol{g_i^t})^2}, \ 0 &lt; \alpha &lt; 1\] </li> <li> <p><strong>Adam:</strong> RMSProp + Momentum, <strong>Momentum decides the direction</strong> of update and <strong>RMSProp decides the step size</strong> of update. And Adam also needs <strong>warm up</strong>.</p> <p><a href="https://arxiv.org/abs/1412.6980">Adam Paper</a> <strong>建议使用 PyTorch 预设的参数即可</strong></p> </li> <li> <p><strong>Learning Rate Scheduling:</strong> 令学习率随着时间变化，即 \(\eta \rightarrow \eta^t\)</p> <ul> <li> <p><strong>Learning Rate Decay</strong></p> <div class="md-img"><img src="/assets/img/DL-img/lr1.png" alt="lr1" style="zoom: 30%;"/><div> </div></div> </li> <li> <p><strong>Warm Up</strong></p> <div class="md-img"><img src="/assets/img/DL-img/lr2.png" alt="lr2" style="zoom: 30%;"/></div> <p>Warm Up is used in <a href="https://arxiv.org/abs/1512.03385">Residual Network</a>, <a href="https://arxiv.org/abs/1706.03762">Transformer</a>, <a href="https://arxiv.org/abs/1810.04805">BERT</a>, 比较玄学，更多理解见 <a href="https://arxiv.org/abs/1908.03265">RAdam</a></p> <blockquote> <p>The shape of the curve is like human life, up and down.</p> </blockquote> </li> </ul> </li> </ul> <hr/> <p><strong><em>Determine it’s caused by model bias or optimization:</em></strong></p> <ol> <li>Gaining the insights from comparison.</li> <li>Start from shallower networks (or linear model, SVM, Tree model, etc.), which are easier to optimize.</li> <li>If deeper networks do not obtain smaller loss on training data, then there is optimization issue.</li> </ol> <ul> <li> <p>Training loss is small, testing loss is large</p> <ol> <li> <p><strong>Overfitting</strong></p> <p><strong>Solution:</strong></p> <ul> <li>Searching more training data</li> <li>Data augmentation (<strong>Creating new data based on the understanding of the problem and the characteristics of data, but need to be reasonable in the real world</strong> (like flipping an image horizontally instead of vertically, because the former does not affect the recognition of objects within the image))</li> <li>Constraining model <ul> <li>Less parameters, sharing parameters</li> <li>Less features</li> <li>Early stopping</li> <li>Regularization</li> <li>Dropout</li> </ul> </li> </ul> </li> <li> <p>Mismatch</p> <p>Training data and test data have different distributions. Be aware of how data is generated.</p> </li> </ol> </li> </ul> <p><strong>Trade-off：</strong>将 Training set 分为 Training set 和 Validation set，用前者拟合得到模型，根据模型在后者上的结果来选择模型，最后在 Test set 上评估。（尽量）不要用 Test set 上的结果去调整模型。最好的就是直接选择 Validation set 上 loss 最小的模型。P.S. 这里的 Validation set 要具有足够的代表性（保证分布一致）。如果担心单一验证集会过于乐观或代表性不足，也可以用 N-fold Cross-Validation，但这里最后就要用全部的 Training set 来拟合模型。</p> <h4 id="classification">Classification</h4> <p><a href="https://www.youtube.com/watch?v=O2VkP8dJ5FE"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>为保证分类的各类别之间距离相等（无特定关系），需要用 <strong>one-hot</strong> vector 来表示类别。</p> <blockquote> \[\text{softmax} = \frac{\exp(y_i)}{\sum_j\exp(y_j)}\] </blockquote> <p>通常在分类的最后要加一层 softmax，目的是将输出归一化（各个输出都介于 0 到 1 之间，且它们的和为1），然后再计算输出与 label（one-hot 形式）之间的距离（用 <strong>Cross-entropy</strong> 来计算 loss）。特别地，当二分类时，用 softmax 和 sigmoid 的效果是一样的。</p> <blockquote> <p><strong>Posterior Probability</strong>（后验概率）：是指在已知某一事件发生的条件下，另一事件发生的概率，它是 Bayes’ Theorem（贝叶斯定理）的核心概念，通常用来<strong>在给定观测数据后更新我们对一个假设的可能性的评估</strong>，从而为下一步的决策提供依据。此外，后验概率的分布还可以作为不确定性的度量，概率分布如果集中某一类别上则表示模型非常确信其预测，而概率分布如果较为平坦则表示模型对其预测相对不确定。贝叶斯定理的公式：\(P(B_i \parallel A) = \frac{P(B_i)P(A \parallel B_i)}{P(A)} = \frac{P(B_i)P(A \parallel B_i)}{\sum^n_{i=1}P(B_i)P(A \parallel B_i)}\)。其中，\(P(B_i)\) 是 <strong>Prior Probability</strong> （先验概率），即在没有观测到数据之前认为假设 \(B_i\) 为真的概率；\(P(B_i \parallel A)\) 是后验概率，即观测到数据 \(A\) 出现后认为假设 \(B_i\) 为真的概率；\(P(A \parallel B_i)\) 是 <strong>Likelihood</strong>（似然），即在假设 \(B_i\) 为真的条件下，观测到数据 \(A\) 的概率；\(P(A)\) 是数据 \(A\) 出现的总概率，保证概率的归一化。</p> <p>Likelihood 是从果到因考虑问题（给定结果，求导致这个结果的原因的可能性）。</p> </blockquote> <p>神经网络的原始输出经过 softmax 函数处理后，可以被转换为概率分布，这里每个类别的输出概率可以被解释为在给定输入数据的条件下，该类别为正确类别的<strong>后验概率</strong>。为什么是后验概率？因为这些概率反映了<strong>模型基于当前观测到的数据对每个类别正确性的评估</strong>。</p> <blockquote> <p>Cross-entropy: \(e = - \sum_i\hat{y_i} \ln y_i\), minimizing cross-entropy is equivalent to maximizing likelihood.</p> </blockquote> <p><strong>For classification tasks, cross-entropy is better than MSE (easy to train).</strong> In PyTorch, <code class="language-plaintext highlighter-rouge">torch.nn.CrossEntropyLoss</code> 自动包含了 softmax 操作，即在使用时会先对模型的输出应用 softmax 函数，再计算交叉熵损失，因此不需要在模型的最后一层手动添加 softmax 激活函数，模型的最后一层输出应直接是未经 softmax 处理的 <strong>logits</strong>。</p> <p>因此，改变 <strong>loss function</strong> 也可以优化 optimization（change the landscape of error surface）。</p> <h4 id="optimizers-for-dl">Optimizers for DL</h4> <p><a href="https://www.youtube.com/watch?v=4pUmZ8hXlHM"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video1"/></a>, <a href="https://www.youtube.com/watch?v=e03YKGHXnL8"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video2"/></a></p> <p><strong>Optimizers:</strong> SGD, <strong><span class="my-red-text">SGD with momentum (SGDM)</span></strong>, AdaGrad, RMSProp, <strong><span class="my-red-text">Adam</span></strong>, AdamW (Hugging Face BERT)</p> <hr/> <p><strong>Adam v.s. SGDM</strong></p> <p><strong>Adam</strong>: Fast Training, Large Generalization Gap, Unstable, Possibly Non-convergence, Suitable for NLP, GAN, RL</p> <p><strong>SGDM</strong>: Slow Training, Small Generalization Gap, Stable, Better Convergence, Suitable for CV</p> <p><strong>Something may help optimization:</strong></p> <ul> <li> <p>Increase Randomness (More Exploration)</p> <p>Shuffle, Dropout, Gradient Noise</p> </li> <li> <p>Start from easy</p> <p>Warm Up, Curriculum Learning, Fine-tuning</p> </li> <li> <p>Normalization, Regularization</p> </li> </ul> <p><strong>AdamW</strong>：在 Adam 中，权重衰减通常是通过在损失函数中加入一个正则项（L2 惩罚）来实现的。在参数更新公式中，这种方式导致权重衰减会受到学习率的影响。而 AdamW 将权重衰减从梯度更新过程中分离出来，允许权重衰减独立于自适应学习率，使其仅依赖于设定的衰减系数，这种方法更接近传统的权重衰减，从而可以提高训练过程的稳定性，并且在一些任务中，如训练深层网络或复杂的模型时，表现得更好。</p> <h4 id="tips-for-dl">Tips for DL</h4> <p>DL 其实不容易 Overfitting，像 KNN、Decision Tree 这样的 ML 模型很容易就会在训练集上达到 100% 的 accuracy，这才叫容易 Overfitting。DL 第一个遇到问题最可能是在训练集上根本 train 不起来，accuracy 很低。在训练集上结果好后，再在验证集上评估如果效果差，如果用某些技术解决了 Overfitting 但是发现训练集又变坏了，那就需要再调整让训练集变好，如此反反复复直到在训练集和验证集上表现都足够好。</p> <p><strong><span class="my-large-text">Activation Function</span></strong></p> <p><strong>ReLU</strong>：\(f(x) = \max(0, x)\) 目前比较常用，其优点为计算速度快且可以解决 vanishing gradient problem。</p> <p><strong>LeakyReLU</strong>：\(f(x) = \begin{cases} x &amp; \text{if } x &gt; 0 \\ \alpha x &amp; \text{if } x \le 0 \end{cases}\)，\(\alpha\) 是一个很小的正数（例如 0.01），有助于避免神经元死亡问题，这使得在训练过程中保持网络的梯度流动。</p> <p><strong><span class="my-large-text">Early Stopping</span></strong></p> <p>如果训练集的 loss 还在下降，但验证集的 loss 反而开始回升，此时应该提前停止训练。</p> <p><strong><span class="my-large-text">Regularization</span></strong></p> <p>Modify the loss function</p> <p><strong>L2-regularization</strong>：\(L_{l_2}(\boldsymbol{\theta}) = L(\boldsymbol{\theta}) + \frac{\lambda}{2} \Vert \boldsymbol{\theta} \Vert^2_2\)，L2 正则化通过在损失函数中添加一个正则化项来实现，这个正则化项由于是平方项，所以对于较大的参数值会更敏感，从而增大对较大参数值的惩罚（即优化算法会增大参数减小的幅度，以最小化总损失）。因此，L2 正则化能够防止模型过于复杂，有利于防止过拟合。</p> <p>更新的过程就变为：\(\theta \leftarrow \theta - \eta \frac{\partial L_{l2}}{\partial \theta} = \theta - \eta (\frac{\partial L}{\partial \theta} + \lambda \theta) = (1 - \eta \lambda)\theta - \eta \frac{\partial L}{\partial \theta}\)，\((1 - \eta \lambda)\theta\) 这一项由于 \(\theta\) 会乘上一个很接近于 1 但小于 1 的值，所以会越来越小趋近于 0，因此也被称为 Weight Decay。</p> <p><strong><span class="my-large-text">Dropout</span></strong></p> <p><strong>适用于训练集表现好但验证集表现不好的情况下。</strong></p> <p>在用每一个 mini-batch 做每一次 update 之前都要重新采样要 dropout 的 neuron，因此每一次 update 用来训练的 network structure 是不同的。Dropout 会让训练的性能变差，但是目标是提升测试（validation）的性能。在测试（validation）时则保留全部的 neuron，需要注意的是，<strong>如果训练时 dropout 的比例是 \(p\%\)，那测试时的所有权重都要乘上 \((1-p)\%\)</strong>。</p> <p><em>Dropout is a kind of ensemble.</em></p> <h3 id="3-cnn">3. CNN</h3> <p><a href="https://www.youtube.com/watch?v=OP5HcXJg2Aw"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <blockquote> <p>Image \(\rightarrow\) 3-D tensor (width, height and channel), every pixel of an image is composed of 3 colors (RGB), so 3 channels represent RGB.</p> </blockquote> <blockquote> <p>Fully Connected Layer: 网络中的每个神经元都与前一层的每一个神经元相连接，在全连接层中，输入的所有特征都会被考虑在内，输入的每个特征都会对每个输出产生影响。全连接层通常用于网络的最后几层，将前面层输出的特征进行汇总和非线性组合，以执行分类、回归或其他任务（数学运算就是矩阵乘法加上偏置项，通常后接一个非线性激活函数）。</p> </blockquote> <p><strong><em>Observation 1</em></strong></p> <p>只需要对 neuron 输入图像的某一小部分来判断是否具有某些重要的具有代表性的 pattern 即可判断图像中的物体，而不需要每个 neuron 都去看完整的图像。</p> <p><strong><em><span class="my-red-text">Same patterns are much smaller than the whole.</span></em></strong></p> <p><strong><em>Simplification 1</em></strong></p> <p>Typical <strong>Receptive Field</strong> Setting for Simplifying Fully Connected Network</p> <ul> <li>Each receptive field has a set of neurons (e.g., 64, 128).</li> <li>Stride (e.g., 1, 2) controls the movement step size of the receptive field and it’s best to have overlap between receptive fields.</li> <li>Padding fills the edges of the image with zeros or other values to control the size of the whole image.</li> </ul> <p><strong><em>Observation 2</em></strong></p> <p>同样的 pattern 可能会出现在不同图像的不同区域，识别同样 pattern 的 neuron 做的事情其实是一样的，只是它们负责的 Receptive Field 有所不同。</p> <p><strong><em><span class="my-red-text">The same patterns appear in different regions.</span></em></strong></p> <p><strong><em>Simplification 2</em></strong></p> <p><strong>Parameter Sharing</strong> for Different Receptive Fields. Typical setting is that each receptive field has the neurons with the same set of parameters (A set of parameters is called a filter).</p> <p><strong><em>Statement 1</em></strong></p> <p><strong><span class="my-yellow-text">Receptive Field + Parameter Sharing = Convolutional Layer</span></strong> (Lower complexity than Fully Connected Layer, and lower risk of overfitting, but larger model bias)</p> <hr/> <p><strong><em>Statement 2</em></strong></p> \[\text{Image} \xrightarrow[]{\text{Convolutional Layer}} \text{Feature Map}\] <p>If convolutional layer has 64 filters, feature map can be seen as <strong>“image” with 64 channels</strong> (image from 3 channels to 64 channels, i.e., convolution). 每一个卷积层中的 filter 的 channel 数需要等于输入的 image/”image“ 的 channel 数。</p> <p><strong>Statement 1 and 2 are Same story:</strong> The values of filters in statement 2 are the same as parameters (weight and bias) of neurons in statement 1, so when a filter sweeps across the image (i.e., convolution), it’s equal to sharing parameters.</p> <hr/> <p><strong><em>Observation 3</em></strong></p> <p>Subsampling the pixels will not change the object \(\longrightarrow\) <strong>Pooling</strong></p> <p>Pooling decreases the width and height of the image.</p> <p>Pooling 在 Convolution 之后使用，并且两者通常交替使用，比如做一次/几次 Convolution 做一次 Pooling。Pooling 主要目的是降低计算量，但是如果识别/侦测的是非常微细的东西，Pooling 所做的 Subsample 可能会对性能有所伤害，<strong>要考虑具体应用场景来决定是否要对 network 做 Pooling。</strong></p> <p>要得到最终的结果，需要对 Pooling 的输出做 Flatten（把矩阵拉直，变成一个向量），再输入到 FC Layer 中，最后再经过 softmax。</p> <hr/> <p><strong>Convolutional layer is specifically designed for images, if it’s used for other tasks, need to consider whether these tasks have characteristics similar to images.</strong></p> <p>But CNN is not invariant to scaling and rotation, so we need <strong>data augmentation</strong>.</p> <h3 id="4-self-attention">4. Self-attention</h3> <p><a href="https://www.youtube.com/watch?v=hYdO9CscNes"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video1"/></a>, <a href="https://www.youtube.com/watch?v=gmsMY5kc-zw"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video2"/></a></p> <p><strong>Self-attention is to consider the information of the whole sequence</strong></p> <p><strong><span class="my-yellow-text">Vector Set as Input and What is the Output</span></strong></p> <ul> <li>Each vector has an output label</li> <li>The whole sequence has an output label (e.g., Input molecular graph and output molecular property)</li> <li>Model decides the number of output labels itself (e.g., <a href="#Seq2seq">Seq2seq</a>)</li> </ul> <hr/> <blockquote> <p>Dot Product: \(\mathbf{A} \cdot \mathbf{B} = a_1b_1 + a_2b_2 + \ldots + a_nb_n = \sum_{i=1}^{n} a_i b_i\)</p> </blockquote> <p>Input of Self-attention can be either input of the whole network or output of a hidden layer</p> <p>输入向量两两之间相互的关联程度/相似性用 \(\alpha\) 来表示，可以通过计算两个向量的点积（点积可以衡量两个向量在各个维度上的值的匹配程度）来得到，点积结果大即关联程度高。</p> \[\boldsymbol{q^1} = \boldsymbol{a^1}W^q, \ \boldsymbol{k^2} = \boldsymbol{a^2}W^k \longrightarrow \alpha_{1,2} = \boldsymbol{q^1} \boldsymbol{\cdot} \boldsymbol{k^2}\] <p>如果有四个输入向量 \(\boldsymbol{a^i}, \ i=1,2,3,4\)，以第一个向量 \(\boldsymbol{a^1}\) 为例，会计算出 \(\alpha_{1,2}, \ \alpha_{1,3}, \ \alpha_{1,4}\) 以及通常还会有自身与自身的关联程度 \(\alpha_{1,1}\)，然后通过 softmax（也可为其他的激活函数） 得到 \(\alpha'\)。然后对每一个输入向量乘上一个 \(W^v\)，再根据 attention scores 来提取信息得到 \(\boldsymbol{b^1}\)。P.S. \(\boldsymbol{b^i}, \ i=1,2,3,4\) 是同时计算出来的，而不是依次。</p> \[\begin{gather*} \boldsymbol{v^i} = \boldsymbol{a^i}W^v, \ i=1,2,3,4 \\ \boldsymbol{b^j} = \sum\limits_i\alpha'_{j,i}\boldsymbol{v^i}, \ j=1,2,3,4 \end{gather*}\] <p>值得注意的是，这其中只有 \(W^q, W^k, W^v\) 是需要从训练数据中学习的。</p> <p>P.S. \(\boldsymbol{q}\) is query, \(\boldsymbol{k}\) is key, \(\boldsymbol{v}\) is value, and \(\alpha\) is attention score.</p> <h4 id="multi-head-self-attention">Multi-head Self-attention</h4> <p>以 2 heads 和 2 input \(\boldsymbol{a^i}, \boldsymbol{a^j}\) 为例，原本 \(\boldsymbol{a^i}\) 所对应的 \(\boldsymbol{q^i}\) 变成 \(\boldsymbol{q^{i,1}}, \boldsymbol{q^{i,2}}\)，即 \(\boldsymbol{q^{i,1}} = W^{q,1}\boldsymbol{q^i}, \ \boldsymbol{q^{i,2}} = W^{q,2}\boldsymbol{q^i}\)，然后在计算输出的时候每一 head 会分开计算。head 1的计算公式为 \(\boldsymbol{b^{i,1}} = \text{softmax}(\boldsymbol{q^{i,1}} \boldsymbol{\cdot} \boldsymbol{k^{i,1}})\boldsymbol{v^{i,1}} + \text{softmax}(\boldsymbol{q^{i,1}} \boldsymbol{\cdot} \boldsymbol{k^{j,1}})\boldsymbol{v^{j,1}}\)。得到每一 head 的输出后，将这些输出 <strong>concatenate \([;]\)</strong>，然后通过另一个线性变化 \(W^O\) 整合不同 head 的信息来得到最终的输出 \(\boldsymbol{b^i} = W^O [\boldsymbol{b^{i,1}}; \boldsymbol{b^{i,2}}]\)。</p> <h4 id="positional-encoding">Positional Encoding</h4> <p>如果输入的 sequence 的每个元素的位置信息很重要，可以给输入 \(\boldsymbol{a^i}\) 添加一个 unique positional vector \(\boldsymbol{e^i}\)，它可以是 hand-crafted 的，也可以是 learned from data。<a href="https://dl.acm.org/doi/pdf/10.5555/3524938.3525525">Paper</a></p> <h4 id="self-attention-for-a-long-sequence">Self-attention for a long sequence</h4> <p>If sequence is very long, there need large momery to storage the attention matrix.</p> <p><strong>Truncated Self-attention</strong></p> <p>对于 sequence 中的某个/些元素只需要看一定范围内的 attention 即可，而不是看整个 sequence。</p> <hr/> <h4 id="self-attention-vs-cnn">Self-attention v.s. CNN</h4> <ul> <li>CNN: Self-attention that can only attends in a receptive field (CNN is simplified self-attention)</li> <li>Self-attention: CNN with learnable receptive field (Self-attention is the complex version of CNN)</li> </ul> <p><strong>CNN is a subset of Self-attention. But more flexible model needs more training data to perform better.</strong></p> <h4 id="self-attention-vs-rnn">Self-attention v.s. RNN</h4> <p><a href="https://www.youtube.com/watch?v=gmsMY5kc-zw">Timestamp - 35:12</a> Self-attention is parallel.</p> <h4 id="self-attention-for-graph">Self-attention for Graph</h4> <p>考虑到 edge 的存在，可以不再需要 model 自己学习 node 之间的关联性，只计算有 edge 相连的 node 之间的 attention 即可。相当于 graph 其实就已经是建立在 domain knowledge 之上的。</p> <hr/> <p>Self-attention 的<strong>缺点</strong>是计算量比较大。</p> <h3 id="5-transformer-fire">5. Transformer :fire:</h3> <h4 id="batch-normalization">Batch Normalization</h4> <p><a href="https://www.youtube.com/watch?v=t3u3WshJQV8"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <ul> <li> <p><strong><em>Batch Normalization - Training</em></strong></p> <p>Batch Normalization can do optimization by <strong>changing the landscape of error surface</strong> (also the loss function part mentioned above)</p> <p>如果 feature 的不同 dimension 的 scale 差距很大，就会导致 error surface 在不同方向上的斜率非常不同。如果可以让不同的 dimension 有同样的数值范围，可能就会得到比较好的 error surface，让 training 变得更容易/<strong><span class="my-yellow-text">更快</span></strong></p> <blockquote> <p>Feature Normalization: For features \(\boldsymbol{x^1}, \boldsymbol{x^2}, \boldsymbol{x^3}, \cdots, \boldsymbol{x^r}, \cdots, \boldsymbol{x^R}\), and for each dimension \(i\), the mean is \(\mu_i\) and the standard deviation is \(\sigma_i\). So the means of all dims are 0, and the stds are 1, \(\tilde{\boldsymbol{x}}\boldsymbol{^r_i} \leftarrow \frac{\boldsymbol{x^r_i} - \mu_i}{\sigma_i}\). Feature Normalization can make gradient descent converge faster.</p> </blockquote> <blockquote> <p>Converge（收敛）：某个过程随着时间的推移逐渐稳定到某个固定值或状态。</p> </blockquote> <p>当对输入 \(\tilde{\boldsymbol{x}}^\boldsymbol{1}\) 做 Feature Normalization 后通过 \(W^1\) 得到的 \(\boldsymbol{z^1}\) 同样也需要做 Feature Normalization 来保证不同的 dims 有同样的 range，然后再通过激活函数得到这一层的输出 \(\boldsymbol{a^1}\)。这里的 Feature Normalization 通常是<strong>在激活函数之前做</strong>，也就是对 \(\boldsymbol{z^i}\) 做，即 \(\tilde{\boldsymbol{z}}^\boldsymbol{i} \leftarrow \frac{\boldsymbol{z^i} - \boldsymbol{\mu}}{\boldsymbol{\sigma}}\)（由于是向量，相减相除都是 element-wise 的）。</p> <blockquote> <p>\(\leftarrow\) 代表赋值（assignment）</p> </blockquote> <p>由于在训练时通常考虑的是一个 batch，而不是整个 training set，所以也称作 <strong>Batch Normalization</strong>。</p> <p>由 \(\boldsymbol{z^i}\) 得到的 \(\tilde{\boldsymbol{z}}^\boldsymbol{i}\) 的 mean 一定是 0，这会对 network 产生一些限制，可能会有未知的负面影响，所以再加回参数 \(\boldsymbol{\gamma}, \boldsymbol{\beta}\) 来让 network 自己学习调整输出的分布，即 \(\hat{\boldsymbol{z}}^{\boldsymbol{i}} \leftarrow \boldsymbol{\gamma}\odot\tilde{\boldsymbol{z}}^\boldsymbol{i} + \boldsymbol{\beta}\)。通常 \(\boldsymbol{\gamma}, \boldsymbol{\beta}\) 的初始值分别为 ones vector 和 zeros vector。</p> </li> </ul> <hr/> <ul> <li> <p><strong><em>Batch Normalization - Testing</em></strong></p> <p>在测试时，由于 Batch Normalization 需要一个 batch 的数据来计算 \(\boldsymbol{\mu}\) 和 \(\boldsymbol{\sigma}\)，但是当用户输入的时候，不可能每次都是恰好一个 batch size 的数据，这时在 PyTorch 中，采用的策略是在训练时每一个 batch 的 \(\boldsymbol{\mu}\) 和 \(\boldsymbol{\sigma}\) 都会用来算 moving average（假如有 t 个 batch，\(\bar{\boldsymbol{\mu}} \leftarrow p\bar{\boldsymbol{\mu}} + (1-p)\boldsymbol{\mu^t}\)，\(p\) 是超参数，默认为 0.1），然后用 \(\bar{\boldsymbol{\mu}}\) 和 \(\bar{\boldsymbol{\sigma}}\) 取代 \(\boldsymbol{\mu}\) 和 \(\boldsymbol{\sigma}\)。</p> </li> </ul> <h4 id="seq2seq">Seq2seq</h4> <p>Input a sequence, output a sequence. The output length is determined by model (e.g., speech recognition, machine translation, speech translation, <strong>Question Answering</strong></p> <p><strong>Question Answering (QA)</strong> can be done by <strong>seq2seq</strong>.</p> \[\begin{gather*} {\large \textbf{Seq2seq Architecture}} \\ \text{Sequence} \longrightarrow \text{Encoder} \longrightarrow \text{Decoder} \longrightarrow \text{Sequence} \end{gather*}\] <p><strong><span class="my-large-text">Seq2seq’s Encoder</span></strong></p> <p>Input vectors, output vectors, i.e., \(\boldsymbol{x^1}, \boldsymbol{x^2}, \cdots, \boldsymbol{x^k} \xrightarrow[]{\text{Encoder}} \boldsymbol{h^1}, \boldsymbol{h^2}, \cdots, \boldsymbol{h^k}\)</p> <p><strong><span class="my-large-text">Seq2seq’s Decoder</span></strong></p> <p>Autoregressive and Non-autoregressive</p> <hr/> <blockquote> <p>内部协变量偏移（Internal Covariate Shift）：训练过程中网络各层的输入分布会随着上一层参数的更新而不断变化，使得网络各层需要不断适应新的输入分布，从而可能导致训练过程缓慢，需要更小的学习率和更细致的参数初始化策略。减少 Internal Covariate Shift 可以加快训练过程，使得模型更快收敛，同时也可以提高模型的训练稳定性，降低梯度爆炸或梯度消失的风险。</p> </blockquote> <blockquote> <p>Layer Normalization: 独立地对每个样本的所有特征进行归一化，即对 \(\begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_k \end{bmatrix}\) 求得 mean \(\mu\) 和 std \(\sigma\)，然后通过 \(x_i' = \frac{x_i - \mu}{\sigma}\) 计算得到 \(\begin{bmatrix} x_1' \\ x_2' \\ \vdots \\ x_k' \end{bmatrix}\)，可以减少 Internal Covariate Shift，同时也不像 BN 那样依赖于 batch size，适用于 batch size 较小或需要适应动态 batch size 的情况。</p> </blockquote> <h4 id="transformers-encoder">Transformer’s Encoder</h4> <p><a href="https://www.youtube.com/watch?v=n9TlOhRjYoc"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <div class="md-img"><img src="/assets/img/DL-img/transformer1.png" alt="transformer1" style="zoom:50%;"/></div> <ol> <li>输入需要做 <a href="#Positional Encoding">Positional Encoding</a> 后再输入到 <a href="#Multi-head Self-attention">Multi-Head Attention</a> (Self-attention) 中；</li> <li>Self-attention 的每个 output vector 还需要再加上它的 input vector 来当作是新的 output，这样的操作叫做 <strong>residual connection</strong>；</li> <li>然后这个新的 output 再去做 Layer Normalization；</li> <li>Layer Normalization 的输出再输入到 FC Network中，FC Network 在这里也有 residual 的架构；</li> <li>FC Network 的输出再做一次 Layer Normalization 作为 Transformer’s Encoder 的一个 block 的输出；</li> <li>Transformer’s Encoder 一共重复 N 次上述的 block。</li> </ol> <hr/> <blockquote> <p>BOS (begin of sentence)：在 NLP 中，处理文本数据时常常需要明确标示句子的起始和结束位置。BOS 作为一个 token，帮助模型识别句子的开始。这对于训练语言模型、进行序列生成任务（如文本生成、机器翻译等）尤为重要，因为模型需要了解句子结构的边界以更准确地处理和生成文本。同理，EOS (end of sentence) 可以用来表示句子的结束。</p> </blockquote> <blockquote> <p>token：通常指文本中的一个独立的、有意义的元素，是构成 sentence 的基本单位。在文本处理和分析中，原始文本经常会被分割成 tokens，以便于进一步的处理和分析。</p> </blockquote> <blockquote> <p>Autoregressive (AR)：基于过去的值来预测未来的值，<strong>逐步生成序列的每个元素</strong>。在 Autoregressive 模型中，每个时刻的输出不仅依赖于输入变量，还依赖于之前时刻的一个或多个输出。e.g., \(X_t = \alpha X_{t-1} + \epsilon_t\)</p> </blockquote> <blockquote> <p>Non-autoregressive (NAR)：<strong>一次性地生成整个序列</strong>（将整个输入序列一次性送入模型并利用并行计算的能力来同时处理序列中的所有位置），显著提高了生成速度。但是，由于模型可能难以捕捉序列中的长距离依赖关系，所以会牺牲一定的生成质量。</p> </blockquote> <h4 id="transformers-decoder">Transformer’s Decoder</h4> <p><a href="https://www.youtube.com/watch?v=N6aRv06iv2g"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <div class="md-img"><img src="/assets/img/DL-img/transformer2.png" alt="transformer2" style="zoom:50%;"/></div> <ol> <li> <p><strong>Masked Self-attention</strong>：举例来说，当产生 \(\boldsymbol{b^2}\) 时，只用 \(\boldsymbol{q^2}\) 与 \(\boldsymbol{k^1}, \boldsymbol{k^2}\) 去计算 attention score，即每个位置只考虑当前和之前的 attention。</p> <p><strong><em>Why masked? Consider how does decoder work (i.e., Autoregressive).</em></strong> Decoder 看到的输入是它在前一个时间点自己的输出（初始从 BOS 开始），即 Self-attention 的 \(\boldsymbol{a^1}, \boldsymbol{a^2}, \cdots, \boldsymbol{a^i}\) 是 one by one 依次产生的，而不是原来的一次性输入全部。</p> <p>最后，添加一个 “Stop Token” EOS，当 Decoder 输出 EOS 时整个程序结束，从而使得机器能够自行决定要输出的 sequence 的长度。</p> </li> <li> <p><strong>Autoregressive Transformer (AT) v.s. Non-autoregressive Transformer (NAT)</strong></p> <ul> <li> <p>因为 NAT 是一次性输出整个序列，那么如何决定其输出序列的长度呢？</p> <ol> <li> <p>Another predictor for output length (在 Encoder 后加一个 classifier 来提前给出 Decoder 所输出的序列的长度)</p> </li> <li> <p>Output a very long sequence, ignoring tokens after EOS</p> </li> </ol> </li> <li>Advantages: parallel, controllable output length</li> <li>Disadvantages: NAT is usually worse than AT</li> </ul> </li> <li> <p><strong>Cross Attention</strong>：Encoder 的输出 \(\boldsymbol{b^1}, \boldsymbol{b^2}, \cdots, \boldsymbol{b^i}\) 会产生 \(\boldsymbol{k^1}, \boldsymbol{k^2}, \cdots, \boldsymbol{k^i}\) 和 \(\boldsymbol{v^1}, \boldsymbol{v^2}, \cdots, \boldsymbol{v^i}\)，Decoder 通过 Masked Self-attention 输出的向量会产生 Query \(\boldsymbol{q}\)。\(\boldsymbol{q}\) 与 \(\boldsymbol{k}\) 点乘得到 \(\alpha\)，再与 \(\boldsymbol{v}\) 加权求和，所得到的向量再输入到 FC Network 中。在 Transformer 中，这里的 \(\boldsymbol{k}\) 和 \(\boldsymbol{v}\) 来自于 Encoder 的最后一层，\(\boldsymbol{q}\) 则来自于 Decoder 的当前层。这样的设置允许 Decoder 的每一层都能够访问到 Encoder 的全部信息。</p> </li> </ol> <h4 id="transformers-training">Transformer’s Training</h4> <ol> <li> <p>minimize cross entropy</p> </li> <li><strong>Teacher Forcing</strong>: using the ground truth as decoder’s input. 在早期阶段，可以有效地指导模型学习正确的输出模式，提高效率。但会导致 training 和 inference (testing) 存在一定的 Mismatch。因为在 inference 中，模型必须依赖于自己的输出来生成下一个词，所以模型会看到一些错误的东西，但在 training 中模型看到的始终是正确的。这个现象叫做 <strong>Exposure Bias</strong>，因此会导致在 inference 中，当模型遇到自己的预测是错误的时会表现不佳，因为它在训练过程中没有足够的机会去学习如何从自己的错误中恢复。<strong>Scheduled Sampling</strong> 可以通过逐渐地将模型自己的预测引入训练过程中来有效地缓解 Exposure Bias，具体来说，是在训练过程的不同阶段以一定的概率选择使用模型的预测输出而不是真实的上一个输出作为下一个时间步（Time Step）的输入，并且这个概率会随着时间逐渐增加，从而帮助模型在训练过程中逐渐适应其在实际应用中的使用情况。Transformer 并没有用 Scheduled Sampling，要想用的话需要更多的考虑。</li> <li><strong>Training tips1 - Guided Attention</strong>: 引入额外的信息或约束来指导注意力的焦点（或引导注意力的分布，比如让注意力保持从左向右），使模型能够更有效地学习从输入到输出的映射关系。Guided Attention 通常通过在模型的损失函数中加入额外的项来实现，使得模型在训练过程中被鼓励学习符合这些引导的注意力分布，从而在特定任务上达到更好的性能。</li> <li><strong>Training tips2 - Noise</strong>: 当需要机器有创造力时，可以在 Decoder 中加入<strong>随机性</strong>。在语音合成（Text-to-Speech, TTS）中，模型训练好后需要在测试时添加 Noise 才会让合成出来的声音更像人声（有点违背常理，因为 Noise 通常在训练时添加（e.g., Dropout），让机器看过更多的可能性，从而模型会更 robust）。</li> <li><strong>Training tips3 - Optimization</strong>: <strong>When you don’t know how to optimize, just use Reinforcement Learning (RL)!</strong> (e.g., loss function is non-differentiable, considering <strong>loss function as reward and Decoder as agent</strong>)</li> </ol> <h3 id="6-generation">6. Generation</h3> <h4 id="network-as-generator">Network as Generator</h4> <p>The input of the network is not only \(\boldsymbol{x}\), but \(\boldsymbol{x}\) and a random variable \(\boldsymbol{z}\), \(\boldsymbol{z}\) is randomly sampled from a distribution, and this distribution is <strong>simple</strong> enough, i.e., we know its formulation (e.g., Normal/Uniform). So the output of the network \(\boldsymbol{y}\) is a <strong>complex distribution</strong>. And the network here is called <strong>generator</strong>. <strong>The architecture of the generator is totally customizable</strong>. P.S. 这些简单的分布选择哪一个差异都不大，只要够简单就行，因为 generator 总是会将其对应到一个复杂的分布。</p> <p>Especially for the tasks needs <strong>“creativity”</strong>. Because the same input \(\boldsymbol{x}\) can have different outputs \(\boldsymbol{y}\).</p> <h4 id="gan">GAN</h4> <p><strong>GAN 很强大但是局限性在于 unstable training。</strong></p> <p>本节的讨论都是基于 <strong>Unconditional generation</strong>: input without \(\boldsymbol{x}\)</p> <p><strong>Discriminator</strong> is actually a neural network (architecture is customizable) and its output is a <strong>scalar</strong> (larger means input is real, otherwise, it is fake).</p> <p><strong><span class="my-large-text">Description</span></strong></p> <p>The discriminator’s function is to determine whether the input data is real or fake, the latter being generated by the generator. And the generator’s function is to generate fake data that is as close as possible to the real one. The two are adversarial, making each other stronger and stronger.</p> <p><strong><span class="my-large-text" id="gan-algorithm">Algorithm</span></strong> <a href="https://www.youtube.com/watch?v=4OWp0wDu6Xw"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Step 1: Randomly Initialize the parameters of generator and discriminator.</p> <p>For each iteration:</p> <p>Step 2: <strong>Fix generator, and update discriminator</strong>. Firstly, sample some vectors from normal distributions (or others) as input to feed into generator, then generator generates some fake objects and we can also sample some real objects from database. Next discriminator learns to assign high scores to the real objects and low scores to the generated objects (Considered as classification or regression).</p> <p>Step 3: <strong>Fix discriminator, and update generator</strong>. According to the scores output by discriminator, generator learns how to maximize the scores to the generated objects. 所以这里可以把 discriminator 输出的 score 加一个负号作为 loss，让 loss 越小越好，从而更新 generator 的参数。</p> <p>Step 4: Repeat step 2 and 3, until both are good enough.</p> <p><strong><span class="my-large-text">Objective</span></strong> <a href="https://www.youtube.com/watch?v=jNY1WBb8l4U"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <blockquote> <p>Divergence（散度）：用于衡量两个概率分布（Probability Distribution）之间的差异或不一致性的程度。例如 KL 散度和 JS 散度都是通过比较两个分布在同一事件集上的概率值来量化分布之间的差异。</p> </blockquote> <blockquote> <p>KL Divergence (Kullback-Leibler Divergence)：也称为相对熵（Relative Entropy），对于两个概率分布 \(P\) 和 \(Q\)，公式为 \(KL(P \parallel Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\)，\(x\) 表示每个事件。其中，对数部分用于衡量 \(P\) 和 \(Q\) 在每个事件上的相对差异，如果 \(P(x)\) 和 \(Q(x)\) 相等，那么表示两者在该事件上没有差异，则对数部分为 0。\(P(x)\) 则是事件 \(x\) 在分布 \(P\) 中发生的真实概率，如果这个概率很低，那么即使差异很大，它对总的 KL 散度的贡献也会较小。最后两者综合的结果表示从分布 \(P\) 到分布 \(Q\)（分布 \(P\) 相对于分布 \(Q\)）的“信息损失”量，即 KL 散度量化了如果我们假设数据遵循分布 \(Q\) 而真实分布为 \(P\) 时，我们期望遭受的信息损失。KL 散度越大，意味着使用假设分布 \(Q\) 来近似真实分布 \(P\) 时会损失更多的信息。局限性：KL 散度是非对称（即 \(KL(P \parallel Q) \ne KL(Q \parallel P)\)）的且无界的。</p> </blockquote> <blockquote> <p>JS Divergence (Jensen-Shannon Divergence): 公式为 \(JS(P \parallel Q) = \frac{1}{2} KL(P(x) \parallel \frac{P(x) + Q(x)}{2}) + \frac{1}{2} KL(Q(x) \parallel \frac{P(x) + Q(x)}{2})\)，相比于 KL 散度，JS 散度是对称且有界（当对数底数为 2 时，范围为 0 到 1）的。当两个概率分布完全相同时，即 \(P(x) = Q(x)\) 时，JS 散度为 0。当两个概率分布完全不相交（没有重叠）时，JS 散度达到最大值。可以理解为一个事件在一个分布中发生时（概率大于 0），在另一个分布中一定不发生（概率为 0）。JS 散度可以看作是基于平均分布的比较。JS 散度对于分布中的小变动（如噪声）通常也更加平滑（不敏感）。</p> </blockquote> <blockquote> <p>Cross Entropy: \(H(P, Q) = -\sum_{x} P(x) \log Q(x)\)，交叉熵常用作 NN 的损失函数来衡量概率分布 \(P\) 和 \(Q\) 之间的相似性。交叉熵与 KL 散度之间的关系：\(H(P, Q) = H(P) + KL(P \parallel Q)\)。因此，交叉熵不仅考虑了当使用分布 \(Q\) 来近似分布 \(P\) 时的信息损失（<strong>分布间差异导致的额外的不确定性</strong>），还考虑了分布 \(P\) <strong>本身的不确定性</strong>。这意味着最小化交叉熵可以间接最小化预测分布与真实分布之间的 KL 散度，从而提高模型的预测准确性。</p> </blockquote> <blockquote> <p>JS 散度倾向于比较两个分布的相似度，交叉熵倾向于优化一个模型，使其预测分布尽可能接近真实分布。</p> </blockquote> <blockquote> <p>\(P(A \mid B)\) 读作 “P of A given B”</p> </blockquote> <p>对于 Generator \(G\) 和其输出的分布 \(P_G\)，以及真实数据的分布 \(P_{data}\)，有</p> \[G^* = \arg \min\limits_G \text{Div}(P_G, P_{data})\] <p><strong>The objective</strong> is to find a generator \(G^*\) that can make minimize the divergence between \(P_G\) and \(P_{data}\). <strong>However</strong>, the divergence (e.g., KL or JS) is hard to compute when the distribution is continuous.</p> <p>Although we do not know how to formulate the continuous distributions \(P_G\) and \(P_{data}\), we can <strong>sample</strong> from them.</p> <blockquote> <p>When it needs to be maximized, it is called an <strong>objective function</strong>; conversely, it is called a <strong>loss function</strong>.</p> </blockquote> <p>Training Discriminator: \(D^* = \arg \max\limits_D V(D, G)\) and <strong>objective function</strong> for discriminator \(D\): \(V(D, G) = E_{y \sim P_{data}}[\log D(y)] + E_{y \sim P_G}[\log (1-D(y))]\) (\(\sim\) represents the random variable \(y\) follows the distribution, 遵循/服从于)。因为要最大化 \(V\) 的值（最大化 discriminator 区分真假样本的能力），所以希望如果样本是从真实数据中采样的，discriminator 给出的分数越高越好。如果是从 generator 生成的样本中采样的，则分数越小越好。\(V(D, G)\) is equal to negative cross entropy, so training discriminator is equal to train classifier, and <strong>the maximum objective value \(\max\limits_D V(D, G)\) is related to JS divergence</strong> (if the two distributions are similar, data sampled from them is mixed, so it’s hard to discriminate and \(\max\limits_D V(D, G)\) is small). So we can replace the old objective function \(Div(P_G, P_{data})\) with the new one \(\max\limits_D V(D, G)\), i.e.,</p> \[G^* = \arg \min\limits_G \max\limits_D V(D, G)\] <p>即在给定 generator 的条件下找 discriminator 来 maximize \(V(D, G)\)，然后再找 generator 来 minimize \(\max\limits_D V(D, G)\)，具体用 <strong><a href="#gan-algorithm">Algorithm</a></strong> 部分的步骤来解。</p> <h5 id="tips-for-gan">Tips for GAN</h5> <blockquote> <p>Manifold（流形）：是一个局部具有欧几里得空间（平直空间）性质的高维空间（复杂空间），即存在于高维空间的数据其实可以用潜在的低维流形来表示，或者说在高维空间中实际有效的数据点（即反映数据本质结构和关系的点）可能只占据了一小部分区域，或者说高维空间中的所有点并非都同等重要。流形学习就是学习一种“将数据从高维空间降维到低维空间，还能不损失信息”的映射，从而能够揭示数据的内在结构（非线性 ok），帮助我们更好地表示和理解数据。</p> </blockquote> <ul> <li> <p><strong>JS divergence is not suitable</strong>, because \(P_G\) and \(P_{data}\) are not overlapped</p> <p>Explanation 1: The nature of data, i.e., both are low-dim manifold in high-dim space, so the overlap can be ignored;</p> <p>Explanation 2: Even though they have overlap, if sampling is not sufficient, there is always a boundary that can separate them.</p> <p>Problem: JS divergence is always log2, so even though the distances between two distributions are different, they are same to the JS divergence, which results in the inability to update parameters during training. In this case, binary classifier always achieves 100% accuracy.</p> </li> <li> <p><strong>WGAN</strong></p> <p><strong>用 Wasserstein distance 替代 JS divergence</strong>。Wasserstein distance (Earth Mover’s Distance, EMD) 是指衡量将一个概率分布变换成另一个概率分布所需的最小“成本”或“工作量”。所以如果两个分布没有重叠，当它们之间的距离不同时，Wasserstein distance 也能给出相应不同的值，从而能够进行 optimization，而非像 JS divergence 那样始终是常数。</p> <div class="md-img"><img src="/assets/img/DL-img/gan1.png" alt="gan1" style="zoom:30%;"/></div> <blockquote> <p>Lipschitz Continuity：一个函数 \(f: X \rightarrow Y\)，存在一个实数 \(c\)，对于该函数定义域 \(X\) 上的任意两点 \(x_1, x_2\)，连接它们的直线的斜率的绝对值不大于这个实数，即 \(\frac{\vert f(x_1) - f(x_2) \vert}{\vert x_1 - x_2 \vert} \le c\)。它本质上是限制了连续函数斜率的变化，保证了函数的平滑性。1-Lipschitz 即实数 \(c\) 的值为 1。</p> </blockquote> <blockquote> <p>Spectral Normalization：是一种正则化技术，用于约束神经网络中权重矩阵的谱范数（spectral norm），可以控制该层输出相对于输入变化的速度，从而确保神经网络满足 Lipschitz 连续性。Spectral norm 是矩阵的最大奇异值，可以理解为矩阵的最大“拉伸因子”。具体步骤为：1）对于每个权重矩阵 \(W\)，计算其最大奇异值 \(\sigma(W)\)；2）对 \(W\) 进行归一化，即新的权重矩阵为 \(W/\sigma(W)\)。其优势在于不需要额外的超参数调整。</p> </blockquote> <blockquote> <p>Singular Value Decomposition (SVD，奇异值分解)：给定一个矩阵 \(M\)，有 \(M = U \Sigma V^T\)。其中，\(U\) 和 \(V\) 是 Orthogonal Matrix（如果一个矩阵是正交矩阵，则它和它 transpose 的乘积是 Identity Matrix），\(\Sigma\) 是 Diagonal Matrix，对角线上的元素是 \(M\) 的奇异值，并且这些奇异值是按照从大到小的顺序排列的。</p> <div class="md-img"><img src="/assets/img/DL-img/svd.png" alt="svd" style="zoom:75%;"/><div> </div></div> </blockquote> <p>WGAN 的 optimization 为：</p> \[D^* = \arg \max\limits_{D \in 1-Lipschitz} \{E_{y \sim P_{data}}[D(y)] - E_{y \sim P_G}[D(y)]\}\] <p>其中的目标函数的值就当作是 Wasserstein distance。因为目标是前一个 \(D(y)\) 要越大越好，后一个则越小越好。所以如果没有 1-Lipschitz 的限制，当真实样本和生成样本没有重叠的时候，discriminator 会分别给出 \(\infty\) 和 \(-\infty\) 的分数，从而导致 discriminator 的训练无法收敛。并且只要是没有重叠，不论分布之间的距离大小，最后得到的值都会是 \(\infty\)，这就跟 JS 散度一样了。加上 1-Lipschitz 限制后，因为要求 discriminator 足够平滑，所以当分布之间距离小时，Wasserstein distance 值就会比较小，反之就会比较大，从而保证了训练的稳定性。</p> <p>WGAN 并没有真正地实现 1-Lipschitz，实际操作上可以用 <strong>Spectral Normalization</strong> (Keep gradient norm smaller than 1 everywhere) 来实现 1-Lipschitz，也就是 SNGAN。</p> </li> <li> <p>GAN for Sequence Generation</p> <p>Gradient 其实是当某一个参数有变化时，对目标造成了多大的影响。当 generator 的参数有一个小变化时，它输出的 distribution 也会有一个小变化，但是这不会影响它最终输出的 token 是哪一个（因为取的是 max），所以 discriminator 输出的分数也不会改变。因此，Gradient descent is not work。</p> </li> <li> <p>Diversity of GAN</p> <p>Problem 1: Mode Collapse. 生成器开始生成几乎相同的样本，而无法覆盖到真实数据分布的多样性。</p> <p>Problem 2: Mode Dropping. 生成器遗漏了一部分真实数据的分布。</p> <p>检测 diversity 的方法：将 generator 的输出 \(y^i\) 输入到一个 classifier 里面，每个 \(y^i\) 都会得到一个分布 \(P(c \mid y^i)\)，将所有的分布取平均，如果平均的分布非常集中（比如都属于某一类），则说明多样性不够。值得注意的是，diversity 是以多个生成器的输出（e.g., 1000 images）来评价的，而 quality 是以单个输出（e.g., 1 image）来评价的。</p> <p>通过 classifier 的输出的类别可能都是一样的，比如生成的分子不同，但是类别都是化合物；或者生成的人脸不同，但类别都是人脸。所以要用 softmax 之前的 hidden layer 的输出向量，这个向量是不同的，用真实数据和生成数据的这个向量来计算 Frechet Inception Distance，这个值越小多样性越高。</p> <p>Problem 3: 如何评判 generator 生成的样本是不是 GAN 所 memory 的？<strong>Evaluation of GAN is difficult</strong>.</p> </li> </ul> <h5 id="conditional-generation">Conditional Generation</h5> <p><a href="https://www.youtube.com/watch?v=MP0BnVH2yOo"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>加回 \(\boldsymbol{x}\) ，作为 condition，用来操控 generator 的输出。例如，Text-to-image 的任务，\(\boldsymbol{x}\) 就是一段文字，通过 RNN 或 Transformer’s Encoder 等等将其编码为向量再输入到 generator 里。</p> <p>按照 Unconditional 的训练方法 generator 只需要学习到如何生成真实的数据即可“骗过” discriminator（因为 discriminator 的输入只有 generator 的输出 \(\boldsymbol{y}\)），并没有学习到所输入的 condition \(\boldsymbol{x}\)。现在 discriminator 的输入还要包括 \(\boldsymbol{x}\)，所以 discriminator 的评判标准变为 \(\boldsymbol{y}\) is realistic or not + \(\boldsymbol{x}\) and \(\boldsymbol{y}\) are matched or not。因此，需要<strong>成对</strong>的输入数据（\(\boldsymbol{x}\), \(\boldsymbol{y}\) <strong>pairs</strong>）来训练，实际上，需要给 discriminator 的是完全配对时是 1，\(\boldsymbol{y}\) 不够好的时候是 0，还有 \(\boldsymbol{y}\) 足够好但是和 \(\boldsymbol{x}\) 不匹配也是 0。所以喂给 discriminator 的 pairs 中应该有正确配对的，也应该有错误配对的。</p> <p><strong>Conditional GAN + Supervised Learning</strong> 可以让 generator “骗过” discriminator，同时也让生成的结果最接近“标准答案”（即 condition \(\boldsymbol{x}\)），例如 pix2pix（按照草稿给出房屋设计图）。特别适用于生成的数据和 condition 的模态一致的情况。</p> <hr/> <p>If training data is unpaired, network needs to learn to how to output domain \(Y\) from input domain \(X\) (e.g., Style Transfer). Similarly, the generator can ignore the input data, but also fools the discriminator. And because the input data is unpaired, so conditional GAN is not work.</p> <p><strong>Cycle GAN</strong> <a href="https://www.youtube.com/watch?v=wulqhgnDr7E"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Add another generator \(G_{Y \rightarrow X}\) after the first generator \(G_{X \rightarrow Y}\), \(G_{Y \rightarrow X}\) is to reconstruct the the output of \(G_{X \rightarrow Y}\) from domain \(Y\) back to domain \(X\). And we hope that the output of \(G_{Y \rightarrow X}\) and the input of \(G_{X \rightarrow Y}\) are as close as possible, the similarity between them can be considered as equivalent to the distance between two vectors. There is also a discriminator that outputs a scalar to determine whether the output of \(G_{X \rightarrow Y}\) belongs to domain \(Y\) or not.</p> <p>The process mentioned above can also be reversed. So Cycle GAN is bidirectional.</p> <h4 id="vae">VAE</h4> <p><a href="https://www.youtube.com/watch?v=8zomhgKrsmQ"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Auto-Encoder 的流程：</p> <p><strong>Input data (high-dims) \(\longrightarrow\) Encoder \(\xrightarrow[]{\text{Compression}}\) vector (low-dims) \(\longrightarrow\) Decoder \(\xrightarrow[]{\text{Reconstruction}}\) Output data (as close to the input data as possible)</strong></p> <p>设 Auto-Encoder 的 Encoder 输出的 vector 是 original vector，对于 VAE (Variational Auto-Encoder) 来说，Encoder 输出的是两个 vector \([m_1, m_2, \dots, m_N]\) 和 \([\sigma_1, \sigma_2, \dots, \sigma_N]\)（维度和 original vector 一致），然后从一个 normal distribution 中采样一个 vector \([e_1, e_2, \dots, e_N]\)，通过 \(c_i = \text{exp}(\sigma_i) \times e_i + m_i\) 得到 vector \([c_1, c_2, \dots, c_N]\)，这个 vector 是用于输入到 Decoder 中的。并且，训练的过程中不仅要让 output data 和 input data 越接近越好，还需要最小化 \(\sum_{i=1}^N(\text{exp}(\sigma_i) - (1 + \sigma_i) + (m_i)^2)\)。</p> <p>这里的 \([m_1, m_2, \dots, m_N]\) 代表了 original vector，\([\sigma_1, \sigma_2, \dots, \sigma_N]\) 代表了 noise 的 variance，从而决定了 noise 的大小（因为 \([e_1, e_2, \dots, e_N]\) 的 variance 是固定的），取 exponential 保证 variance 一定是正的。因此，\([c_1, c_2, \dots, c_N]\) 相当于 original vector with noise。这个 variance 的大小应该是多少是机器在训练时自己学出来的，但是如果不加限制，variance 一定会倾向于为 0，因此给它一个限制让 variance 不能太小 \(\sum_{i=1}^N(\text{exp}(\sigma_i) - (1 + \sigma_i) + (m_i)^2)\)，式中 \(\text{exp}(\sigma_i) - (1 + \sigma_i)\) 的最低点为 \(\sigma_i = 0\) 时，所以 \(\text{exp}(\sigma_i)\) 的 variance 最小值为 1。\((m_i)^2\) 这一项则相当于做 L2 regularization。</p> <hr/> <p>我们想要的是 estimate the probability distribution</p> <blockquote> <p>Multinomial Distribution：用于描述在具有多个可能结果的实验中，每个结果出现次数的概率，属于一种离散概率分布。其 PMF (Probability Mass Function) 为 \(P(X_1 = x_1, X_2 = x_2, \dots, X_k = x_k) = \frac{n!}{x_1! x_2! \cdots x_k!} p_1^{x_1} p_2^{x_2} \cdots p_k^{x_k}\)，并且有 \(\sum^k_{i=1}p_i=1\)，\(\sum^k_{i=1}x_i=n\)。</p> </blockquote> <blockquote> <p>Gaussian Mixture Model：由若干个高斯分布组成，每个高斯分布在混合中都有自己的比重，每个数据点都被看作是由这些高斯分布中的一个生成的。其公式为 \(P(x) = \sum_m P(m)P(x \mid m)\)，\(m \sim P(m)\) 表示从一个 multinomial distribution 中采样出第 \(m\) 个高斯分布，\(x\) 是从 \(m\) 中采样得到的，即 \(x \mid m \sim N(\mu^m, \sigma^m)\)。</p> </blockquote> <blockquote> <p>Maximum Likelihood Estimation：用于从一组给定的数据中估计模型的参数，核心思想是选择可以使观测到的数据出现概率（即似然）最大的参数值作为最佳估计。首先，假设有数据集 \(D\)，包含 \(n\) 个独立同分布的观测数据点 \(\{x_1, x_2, \dots, x_n\}\) 和模型参数 \(\theta\)。定义似然函数 \(L(\theta)\) 为<strong>在参数 \(\theta\) 下观察到数据集 \(D\) 的概率</strong> \(L(\theta) = P(D \mid \theta) = \prod^n_{i=1} P(x_i \mid \theta)\)。然后取对数将乘积转换为求和 \(\log L(\theta) = \sum^n_{i=1} \log P(x_i \mid \theta)\)，然后对对数似然函数求导并令其为 0 \(\frac{d}{d\theta} \log L(\theta) = 0\)，即可求出使对数似然函数最大化的参数值。</p> </blockquote> <blockquote> <p>\(P(z,x) = P(z \mid x)P(x)\)，\(P(z,x)\) 是 \(z\) 和 \(x\) 同时发生的联合概率。</p> </blockquote> <p>上述是 VAE 的直观解释，数学解释如下：</p> <p>基于 Gaussian Mixture Model 的原理，首先从 normal distribution 中 sample 出一个 vector \(z\)。\(z\) 的每一个维度代表了一个属性（attribute）。从 \(z\) 中采样可以对应到不同的 normal distribution，所以由 \(z\) 可以决定 normal distribution \(P(x \mid z)\) 的 mean 和 variance，即 \(\mu(z)\) 和 \(\sigma(z)\)，写作 \(x \mid z \sim N(\mu(z), \sigma(z))\)。由于 \(z\) 是 <strong>continuous</strong> 的，所以 \(\mu(z)\) 和 \(\sigma(z)\) 有无限多的可能，可以<strong>用 NN 来学（\(z\) 为输入，\(\mu(z)\) 和 \(\sigma(z)\) 为输出）</strong>。从而得到 \(P(x) = \int\limits_{z}P(z)P(x \mid z)dz\)，\(P(z)\) 也是一个 normal distribution。这里要解决的是 \(\mu(z)\) 和 \(\sigma(z)\) 需要被估计，它的 <strong>criterion</strong> 是 maximize the likelihood \(L = \sum\limits_x \log P(x)\) of the observed \(x\)，即需要<strong>调整 NN 的参数使得 \(L\) 最大</strong>。另外，还需要一个分布 \(Q(z \mid x)\) with \(z \mid x \sim N(\mu'(x), \sigma'(x))\) 来决定 \(P(z)\) 的 mean 和 variance，即 \(\mu'(x)\) 和 \(\sigma'(x)\)。所以<strong>需要另一个 NN’</strong>，输入 \(x\) 输出 \(\mu'(x)\) 和 \(\sigma'(x)\)。因此，<strong>NN（\(P(x \mid z)\)）就相当于 VAE 的 Decoder，NN’（\(Q(z \mid x)\)）就相当于 VAE 的 Encoder</strong>。</p> <p>针对 criterion 进行推导：</p> <div class="math-scroller"> $$ \begin{align*} \log P(x) &amp;= \int\limits_z Q(z \mid x) \log P(x) dz \ , \ (Q(z \mid x) \text{ can be any distribution, so the integral = 1}) \\ &amp;= \int\limits_z Q(z \mid x) \log (\frac{P(z,x)}{P(z \mid x)})dz \\ &amp;= \int\limits_z Q(z \mid x) \log (\frac{P(z,x)}{Q(z \mid x)} \frac{Q(z \mid x)}{P(z \mid x)}) \\ &amp;= \int\limits_z Q(z \mid x) \log (\frac{P(z,x)}{Q(z \mid x)})dz + \int\limits_z Q(z \mid x) \log (\frac{Q(z \mid x)}{P(z \mid x)})dz \\ &amp;= \int\limits_z Q(z \mid x) \log (\frac{P(x \mid z)P(z)}{Q(z \mid x)})dz + \int\limits_z Q(z \mid x) \log (\frac{Q(z \mid x)}{P(z \mid x)})dz \ , \ (\text{the first term is lower bound} \ L_b \ , \ \text{the second term is KL divergence which is} \ge 0) \\ &amp;= L_b + KL(Q(z \mid x) \parallel P(z \mid x)) \end{align*} $$ </div> <p>对于 lower bound \(L_b = \int\limits_z Q(z \mid x) \log (\frac{P(x \mid z)P(z)}{Q(z \mid x)})dz\)，未知的是 \(P(x \mid z)\) 和 \(Q(z \mid x)\)。原本依据 \(P(x) = \int\limits_{z}P(z)P(x \mid z)dz\) 我们只需要找 \(P(x \mid z)\) 来最大化 likelihood，现在则需要<strong>找 \(P(x \mid z)\) 和 \(Q(z \mid x)\) 来最大化 \(L_b\)</strong>。如果还是只找 \(P(x \mid z)\) 来最大化 \(L_b\)，则有可能 \(L_b\) 增加但 likelihood 反而减小，因为不知道它们之间的差距是多少，likelihood 减小也会比 \(L_b\) 大。因为 \(\log P(x)\) 的大小与 \(Q(z \mid x)\) 无关，所以如果先固定住 \(P(x \mid z)\)（即 \(\log P(x)\) 的大小保持不变）再调 \(Q(z \mid x)\) 去最大化 \(L_b\)，就可以让 \(L_b\) 越来越接近 likelihood（\(\log P(x)\)）。等到两者相等时，再增大 \(L_b\) 就可以保证 likelihood 一定也是增大的（因为 \(\log P(x) \ge L_b\)）。<strong>但是总归来说 VAE 直接优化的是 \(L_b\)，而不是 likelihood，所以这两者之间具体的差距到底是多少我们并不清楚，这也是 VAE 的局限性。</strong></p> \[\begin{align*} L_b &amp;= \int\limits_z Q(z \mid x) \log (\frac{P(x \mid z)P(z)}{Q(z \mid x)})dz \\ &amp;= \int\limits_z Q(z \mid x) \log (\frac{P(z)}{Q(z \mid x)})dz + \int\limits_z Q(z \mid x) \log P(x \mid z)dz \\ &amp;= -KL(Q(z \mid x) \parallel P(z)) + \int\limits_z Q(z \mid x) \log P(x \mid z)dz \end{align*}\] <p>对于 \(L_b\) 的第一项 \(-KL(Q(z \mid x) \parallel P(z))\)，最小化的方法是调 \(Q(z \mid x)\) 所对应的 NN’ 的参数让它产生的 distribution 和一个 normal distribution 越接近越好。最小化第一项，其实就是最小化 \(\sum_{i=1}^N(\text{exp}(\sigma_i) - (1 + \sigma_i) + (m_i)^2)\)。</p> <p>对于 \(L_b\) 的第二项 \(\int\limits_z Q(z \mid x) \log P(x \mid z)dz\)，可以想成是用 \(Q(z \mid x)\) 对 \(\log P(x \mid z)\) 做 weighted sum，所以就可以看作是一个期望值 \(\int\limits_z Q(z \mid x) \log P(x \mid z)dz = E_{Q(z \mid x)}[\log P(x \mid z)]\)。相当于向 NN’ 输入一个 \(x\)，从 NN’ 输出的一个 distribution（\(Q(z \mid x)\)）中可以采样出一个 \(z\)，然后需要最大化由这个 \(z\) 再产生 \(x\) 的概率（\(\log P(x \mid z)\)），要做到最大化需要将 \(z\) 输入到 NN 中，NN 会输出 \(\mu(x)\) 和 \(\sigma(x)\)，希望 \(\mu(x)\) 和 \(x\) 越接近越好（在 normal distribution 中 \(\mu(x)\) 这个点的概率是最高的）。</p> <p>因此，\(L_b\) 就是 VAE 的 loss function。</p> <p><strong>VAE 的问题：VAE 可能只是会模仿，而没有办法创新。</strong></p> <h4 id="flow-based-model">Flow-based Model</h4> <p><a href="https://www.youtube.com/watch?v=uXY18nzdSsM"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Flow-based model can directly optimize the objective function \(G^* = \arg \max\limits_G \sum^n_{i=1} \log P_G(x^i)\), i.e., maximizing the likelihood, instead of indirectly minimizing the divergence \(G^* = \arg \min\limits_G \text{Div}(P_G, P_{data})\).</p> <blockquote> <p>Jacobian Matrix：如果有一个函数 \(\boldsymbol{x} = f(\boldsymbol{z})\)，其中向量 \(\boldsymbol{x}\) 是关于向量 \(\boldsymbol{z}\) 的函数，Jacobian Matrix 可以表示为 \(\boldsymbol{x}\) 关于 \(\boldsymbol{z}\) 的所有一阶偏导数。如果 \(\boldsymbol{x}\) 由 \(m\) 个分量组成，\(\boldsymbol{z}\) 由 \(n\) 个分量组成，则 Jacobian Matrix \(\boldsymbol{J}\) 为：</p> \[\boldsymbol{J}_f = \begin{bmatrix} \frac{\partial x_1}{\partial z_1} &amp; \frac{\partial x_1}{\partial z_2} &amp; \cdots &amp; \frac{\partial x_1}{\partial z_n} \\ \frac{\partial x_2}{\partial z_1} &amp; \frac{\partial x_2}{\partial z_2} &amp; \cdots &amp; \frac{\partial x_2}{\partial z_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial x_m}{\partial z_1} &amp; \frac{\partial x_m}{\partial z_2} &amp; \cdots &amp; \frac{\partial x_m}{\partial z_n} \end{bmatrix}\] <p>可以把 \(f\) 当作 generator，\(\boldsymbol{z}\) 当作 input，\(\boldsymbol{x}\) 当作 output (generation)。</p> <p>如果有一个 \(f\) 的反函数 \(\boldsymbol{z} = f^{-1}(\boldsymbol{x})\)，其 Jacobian Matrix \(\boldsymbol{J}_{f^{-1}}\) 与 \(\boldsymbol{J}_f\) 相乘的结果为单位矩阵，即 \(\boldsymbol{J}_f \boldsymbol{J}_{f^{-1}} = I\)。</p> </blockquote> <blockquote> <p>Determinant：The determinant of a square matrix is a <strong>scalar</strong> that provides information about the matrix. 因为有 \(\det(A) \cdot \det(A^{-1}) = 1\)，所以有 \(\det(\boldsymbol{J}_f) \cdot \det(\boldsymbol{J}_{f^{-1}}) = 1\)。二阶行列式的几何意义是二维空间中平行四边形的面积，三阶行列式的几何意义是三维空间中平行六面体的体积，更高阶行列式的几何意义是高维空间中的“体积”。另外，一个矩阵做 transpose 不会改变它的 determinant，即 \(\det(A) = \det(A^T)\)。</p> </blockquote> <blockquote> <p>Change of Variable Theorem：假设有一个分布 \({\pi(\boldsymbol{z})}\)（相当于 generator 输入的分布）和一个函数 \(\boldsymbol{x} = f(\boldsymbol{z})\)，\(\boldsymbol{x}\) 也形成一个分布为 \(p(\boldsymbol{x})\)（相当于 generator 输出的分布），在分布 \({\pi(\boldsymbol{z})}\) 上有一点 \(z'\)，它的 probability density value 是 \(\pi(z')\)，\(z'\) 通过函数后会得到 \(x'\)，它的 probability density value 是 \(p(x')\)。\(\pi(z')\) 与 \(p(x')\) 之间存在关系：\(p(x')\vert\det(\boldsymbol{J}_f)\vert = \pi(z')\) 等同于 \(p(x') = \pi(z')\vert\det(\boldsymbol{J}_{f^{-1}})\vert\)。</p> </blockquote> <p>由 Change of Variable Theorem，可以将 \(G^* = \arg \max\limits_G \sum^n_{i=1} \log p_G(x^i)\) 中的 \(\log p_G(x^i)\) 表示出来，即 \(p_G(x^i) = \pi(z^i)\vert\det(\boldsymbol{J}_{G^{-1}})\vert\) 和 \(z^i = G^{-1}(x^i)\)，进一步推导有 \(\log p_G(x^i) = \log \pi(G^{-1}(x^i)) + \log \vert\det(\boldsymbol{J}_{G^{-1}})\vert\)。但是算 \(\log p_G(x^i)\) 的这个式子要有两个前提，一是需要计算 \(\boldsymbol{J}_{G^{-1}}\)，即计算 \(\boldsymbol{J}_G\)，尽管只需要知道怎么计算 \(\frac{\partial{x_i}}{\partial{z_i}}\) 即可，但是 \(\boldsymbol{J}_G\) 可能会很大，导致计算 \(\det(\boldsymbol{J}_G)\) 的运算量非常大。二是 \(G^{-1}\) 是可被计算的，所以要求 \(G\) 必须是 invertible 的，则输入 \(\boldsymbol{z}\) 的维度和输出 \(\boldsymbol{x}\) 的维度就需要保持一致。因此，<strong>Flow-based Model 的 \(G\) 具有一定的限制性</strong>。</p> <p>既然如此，那就将多个 \(G\) 依次连接起来（所以叫 Flow），对于 \(\{G_1, \dots, G_N\}\)，有 \(p_K(x^i) = \pi(z^i)(\vert\det(\boldsymbol{J}_{G^{-1}_1})\vert) \cdots (\vert\det(\boldsymbol{J}_{G^{-1}_N})\vert)\)，</p> <p>所以有 \(\log p_N(x^i) = \log \pi(z^i) + \sum\limits^N_{n=1} \log \vert\det(\boldsymbol{J}_{G^{-1}_N})\vert\) 和 \(z^i = G^{-1}_1(\cdots G^{-1}_N(x^i))\)。</p> <p>虽然用于生成的是 \(G\)，但实际训练的是 \(G^{-1}\)，即从 \(p_{data}(x)\) 中采样 \(x^i\)，然后输入进 \(G^{-1}\) 得到 \(z^i = G^{-1}(x^i)\)。对于 \(\log p_G(x^i) = \log \pi(G^{-1}(x^i)) + \log \vert\det(\boldsymbol{J}_{G^{-1}})\vert\) 的第一项 \(\log \pi(z^i)\)，因为 \(\pi\) 是一个 normal distribution，所以 \(z^i\) 为 zero vector 时，\(\pi(z^i)\) 最大。但是如果经过训练后 \(z^i\) 都是 zero vector，会导致 \(\boldsymbol{J}_{G^{-1}}\) 为 zero matrix，\(\det(\boldsymbol{J}_{G^{-1}}) = 0\)，则第二项会趋近于 \(-\infty\)，从而导致无法最大化 \(\log p_G(x^i)\)。所以最大化时要同时考虑这两项，第一项让 \(z^i\) 趋近于 zero vector，第二项限制不会让所有的 \(z^i\) 都变为 zero vector。</p> <p>Flow-based model 中常用的 \(G\) 是 <strong>Coupling Layer</strong>，它被用于 RealNVP 和 Glow 中。Coupling Layer 的核心思想是将输入分割成两部分，然后以一种方式修改其中一部分，并且这种修改依赖于另一部分的值，同时保持另一部分不变。Coupling Layer 允许进行复杂的变换，同时可以保持整个变换过程的可逆性。</p> <p>对于一个 \(D\) 维的输入向量 \(z_D\)，将其分成两部分 \((z_1, \dots, z_d)\) 和 \((z_{d+1}, \dots, z_D)\)，前一部分保持不变输出 \((x_1, \dots, x_d)\)，并且前一部分分别通过函数 \(F\) 和函数 \(H\) 得到 \((\beta_{d+1}, \dots, \beta_D)\) 和 \((\gamma_{d+1}, \dots, \gamma_D)\)（\(F\) 和 \(H\) 是任意的），然后通过 \(x_{i &gt; d} = \beta_{i &gt; d} \cdot z_{i &gt; d} + \gamma_{i &gt; d}\) 计算得到 \((x_{d+1}, \dots, x_D)\)。<strong>可逆性</strong>体现在，当我们知道 \((x_1, \dots, x_d)\) 和 \((x_{d+1}, \dots, x_D)\) 时，对于前者，由于不变可以直接通过 \(z_{i \le d} = x_{i \le d}\) 得到 \((z_1, \dots, z_d)\)。然后将其正向通过 \(F\) 和 \(H\) 可以分别得到 \((\beta_{d+1}, \dots, \beta_D)\) 和 \((\gamma_{d+1}, \dots, \gamma_D)\)，就可以根据公式 \(z_{i &gt; d} = \frac{x_{i&gt;d} - \gamma_{i&gt;d}}{\beta_{i&gt;d}}\) 得到 \((z_{d+1}, \dots, z_D)\)。因此，依据可逆性就可以算出 \(z^i\)。</p> <p>对于 \(\det(\boldsymbol{J}_G)\) 的计算，具体看视频 <a href="https://www.youtube.com/watch?v=uXY18nzdSsM">Timestamp - 49:28</a>，最后公式为 \(\det(\boldsymbol{J}_G) = \beta_{d+1}\beta_{d+2} \cdots \beta_D\)，因此也很容易计算。</p> <p>在对 Coupling Layer 进行堆叠（stack）时，需要在某些位置换一下不变的那一部分的位置，可以防止最初设定的不变的那一部分最后的输出还是和输入（随机采样的 noise）一样。</p> <hr/> <p>在 GLOW 中还用了一种方法 1x1 Convolution，给定一个 3x3 的 Matrix \(W\)（3 channels）作为 \(G\)，通过学习这个 \(W\) 做到 shuffle the channels。\(W\) 也需要是 invertible 的。</p> <h4 id="diffusion-model">Diffusion Model</h4> <p>生成分子的<strong>多样性</strong>：VAE、FLOW-based Model</p> <p>生成分子的<strong>质量和细节</strong>：GAN、Diffusion Model</p> <h3 id="7-self-supervised-learning-fire">7. Self-Supervised Learning :fire:</h3> <p>Self-Supervised Learning 是通过利用输入的无标记数据本身的结构来生成标签（一部分数据作为输入，另一部分则作为这个输入的预期输出或标签），进而训练模型，从而无需依赖外部的、成本高昂的标注过程。这种学习方法允许模型通过预测任务来自我学习，从而提取和理解数据的内在结构和特征。</p> <h4 id="bert-encoder-only">BERT (Encoder-Only)</h4> <p><a href="https://www.youtube.com/watch?v=gh0hewYkjgo"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>BERT (<strong>B</strong>idirectional <strong>E</strong>ncoder <strong>R</strong>epresentations from <strong>T</strong>ransformers) is an <strong>Encoder</strong>.</p> <p><strong><span class="my-large-text">Masking Input</span></strong></p> <p>Randomly masking some tokens, with the method of masking also chosen randomly: there’re 2 methods, one is to use a special token (e.g., [MASK]), and the other is to use another random token.</p> <p>然后将 masked token 通过 BERT，其输出做一个 Linear 的 transform 和 softmax 后得到一个分布，再将这个分布与 ground truth 计算 cross-entropy。训练 BERT 使其能够成功预测 masked token 是什么（<strong><span class="my-yellow-text">填空题</span></strong>），相当于一个分类问题。</p> <p>Masking Input 任务就是一个自监督学习的过程，这个过程不需要外部的标签，因为正确的标签（即被 masked 之前的 token）已经包含在输入中。</p> <p><strong><span class="my-large-text">Next Sentence Prediction</span></strong></p> <p>Add a <strong>[CLS]</strong> token at the beginning, and add a <strong>[SEP]</strong> token between two sentences. BERT 处理整个序列，为序列中的每个 token 输出一个向量，但是只有 [CLS] 的向量随后被输入到一个线性层中（这个向量能够捕获整个输入序列的上下文信息（Self-attention）/ 看过整个 sentence 了），根据最终输出的 class 来预测第二个句子是否为第一个句子的逻辑后续。</p> <p><em>But NSP is maybe not useful. 所以有以下几种改进：</em></p> <ul> <li> <p><a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>: Robustly Optimized BERT Approach;</p> </li> <li> <p><a href="https://arxiv.org/abs/1909.11942">ALBERT</a>: Sentence Order Prediction (SOP).</p> </li> </ul> <p><strong><span class="my-large-text">Fine-tune</span></strong></p> <p>BERT 可以通过 fine-tune（<strong>need a little bit labeled data</strong>）后用于各种 downstream tasks，相当于干细胞。在 fine-tune 中，向模型中输入少量有标记的数据，模型的所有参数（包括 BERT 的原始参数和线性层的新参数）通常都会根据特定任务的损失函数进行优化，以最小化预测输出和实际标签之间的差异，从而提高模型在该任务上的表现。</p> <p><strong><span class="my-large-text">Pre-train</span></strong></p> <p>在 fine-tune 之前产生 BERT 的过程是 Self-Supervised Learning，也叫做 Pre-train。</p> <hr/> <p><strong>The use of BERT</strong>: Pre-train + Fine-tune can be considered as Semi-supervised Learning (i.e., A large amount of unlabeled data and a small amount of labeled data).</p> <p>Case 1: Input is sequence, output is class. Add a [CLS] token before the sequence, BERT outputs a vector for each token fed into it, but only the output vector of [CLS] will be input into Linear, and finally output the class. <strong>BERT and Linear both need to update parameters, the parameters of Linear is random initialization, but BERT is initiated by Pre-train</strong>.</p> <p>Case 2: Input is sequence, output is also sequence, and both have the same length. BERT outputs a vector for each token fed into it, each vector will be input into Linear, and get its output class.</p> <p>Case 3: Input is two sequences, output is class. Add a [CLS] token at the beginning, and add a [SEP] token between two sequences. The rest as in case 1.</p> <p>Case 4: QA。对 BERT 输入一个 sequence，得到 sequence 中每个 token 对应的输出向量 $\boldsymbol{t^i}$，随机初始化一个向量 \(\boldsymbol{v}\)，将这两者做 Self-attention 后通过 softmax 输出每个 token 对应的概率，最后输出概率最高的 token。也可以初始化两个向量，可以输出由两个 token 组成的这个 sequence 的范围。上述基于正确答案一定在输入的 sequence 里面。</p> <p><strong>In general，最常见的用法是：BERT 是预训练好的，后面接一个 Linear Classifier，再通过少量的有标记的数据微调两者的参数即可。</strong></p> <hr/> <p>BERT 只是 Pre-train 了一个 Encoder，那么如何 Pre-train 一个 seq2seq model 呢？需要将 input sequence 弄坏（corrupted），然后希望 Decoder 输出的 sequence 和弄坏前一模一样（Encoder 和 Decoder 由 cross attention 连接）。弄坏的方法：Mask token、Delete token、打乱顺序、或 Mask + 打乱等等。<a href="https://arxiv.org/abs/1910.13461">BART</a></p> <hr/> <blockquote> <p>Cosine Similarity：对于 n 维向量 \(\boldsymbol{A}\) 和 \(\boldsymbol{B}\)，它们的余弦相似度为</p> \[\text{cosine similarity} = \cos(\theta) = \frac{\boldsymbol{A} \cdot \boldsymbol{B}}{\Vert \boldsymbol{A} \Vert \Vert \boldsymbol{B} \Vert} = \frac{\sum\limits_{i=1}^{n} A_i B_i}{\sqrt{\sum\limits_{i=1}^{n} A_i^2} \sqrt{\sum\limits_{i=1}^{n} B_i^2}}\] <p>余弦相似度可以很好地衡量两个向量方向的一致性，而忽略它们的大小。</p> </blockquote> <p>Sequence 的 token 经过 BERT 处理后输出的向量可以称之为 embedding。同样的 token 在不同的上下文中可能代表的意思就不同，所以它们的 embedding 也会不同，计算 embedding 之间的余弦相似度可以用于判断其相似性。BERT 在学习做填空题的过程中（Masking input）也许就是学习从上下文（context）中获取信息来进行预测，由于这里的 embedding 是考虑了上下文信息的，所以可以称之为 contextual embedding。</p> <h4 id="gpt-decoder-only">GPT (Decoder-Only)</h4> <p><a href="https://www.youtube.com/watch?v=WY_E0Sd4K80"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>GPT (<strong>G</strong>enerative <strong>P</strong>re-trained <strong>T</strong>ransformer) 的任务是<strong>预测下一个出现的 token 是什么</strong>，所以 GPT 具有<strong>生成</strong>的能力。首先输入 &lt;BOS&gt; token，GPT 输出相应的 embedding，embedding 会通过 Linear Transform 输出一个分布，然后优化其与真实分布之间的交叉熵，以此类推。<strong>相当于 Transformer 的 Decoder</strong>，只不过 GPT 是经过预训练的且没有 Cross Attention 那部分，只有 Masked Self-attention 那部分。</p> <blockquote> <p>Prompt：指输入给模型的文本片段，模型据此生成相应的输出，即 Prompt 用于指导模型的生成。</p> </blockquote> <p>The use of GPT in downstream tasks: Description, example, and prompt.</p> <p><strong>GPT 基于大规模的预训练和理解上下文的能力，能够在仅有少量所提供的样本的情况下快速适应新的任务，并生成与这些样本相似的输出。这使得 GPT 在很多情况下能够实现或接近专门针对特定任务进行微调的效果。</strong></p> <p>在 GPT 中的 Few-shot / One-shot / Zero-shot Learning，和一般的不一样，这里并<strong>没有做 gradient descent</strong>，也就没有微调 GPT 的参数。所以在文献中称作 In-context Learning。</p> <div class="md-img"><img src="/assets/img/DL-img/gpt0.png" alt="gpt0" style="zoom:30%;"/></div> <p><a href="https://www.youtube.com/watch?v=DOG1L9lvsDY">GPT-3 Paper Video</a></p> <h4 id="auto-encoder">Auto-encoder</h4> <p><a href="https://www.youtube.com/watch?v=3oHlf8-J3Nc"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p><strong>Input data (high-dims) \(\longrightarrow\) Encoder \(\xrightarrow[]{\text{Compression}}\) vector (low-dims) \(\longrightarrow\) Decoder \(\xrightarrow[]{\text{Reconstruction}}\) Output data (as close to the input data as possible)</strong></p> <p>Here, vector can be called embedding, representation or feature. And this vector is usually used for downstream tasks.</p> <p>Auto-encoder 中间输出低维向量的层又被称作 <strong>Bottleneck</strong>，Bottleneck 强制 Auto-encoder 在有限的维度中捕获输入数据的最重要特征，以便在 Decoder 中尽可能准确地重建输入。因此，Auto-encoder也可以用来做 Dimension Reduction。</p> <p>虽然输入数据的维度很高，从表面上看比较复杂，但是实际的变化可能是有限的，所以可以用更简单的方法来表示它。那么在下游的任务中，可能只需要比较少的训练数据就可以让模型学到本来应该学到的东西。</p> <p><strong><span class="my-large-text">De-noising Auto-encoder</span></strong></p> <p>给原本的输入加上 noise 作为 Encoder 新的输入，但是 Decoder 重建的还是没有 noise 的输入。BERT 的 Mask Input 其实也相当于是加上 noise。</p> <p><strong><span class="my-large-text">Feature Disentanglement</span></strong> <a href="https://www.youtube.com/watch?v=JZvEzb5PV3U"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Feature Disentanglement 的目的是尝试搞清楚 encoder 输出的 embedding 中，各个/些维度分别代表了什么实际的含义。</p> <div class="md-img"><img src="/assets/img/DL-img/fd1.png" alt="fd1" style="zoom:35%;"/></div> <p><strong><span class="my-large-text">Discrete Latent Representation</span></strong></p> <p>原本 encoder 输出的 embedding 中的值是 continuous 的，现在使用离散值来表示隐含的特征或状态，每个隐含状态可以对应到一组<strong>有限</strong>的标签或类别上，从而使得模型可以更简洁地捕捉到关键的信息。比如可以是 Binary（每一维代表某个特征有或没有） 或者 One-hot，或者设定一个 codebook（ a set of vectors），计算 embedding 与这些向量之间的相似度，然后将其中相似度最大的向量再输入到 decoder 中，这里的 codebook 也是需要从训练数据中学习的。</p> <p>In general，embedding 从原来的无限种可能变成了有限种可能。</p> <hr/> <p><strong><a href="#vae">VAE</a></strong> 则是 encoder 将输入数据映射到一个 latent space（通常是多维正态分布），而非直接映射到一个固定的 latent vector，decoder 再从该分布中 sample 来生成数据，这样 VAE 不仅能够重建输入样本，还能够生成新的数据样本。</p> <hr/> <p>Auto-encoder 可以应用于 Anomaly Detection（异常检测），比如 Cancer Detection，难点在于负样本通常很少，所以一般的分类很难 work。</p> <h4 id="recent-advances">Recent Advances</h4> <p><em><u>TODO</u></em></p> <p>Generative Approach</p> <p>Predictive Approach</p> <p>Contrastive Learning</p> <p>Bootstrapping Approach</p> <h3 id="8-explainable-ai-xai">8. Explainable AI (XAI)</h3> <p><strong>模型可解释性库：<a href="https://captum.ai/">Captum - Model Interpretability for PyTorch</a></strong></p> <p>目前的 DL：</p> <div class="md-img"><img src="/assets/img/DL-img/xai1.png" alt="xai1" style="zoom:33%;"/></div> <p>未来的目标：根据解释的结果来修正模型</p> <hr/> <p>Explainable：给予黑箱可解释的能力</p> <p>Interpretable：解释的对象本来就不是黑箱</p> <hr/> <h4 id="goal-of-xai">Goal of XAI</h4> <p><strong><span class="my-yellow-text">We do not need to completely know how an ML model works. Because we do not completely know how human brains work, but we trust the decisions of humans!</span></strong></p> <p>Why we trust the decisions of humans? Usually, You need <strong>a reason (or an excuse)</strong> to convince people to believe you (<em>The Copy Machine Study by Ellen Langer</em>). <strong>So Good XAI make people (your customers, your boss, yourself) acceptable/comfortable/happy.</strong></p> <p><strong><em>我们不知道机器到底真正在想什么，我们希望的是通过某些方法解读出来的东西是人看起来会觉得很开心的（然后就可以编故事说机器就是这么想的）。</em></strong></p> <h4 id="local-explanation--global-explanation">Local Explanation &amp; Global Explanation</h4> <p>给定一个 classifier，以及其 input (e.g., molecule) 和 output (e.g., non-toxic)。Local Explanation 问的是“为什么这个分子没有毒性”；Global Explanation 问的是“什么样的分子是没有毒性的”，而不是针对某个特定的分子。</p> <h5 id="local-explanation-explain-the-decision">Local Explanation: Explain the Decision</h5> <p><a href="https://www.youtube.com/watch?v=WQY85vaQfTI"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <ol> <li> <p>Which component of input data is critical?</p> <p><strong>从 gradient 的角度</strong>，对于 \(\{x_1, \cdots, x_n, \cdots, x_N\} \longrightarrow \{x_1, \cdots, x_n +\Delta x, \cdots, x_N\}\)，有 \(e \longrightarrow \Delta e\)，这里的每一个 \(x\) 是一个 component，举例来说，对应 image 而言就是一个 pixel，对于 sequence 而言就是一个 token。\(e\) 就是 loss。如果某个 \(x\) 加上很小的 \(\Delta x\)，\(\Delta e\) 却很大，则说明这个 component 是重要的。因此，可以用 \(\vert\frac{\Delta e}{\Delta x}\vert\) 来代表 \(x_n\) 的重要性，实际上就是把 \(x_n\) 对 loss 做偏微分。 把所有的这个比值都算出来后，就可以得到 <strong>Saliency Map</strong>。</p> <p><strong>SmoothGrad</strong>: Randomly add noises to the input, get saliency maps of the noisy input, and average them. 可以更明显地展示出 saliency map 中对模型决策重要的区域。</p> <p>只考虑 gradient 会有 gradient saturation 的限制，可以采用 Integrated gradient 来替代。</p> </li> <li> <p>How a network processes the input data?</p> <ul> <li> <p><strong>Visualization</strong> - 可视化观察网络某个层的输出。</p> </li> <li> <p><strong>Probing</strong> - 训练一个探针（其实就是一个分类器）插入到网络的某一层中，将这一层输出的 embeddings 输入到分类器中，通过分类器的输出判断目前的 embeddings 到哪一个阶段了或是否学到了什么。但是要注意分类器是否训练成功，因为如果 accuracy 很低，有可能是机器没有学到，也有可能是机器学到了但是分类器训练得很烂，或者是 accuracy 很高，可能因为机器没有学好但是分类器过拟合导致乐观估计。</p> </li> </ul> </li> </ol> <h5 id="global-explanation-explain-the-whole-model">Global Explanation: Explain the Whole Model</h5> <p><a href="https://www.youtube.com/watch?v=0ayIPqbdHYQ"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>首先 Training a generator with data: input low-dim vector \(z\) into a generator \(G\) (GAN, VAE, etc.) and the generator outputs \(X\) (\(X = G(z)\))。然后将 \(X\) 输入到一个 classifier 中输出 \(y\)，希望找到一个 \(z\) 使得 \(y\) 中的某一个 dim / 某一个类别的概率越高越好，即 \(z^* = \arg \max\limits_z y_i\)，最后将 \(z^*\) 输入到 \(G\) 中，观察产生的 \(X^*\) 是什么样子，从而可以知道<strong>在机器眼中某一个类别是长什么样子的</strong>。</p> <hr/> <p>还可以尝试用简单的 Linear Model 尽可能地模仿复杂黑盒模型的行为，然后再去分析 Linear Model 也许就可以解释复杂模型。例如 <strong>LIME</strong> (Local Interpretable Model-Agnostic Explanations) 是用 Linear Model 去模仿复杂模型的一小个区域内的行为，因为 Linear Model 能力有限，很难模仿整个复杂模型的行为。<a href="https://www.youtube.com/watch?v=K1mWgthGS-A">LIME Video1</a>, <a href="https://www.youtube.com/watch?v=OjqIVSwly4k">LIME Video2</a></p> <h3 id="9-adversarial-attack">9. Adversarial Attack</h3> <p>对于药物设计来说，目前研究的重点更倾向于提高模型的预测准确性和可靠性或解决特定的生物医学问题，而不是对抗潜在的对抗性攻击（安全性）。另外，药物设计领域要构造有效的对抗性样本也比较困难。</p> <h3 id="10-domain-adaptation">10. Domain Adaptation</h3> <p><em>Domain adaptation can be considered <strong>a part of transfer learning</strong>.</em> <a href="https://www.youtube.com/watch?v=Mnk_oUrgppM"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <hr/> <p><strong>Domain shift: Training and testing data have different distributons.</strong></p> <p>Source domain 是 with labeled data 的，随着对 target domain 的了解程度不同，有不同的 domain adaptation 的方法。</p> <ul> <li> <p>在 target domain 上有大量数据且有标签：</p> <p>直接做训练就好了，根本不需要做 domain adaptation。</p> </li> <li> <p>在 target domain 上有少量数据且有标签：</p> <p>用这些少量数据来对已经在 source domain 上训练好的模型进行微调，需要注意的是，由于数据量很少，所以不要在 target domain 上跑太多的 epoch（maybe 个位数？），避免过拟合。</p> </li> <li> <p>在 target domain 上有大量数据但无标签：</p> <p>Basic Idea：训练两个 Feature Extractor，分别接收来自 source domain 和 target domain 的输入，然后输出各自的 feature（一个 vector）。Feature Extractor 被训练成能够抽取出两者共同的部分，即<strong>各自的 feature 的分布几乎相同</strong>。</p> <p><strong><span class="my-large-text">Domain Adversarial Training</span></strong></p> <p>可以将一个 classifier 视为 feature extractor 和 label predictor 两部分，其中哪些部分算 feature extractor，哪些部分算 label predictor 是自行决定的（也算是一个 hyperparameter）。然后再训练一个二元的 domain classifier，它的输入是 feature extractor 所输出的 feature，输出是判断这个 feature 来自于哪个 domain。domain classifier 要做的事是能够正确分类原本来自于哪个 domain，而 feature extractor 则是要模糊界限骗过 domain classifier。所以可以看作是 feature extractor 扮演 generator 的角色，domain classifier 扮演 discriminator 的角色。</p> <p>以数学公式的角度来看，对于 label predictor，存在参数 \(\boldsymbol{\theta_p}\) 和 loss \(L\)，要求得 \(\boldsymbol{\theta_p^*} = \arg \min\limits_{\boldsymbol{\theta_p}}L\)；对于 domain classifier，存在参数 \(\boldsymbol{\theta_d}\) 和 loss \(L_d\)，要求得 \(\boldsymbol{\theta_d^*} = \arg \min\limits_{\boldsymbol{\theta_d}}L_d\)；对于 feature extractor，存在参数 \(\boldsymbol{\theta_f}\)，要求得 \(\boldsymbol{\theta_f^*} = \arg \min\limits_{\boldsymbol{\theta_f}}L - L_d\)。</p> </li> </ul> <hr/> <p>以上是假设两个 domain 内类别集完全相同的情况，但实际上这可能并不总是成立，<a href="https://openaccess.thecvf.com/content_CVPR_2019/html/You_Universal_Domain_Adaptation_CVPR_2019_paper.html">Universal Domain Adaptation</a> 考虑了 target domain 可能包含 source domain 未见过的新类别，同时也可能缺少 source domain 中的一些类别。目标是使模型能够识别和适应 target domain 中的已知类别（即两者共有的类别），同时对于 target domain 特有的未知类别，模型也能够进行有效的区分和处理。</p> <ul> <li> <p>在 target domain 上有少量数据且无标签：</p> <p><a href="https://arxiv.org/abs/1909.13231">Testing Time Training (TTT)</a></p> </li> <li> <p>对 target domain 一无所知：</p> <p>Domain Generalization</p> </li> </ul> <h3 id="11-deep-rl-fire">11. Deep RL :fire:</h3> <p>在有标签的数据收集有困难且<strong><span class="my-yellow-text">不知道正确答案</span></strong>的情况下可以考虑 RL。</p> <hr/> <p><em>Machine Learning ≈ Looking for a Function</em></p> <p>在 RL 中会有一个 <strong>Actor (or Agent)</strong> 和一个 <strong>Environment</strong>，两者会进行互动，Environment 会给 Actor 一个 <strong>Observation (or State)</strong> 作为其输入，Actor 看到这个 Observation 后会输出一个 <strong>Action</strong> 去影响 Environment，Environment 改变后就会产生新的 Observation，再进行下一次的互动。所以，Actor 在这里其实就是我们要找的 Function（\(\text{Action} = f(\text{Observation})\)）。同时，在互动的过程中，Environment 会不断地给 Actor 一些 <strong>Reward</strong> 来告诉它现在的 Action 是好的还是不好的。最终 Function 的目标是要最大化所获得的 Reward 的总和。</p> <h4 id="rl-framework-also-3-steps">RL Framework (Also 3 Steps)</h4> <p><a href="https://www.youtube.com/watch?v=XWukX-ayIrs"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <ol> <li> <p><strong>Function with Unknown</strong></p> <p>This function is “<strong>Actor</strong>”, usually called “<strong>Policy Network</strong>”. The input of policy network is the observation of machine represented as a vector or a matrix. The output is the score for each possible action. The architecture of network is <strong>customized</strong>. The usual strategy for selecting which action to take is <strong>randomly sampling</strong> based on the scores as the corresponding probabilities. <strong><em>RL 的结果受 Sample 的影响非常大。</em></strong></p> </li> <li> <p><strong>Define Loss Function from Training Data</strong></p> <p>完成一次 Game Over（达到目标状态/完成任务/任务失败）的整个过程，称作是一个 <strong>episode</strong>，并得到一个 Total Reward（或者称作 Return）\(R = \sum^T_{t=1}r_t\)，目标就是要在一个 episode 或多个 episode 中最大化累积的奖励 \(R\) ，也可以说 \(-R\) 就是 loss。</p> </li> <li> <p><strong>Optimization</strong></p> <p>存在一个互动过程 \(\begin{gather*} env \rightarrow s_0 \rightarrow actor \rightarrow a_0 \rightarrow env \rightarrow s_1 \rightarrow actor \\ \rightarrow a_1 \rightarrow env \rightarrow s_2 \rightarrow actor \rightarrow a_2 \rightarrow \cdots \end{gather*}\)，可以用 trajectory（轨迹）来描述，即 \(\tau = (s_0, a_0, s_1, a_1, s_2, a_2, \cdots)\)。同时，在这个互动过程中的每个时间步 \(t\)，reward \(r_t\) 的获得都需要依据 \(s_t\) 和 \(a_t\)，所以有 \(R(\tau) = \sum^T_{t=1}r_t\)。因此，Optimization 的做法就是<strong>调 Network（Actor）的参数使 \(R(\tau)\) 的数值越大越好</strong>。</p> <p>难点在于：1）Actor 的输出是有随机性的，因为 \(a_1\) 是 randomly sample 产生的。给定一个 \(s_1\)，每次输出的 \(a_1\) 不一定一样。（用期望值）2）Environment 和 Reward 都是 black box，很难解释它们的输出是为什么。（只需要与环境交互，不需要了解环境的内部机制）3）Environment 和 Reward 往往也是有随机性的。（用期望值）</p> </li> </ol> <p>对于 Actor 来说，有 \(s \longrightarrow \text{Actor}(\text{with param} \ \boldsymbol{\theta}) \longrightarrow a\)，如果在特定的 \(s\) 的情况下想要输出特定的 \(a\)，可以计算 \(a\) 与 ground truth \(\hat{a}\) 之间的交叉熵 \(e\)。假设有一组训练数据对 \(\{s_1, \hat{a}_1\}, \{s_2, \hat{a}_2\}, \{s_3, \hat{a}_3\}, \cdots, \{s_N, \hat{a}_N\}\)，如果期待 Actor 能够执行的行为是 take action \(\hat{a}_1, \hat{a}_3\) 且 don’t take action \(\hat{a}_2\)，则 loss 为 \(L = e_1 - e_2 + e_3 \cdots\)，然后再去 learn 参数 \(\boldsymbol{\theta}\) 使 loss 最小（\(\boldsymbol{\theta}^* = \arg \min\limits_{\boldsymbol{\theta}}L\)）。更进一步，如果每个行为并不是只有好或不好，而是有一个程度可以衡量（不再是一个 binary 的问题），即每一训练数据对 \(\{s_t, \hat{a}_t\}\) 都有相对应的一个分数 \(A_t\) 作为想要执行该行为的程度。因此，loss 也就变为 \(L = \sum A_t e_t\)。</p> <p><em>那么现在的问题是应该如何正确地获得训练数据对 \(\{s_t, \hat{a}_t\}\) 和分数 \(A_t\)？</em></p> <p><strong>Version 0：</strong>首先<strong>随机初始化</strong>一个 Actor，<strong>在与 Environment 的交互中得到训练数据对</strong> \(\{s_t, a_t\}\)，然后在多个 episode 中收集到足够的数据。Reward \(r_t\) 就当作 action 的分数 \(A_t\)（<span class="my-yellow-text">\(A_t = r_t\)</span>）。但是，由于一个 action 不仅会影响当前的 reward，还会影响后续的 observation，进而影响后续的 reward。所以 Version 0 是一个 short-sighted version。</p> <blockquote> <p><strong>Reward Delay</strong>: Actor has to sacrifice immediate reward (or do something that cannot get any reward) to gain more long-term reward.</p> </blockquote> <p><strong>Version 1：</strong>改进了 Version 0 不合理的点，将以当前点来看未来所有的 reward 加起来来评估当前 action 的好坏，即计算 cumulative reward \(G_t = r_t + r_{t+1} + \cdots + r_N = \sum^N_{n=t}r_n\)，令 <span class="my-yellow-text">\(A_t = G_t\)</span>。这样即使当前的 reward 为 0，只看当前的 reward 无法判断 action 的好坏，但是由于 action 还会造成后续的一系列影响，所以也能够知道当前的 action 是好还是坏。</p> <p><strong>Version 2：</strong>由于 \(G_t\) 的公式是加和后续所有的 \(r\)，可能有 \(r_t\) 对距离很远的 \(r\) 的贡献很小。所以进一步改进了 \(G_t\) 的公式，设定一个 discount factor \(\gamma &lt; 1\)，从而有 <strong>Discounted Cumulative Reward</strong> \(G_t' = r_t + \gamma r_{t+1} + \gamma^2 r_{t+2} + \cdots + \gamma^{N-t} r_N = \sum^N_{n=t} \gamma^{n-t} r_n\)，令 <span class="my-yellow-text">\(A_t = G_t'\)</span>。</p> <p><strong>Version 3：</strong>由于 reward 好还是坏是相对的，所以需要做 Normalization（也能够降低方差）。可以让所有的 \(G_t'\) 都减去一个 baseline \(b\)（<span class="my-yellow-text">\(A_t = G_t' - b\)</span>）来实现。</p> <hr/> <h4 id="policy-gradient">Policy Gradient</h4> <p><a href="https://www.youtube.com/watch?v=US8DFaAZcp4"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22"/> alt=”Youtube Video”</a></p> <ul> <li> <p>Initialize actor network parameters \(\boldsymbol{\theta^0}\)</p> </li> <li> <p>For training iteration \(i\) = \(1\) to \(T\):</p> <ul> <li>Using actor \(\boldsymbol{\theta^{i-1}}\) to interact with the environment</li> <li>Obtain data \(\{s_1, a_1\}, \{s_2, a_2\}, \{s_3, a_3\}, \cdots, \{s_N, a_N\}\) (<em>Data collection is in the “for loop” of training iterations</em>)</li> <li>Compute \(A_1, A_2, \cdots, A_N\)</li> <li>Compute loss \(L\)</li> <li>Update parameters \(\boldsymbol{\theta^i} \leftarrow \boldsymbol{\theta^{i-1}} - \eta \nabla L\)</li> </ul> </li> </ul> <p><strong>Each time you update the model parameters, you need to collect the whole training set again.</strong> One explanation is that the data collected by \(\boldsymbol{\theta^{i-1}}\) is the result of \(\boldsymbol{\theta^{i-1}}\) interacting with the environment, so that is the experience of \(\boldsymbol{\theta^{i-1}}\). This experience can be used to update \(\boldsymbol{\theta^{i-1}}\), however, maybe not be good for \(\boldsymbol{\theta^{i}}\). (The same action results in different rewards for actors with different capabilities)</p> <hr/> <p>另一种讲法（衔接 <a href="#PPO">PPO</a>）：<a href="https://www.youtube.com/watch?v=z95ZYgPgXOY"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>在给定 Actor 的参数 \(\theta\) 下，与环境互动得到某一个 trajectory \(\tau\) 的概率为 \(p_{\theta}(\tau) = p(s_1) \prod\limits^T_{t=1} p_{\theta}(a_t \mid s_t) p(s_{t+1} \mid s_t,a_t)\)，所以 Reward \(R(\tau) = \sum\limits^T_{t=1} r_t\) 在这里应该是 Expected Reward \(\bar{R_{\theta}} = \sum\limits_{\tau} R(\tau) p_{\theta}(\tau) = E_{\tau \sim p_{\theta}(\tau)}[R(\tau)]\)。因此可以计算出 gradient 为</p> <div class="math-scroller"> $$ \begin{align*} \nabla \bar{R_{\theta}} = \sum\limits_{\tau} R(\tau) \nabla p_{\theta}(\tau) &amp;= \sum\limits_{\tau} R(\tau) p_{\theta}(\tau) \frac{\nabla p_{\theta}(\tau)}{p_{\theta}(\tau)} \\ &amp;= \sum\limits_{\tau} R(\tau) p_{\theta}(\tau) \nabla \log p_{\theta}(\tau) \ , \ (\text{可以推广到 } \nabla f(x) = f(x) \nabla \log f(x)) \\ &amp;= E_{\tau \sim p_{\theta}(\tau)}[R(\tau) \nabla \log p_{\theta}(\tau)] \\ &amp;\approx \frac{1}{N} \sum\limits^N_{n=1} R(\tau^n) \nabla \log p_{\theta}(\tau^n) \\ &amp;= \frac{1}{N} \sum\limits^N_{n=1} \sum\limits^{T_n}_{t=1} R(\tau^n) \nabla \log p_{\theta}(a^n_t \mid s^n_t) \ , \ (\text{对于 } p_{\theta}(\tau^n) \text{ 只有 } p_{\theta}(a_t \mid s_t) \text{ 这一项与 } \theta \text{ 有关}) \end{align*} $$ </div> <p>可以直观理解为如果在某个 \(s_t\) 执行的 \(a_t\) 导致 \(R(\tau)\) 是正的（大于 baseline 更合理），就增加 \(\{s_t, a_t\}\) 这一项的概率；反之，则减少概率。</p> <p>所以，就可以用 gradient ascent 来做 update（每一次 update 前都需要先收集 \(\tau^n\) 和 \(R(\tau^n)\)），即 \(\theta \leftarrow \theta + \eta \nabla \bar{R_{\theta}}\)。</p> <blockquote> <p>Cross-Entropy Loss 的公式为：\(L(\theta) = - \frac{1}{N} \sum\limits^N_{i=1} \sum\limits^C_{j=1} y_{ij} \log(p(y=j \mid x_i;\theta))\)，其中 \(C\) 指有 \(C\) 个类别，\(y_{ij}\) 是一个指示变量，如果样本 \(i\) 属于类别 \(j\)，则其值为 1，否则为 0。对于单个样本 \(x_i\)，\(p(y=j \mid x_i;\theta)\) 为模型对每个类别 \(j\) 的预测概率。</p> </blockquote> <blockquote> <p>Log-Likelihood 的公式为：\(\log L(\theta) = \sum\limits^N_{i=1} \sum\limits^C_{j=1} y_{ij} \log(p(y=j \mid x_i;\theta))\)</p> </blockquote> <blockquote> <p>因此，对于分类问题，我们在最小化交叉熵损失时，实际上是在最大化对数似然，所以<strong>最小化交叉熵等同于最大化似然</strong>（交叉熵直接衡量了模型预测概率分布与真实概率分布之间的差异，而最大化对数似然意味着寻找能够使得模型预测概率最接近真实标签概率的模型参数）。</p> </blockquote> <p>具体操作上，对于 Actor 输出 \(a_t\)（选择采取哪一个动作）可以看作是一个分类问题（输出给定状态下动作的概率分布），由于最小化交叉熵等同于最大化似然，所以最大化 \(\frac{1}{N} \sum\limits^N_{n=1} \sum\limits^{T_n}_{t=1} \log p_{\theta}(a^n_t \mid s^n_t)\) 这个目标函数就可以通过最小化交叉熵损失来实现，而它的梯度 \(\frac{1}{N} \sum\limits^N_{n=1} \sum\limits^{T_n}_{t=1} \nabla \log p_{\theta}(a^n_t \mid s^n_t)\) 在 PyTorch 中可以自动计算。在这个基础上，只需要在损失函数前乘上一个 weight，即 \(R(\tau^n)\)。</p> <p>另外，考虑 baseline 的话，Expected Reward 的 gradient 就变为 \(\nabla \bar{R_{\theta}} = \frac{1}{N} \sum\limits^N_{n=1} \sum\limits^{T_n}_{t=1} (R(\tau^n) - b) \nabla \log p_{\theta}(a^n_t \mid s^n_t)\)，\(b\) 可以取 \(E[R(\tau)]\)，\(E[R(\tau)]\) 是会随着 training 不断改变的，即每得到一个 \(R(\tau^n)\)，其值就会更新。</p> <p>对于一个 \(\tau\) 中的所有 action 都赋予相同的权重（\(R(\tau^n)-b\)）看似并不合理，一个做法是用 \(\sum\limits^{T_n}_{t=t'} r^n_{t'}\) 替换 \(R(\tau^n) = \sum\limits^{T_n}_{t=1} r^n_t\)，防止在这个 action 发生之前的 reward 的影响，认为只有在这个 action 发生之后的所有 reward 是与它有关的。更进一步，加一个 discount factor \(\gamma &lt; 1\) 减小离 \(t'\) 较远的 reward 的影响（action 对远端的 reward 的贡献会逐渐减小），即 \(\sum\limits^{T_n}_{t=t'} r^n_{t'}\) 变为 \(\sum\limits^{T_n}_{t=t'} \gamma^{t-t'} r^n_{t'}\)。因此，可以说 total reward 是 state-dependent。\((\sum\limits^{T_n}_{t=t'} \gamma^{t-t'} r^n_{t'} - b)\) 这一项也被称为 Advantage Function，用 \(A^{\theta}(s_t,a_t)\) 来表示。</p> <hr/> <p>Mentioned above is “<strong>On-policy</strong>”, i.e., <strong>the actor to train</strong> and <strong>the actor to interact</strong> is the same.</p> <p>“<strong>Off-policy</strong>” is that the two can be different. In this way, we do not have to collect data after each update, it enables the use of previously collected data. But the actor to train has to know its difference from the actor to interact. The most commonly used technique is <strong>Proximal Policy Optimization (PPO)</strong>.</p> <p><strong>Exploration</strong>：Actor 在收集数据时的随机性需要大一点，才能收集到更丰富的数据（尝试更多的 Action），因为如果有些 Action 从来没有被执行过，那根本就无法知道这个 Action 好或不好。可能的做法是：1）增大 Actor 输出的策略分布的 entropy（即概率分布更均匀），从而增大随机性（降低预测性）；2）在 Actor 的参数上加 noise。</p> <h4 id="ppo">PPO</h4> <p><a href="https://www.youtube.com/watch?v=OAKAZhFmYoI"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p><strong><span class="my-large-text">Importance Sampling</span></strong></p> <p>For \(E_{x \sim p}[f(x)] \approx \frac{1}{N} \sum^N_{i=1} f(x^i)\), \(x^i\) is sampled from distribution \(p(x)\). But if we only have \(x^i\) sampled from distribution \(q(x)\), the formula is modified to \(E_{x \sim p}[f(x)] = \int f(x)p(x)dx = \int f(x)\frac{p(x)}{q(x)}q(x)dx = E_{x \sim q}[f(x)\frac{p(x)}{q(x)}]\)，可以理解为因为变成了从 \(q(x)\) 中 sample data，所以对 sample 出来的每一笔 data 都需要乘上一个 weight \(\frac{p(x)}{q(x)}\) 来修正这两个分布之间的差异。实作上，<strong>这两个分布之间的差异不宜过大</strong>，如果它们之间差异过大，会导致它们的 variance 差很多，此时 sample 的次数不够多就会导致它们的 expectation 相同无法成立。公式说明：由 \(Var[X] = E[X^2] - (E[X])^2\)，有 \(Var_{x \sim p}[f(x)] = E_{x \sim p}[f(x)^2] - (E_{x \sim p}[f(x)])^2\) 和 \(Var_{x \sim q}[f(x)\frac{p(x)}{q(x)}] = E_{x \sim q}[(f(x)\frac{p(x)}{q(x)})^2] - (E_{x \sim q}[f(x)\frac{p(x)}{q(x)}])^2 = E_{x \sim p}[f(x)^2\frac{p(x)}{q(x)}] - (E_{x \sim p}[f(x)])^2\)，差距就在于第一项多乘了一项 \(\frac{p(x)}{q(x)}\)。</p> <p>利用 Importance Sampling <strong>从 On-policy 到 Off-policy</strong>，使用另外一个 actor with policy \(\pi_{\theta'}\) 与环境做互动来 sample \(\tau\) 然后用于训练 \(\theta\)，Expected Reward 的 gradient 就变为 \(\nabla \bar{R_{\theta}} = E_{\tau \sim p_{\theta'}(\tau)}[\frac{p_{\theta}(\tau)}{p_{\theta'}(\tau)} R(\tau) \nabla \log p_{\theta}(\tau)]\)，这样做可以多次利用采样得到的数据，而不是像 on-policy 一旦 \(\theta\) 更新 \(\pi_{\theta}\) 就必须重新再采样新的数据。因此，可知 objective function 为 \(J^{\theta'}(\theta) = E_{(s_t,a_t) \sim \pi_{\theta'}}[\frac{p_{\theta}(a_t \mid s_t)}{p_{\theta'}(a_t \mid s_t)}A^{\theta'}(s_t,a_t)] \approx \sum\limits_{(s_t,a_t)} \frac{p_{\theta}(a_t \mid s_t)}{p_{\theta'}(a_t \mid s_t)}A^{\theta'}(s_t,a_t)\)。</p> <p>PPO 在此基础上再加一个限制使得两个分布不能差太多。<strong>PPO-Penalty</strong> 的 objective function 为 \(J^{\theta'}_{PPO}(\theta) = J^{\theta'}(\theta) - \beta KL(\theta, \theta')\)，希望的是在训练中学出来的 \(\theta\) 和 \(\theta'\) 越像越好（最大化 objective function 需要 KL 散度尽可能小）。这里的 KL 散度指的是这两个参数所对应的 policy 输入同一个 state 输出的 action 的 distribution 之间的距离。\(\beta\) 是一个 adaptive 的惩罚项，如果 \(KL(\theta, \theta') &gt; KL_{max}\)，增大 \(\beta\)，如果 \(KL(\theta, \theta') &lt; KL_{min}\)，减小 \(\beta\)。</p> <p>还有一种 variant 是 <strong>PPO-Clip</strong>（the primary variant used at OpenAI），它的 objective function 为 \(J^{\theta'}_{PPO2}(\theta) \approx \sum\limits_{(s_t,a_t)} \min(\frac{p_{\theta}(a_t \mid s_t)}{p_{\theta'}(a_t \mid s_t)}A^{\theta'}(s_t,a_t), \text{clip} (\frac{p_{\theta}(a_t \mid s_t)}{p_{\theta'}(a_t \mid s_t)}, 1-\epsilon, 1+\epsilon)A^{\theta'}(s_t,a_t))\)。clip 函数的意思是如果第一项小于第二项就输出第二项，如果第一项大于第三项就输出第三项。<strong>具体的实现是用其简化版</strong> \(J^{\theta'}_{PPO2}(\theta) = \sum\limits_{(s_t,a_t)} \min (\frac{p_{\theta}(a_t \mid s_t)}{p_{\theta'}(a_t \mid s_t)}A^{\theta'}(s_t,a_t), \ g(\epsilon, A^{\theta'}(s_t,a_t)))\)，其中 \(g(\epsilon, A) = \begin{cases} (1+\epsilon)A &amp; A \ge 0 \\ (1-\epsilon)A &amp; A &lt; 0 \end{cases}\)。如果 \(A\) 为正，则说明这个 action 是好的，我们会希望这个 action 被采取的概率 \(p_{\theta}(a_t \mid s_t)\) 越大越好，但是不能超过 \((1+\epsilon)p_{\theta'}(a_t \mid s_t)\)，即 \(J^{\theta'}_{PPO2}(\theta) = \sum\limits_{(s_t,a_t)} \min (\frac{p_{\theta}(a_t \mid s_t)}{p_{\theta'}(a_t \mid s_t)}, (1+\epsilon)) A^{\theta'}(s_t,a_t)\)；同样地，如果 \(A\) 为负，我们会希望 \(p_{\theta}(a_t \mid s_t)\) 越小越好，但是不能小于 \((1-\epsilon)p_{\theta'}(a_t \mid s_t)\)，即 \(J^{\theta'}_{PPO2}(\theta) = \sum\limits_{(s_t,a_t)} \max (\frac{p_{\theta}(a_t \mid s_t)}{p_{\theta'}(a_t \mid s_t)}, (1-\epsilon)) A^{\theta'}(s_t,a_t)\)，从而保证两个分布差距不会太大。</p> <p>额外链接：https://spinningup.openai.com/en/latest/algorithms/ppo.html</p> <h4 id="actor-critic">Actor-Critic</h4> <p><a href="https://www.youtube.com/watch?v=kk6DqWreLeU"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Critic: Given actor \(\boldsymbol{\theta}\), how good it is when observing \(s\) (and taking action \(a\))</p> <p><strong>Value Function (or State-Value Function)</strong> \(V^{\boldsymbol{\theta}}(s)\): (is a critic) When using actor \(\boldsymbol{\theta}\), the discounted cumulative reward expects to be obtained after seeing observation \(s\).（未卜先知，提前预测 discounted cumulative reward）</p> <p>How to estimate \(V^{\boldsymbol{\theta}}(s)\)?</p> <ul> <li> <p><strong>Monte-Carlo (MC) Based Approach</strong>: The critic watches actor \(\boldsymbol{\theta}\) to interact with the environment, it will obtain a set of training data \(\{s_1, G_1'\}, \{s_2, G_2'\}, \{s_3, G_3'\}, \cdots\) for value function \(V^{\boldsymbol{\theta}}\) at the end of the episode. \(V^{\boldsymbol{\theta}}\) will be input with \(s_t\) and output \(V^{\boldsymbol{\theta}}(s_t)\), \(V^{\boldsymbol{\theta}}(s_t)\) should be as close as possible to \(G_t'\).</p> </li> <li> <p><strong>Temporal-difference (TD) Approach</strong>: There’s no need to complete the whole episode (or the episode may not be able to be completed in some cases.), just \(s_t, a_t, r_t, s_{t+1}\) is enough to update the parameters of \(V^{\boldsymbol{\theta}}\) in each episode. The goal is that \(V^{\boldsymbol{\theta}}(s)\) is as close as possible to \(G'\), so there are following relationships</p> </li> </ul> <div class="math-scroller"> $$ V^{\boldsymbol{\theta}}(s_t) = r_t + \gamma r_{t+1} + \gamma^2 r_{t+2} + \cdots \\ V^{\boldsymbol{\theta}}(s_{t+1}) = r_{t+1} + \gamma r_{t+2} + \cdots \\ V^{\boldsymbol{\theta}}(s_t) = \gamma V^{\boldsymbol{\theta}}(s_{t+1}) + r_t $$ </div> <p>Therefore, the problem is transformed into \(V^{\boldsymbol{\theta}}(s_t) - \gamma V^{\boldsymbol{\theta}}(s_{t+1})\) should be as close as possible to \(r_t\).</p> <p><strong>Version 3.5：</strong>baseline \(b\) 的一个可能的选择是 \(V^{\boldsymbol{\theta}}(s_t)\)，即 \(A_t = G_t' - V^{\boldsymbol{\theta}}(s_t)\)。实际上，由于当 actor 看到 \(s_t\) 时所采取的 action 是根据概率分布随机采样的，所以会得到多种可能的 \(G'\)，而这些 \(G'\) 的平均值（期望值）就是 \(V^{\boldsymbol{\theta}}(s_t)\) 的含义，也就是相当于平均水平。当采取特定 action \(a_t\) 时，会得到相对应的 \(G_t'\)。如果 \(A_t\) 为正，意味着动作 \(a_t\) 比平均情况更有利，反之亦然。</p> <p><strong>Version 4：</strong>Version 3.5 中计算 \(A_t\) 时只用了在 state \(s_t\) 下某个特定 action 的 \(G_t'\)，忽略了其他的可能，而 \(V^{\boldsymbol{\theta}}(s_t)\) 则是考虑了所有的可能。当 \(s_t\) 进行到 \(s_{t+1}\) 后，可以把 \(V^{\boldsymbol{\theta}}(s_{t+1})\) 作为在 state \(s_{t+1}\) 下所有可能的 \(G'\) 的平均值（期望值），再加上 \(s_t\) 的 reward \(r_t\) 后，即 \(r_t + V^{\boldsymbol{\theta}}(s_{t+1})\) 就可以代表在 state \(s_t\) 下考虑到了所有的可能后的 \(G_t'\)。最后考虑到折扣因子 \(\gamma\)，<strong>最终的公式为</strong> \(A_t(s_t, a_t) = r_t + \gamma V^{\boldsymbol{\theta}}(s_{t+1}) - V^{\boldsymbol{\theta}}(s_t)\)。该公式也被称为 <strong>Advantage Function</strong>，可以用于衡量<strong>在给定 state 下，采取特定 action 相比于平均情况下能带来多少额外收益，从而帮助 actor 做出更好的 action</strong>。这样当 Advantage Function 作为 Critic 时被称为 <strong>Advantage Actor-Critic (A2C)</strong>。Tip：由于 Actor 和 Critic 的输入是同一个 \(s\)，所以它们可以共享网络前面几层的参数。</p> <blockquote> <p>基础的 Actor-Critic 是用 Action-Value Function 来作为 Critic，即 \(A^{\pi}(s, a) = Q^{\pi}(s, a) - V^{\pi}(s)\)，其中 \(Q^{\pi}(s, a)\) 就是 <strong>Action-Value Function</strong>。简单地说，\(Q^{\pi}(s, a)\) 表示在状态 \(s\) 下采取动作 \(a\) 并遵循特定策略 \(\pi\) 的<strong>期望回报</strong>，\(V^{\pi}(s)\) 表示在状态 \(s\) 下遵循特定策略 \(\pi\) 的<strong>期望回报</strong>。策略 \(\pi\) 就是 Policy Network/Agent with parameter \(\boldsymbol{\theta}\)。</p> </blockquote> <p>P.S. Deep Q Network (DQN) 只用 Critic 就可以决定选择哪个 action。</p> <p><a href="https://www.youtube.com/watch?v=o_g9JUMw1Oc">DQN Video1</a>, <a href="https://www.youtube.com/watch?v=2-zGCx4iv_k">DQN Video2</a></p> <h4 id="reward-shaping">Reward Shaping</h4> <p><a href="https://www.youtube.com/watch?v=73YyF1gmIus"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>If <strong>reward is sparse</strong>, i.e., \(r_t = 0\) in most cases, we don’t know actions are good or bad. 这时可以采用 reward shaping 的方法，定义 extra reward（正或负）来指导 agent，但是不同的 action 的 extra reward 的值具体应该设为多少需要依据 <strong>domain knowledge</strong> 来保证设置的正确。</p> <p><strong>Curiosity-based reward shaping:</strong> Obtaining extra reward when the agent sees something new (but meaningful). agent 被激励去探索更多未知的环境，学习更多 state 和 action 的组合（\(\{s, a\}\)），从而加速学习过程。</p> <p>适用情况：例如下围棋是只有结尾才能判断输或赢，即只有 \(r_N\) 才有分数，分子生成也可以是这样，只有生成完整个分子才能判断是好还是坏。（用最原始的方法也可以做，那就是如果 \(r_N\) 是好的，那之前一连串的 Action 都算是好的，反之亦然。）</p> <h4 id="no-reward">No Reward</h4> <p><a href="https://www.youtube.com/watch?v=75rZwxKBAf0"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>In some cases, define reward is challenging and <strong>hand-crafted rewards (reward shaping) can lead to uncontrolled behavior</strong>.</p> <p><strong>Imitation Learning</strong></p> <p>Actor can interact with the environment, but reward function is not available. 取而代之的是，用专家示范（demonstration of the expert）来引导 Agent 的学习过程。专家示范通常是一系列 trajectory \(\{\hat{\tau}_1, \hat{\tau}_2, \cdots, \hat{\tau}_K \}\)，每个 trajectory 就是一系列状态 \(s\) 和在这些状态下采取的动作 \(a\) 对 \(\{s_1, \hat{a}_1, s_2, \hat{a}_2, \cdots \}\)。Agent 的学习过程可以通过 Supervised Learning 来实现，即尝试学习一个函数，可以映射状态到动作，以最小化其行为 \(a_t\) 与专家行为 \(\hat{a}_t\) 之间的差异，这样的做法叫做 <strong>Behavior Cloning</strong>。</p> <p>但是这样做的问题是专家示范中可能只包含了有限的情况，有更多罕见的情况如果 Agent 没有学过它就可能会不知道如何处理，从而能力会受到限制。另一个问题是。Agent 会复制专家的每一个行为，甚至是和目标不相关的行为，甚至如果 Agent 学到的只是专家的一部分行为，而不是全部，有可能学到的这些行为反而是那些没用的，会导致其能力大打折扣。</p> <p><strong>Inverse Reinforcement Learning (IRL)</strong></p> <p>既然人定的 reward 会有问题，那就让机器自己去定。</p> <p>IRL 的做法是从专家示范和 Environment 中学出 Reward Function。然后再将其用到 RL 中去学出 Actor。学出来的 Reward Function 可能很简单，但不代表由它学出来的 Actor 也是简单的。</p> <p>IRL 遵循的原则是：The expert is always the best。</p> <p>基本的步骤是：</p> <ul> <li>Initialize an actor \(\pi\)</li> <li> <p>In each iteration</p> <ul> <li> <p>The actor interacts with the environments to obtain some trajectories \(\{\tau_1, \tau_2, \cdots, \tau_K \}\)</p> </li> <li> <p>Define a reward function \(R\), which <strong>assigns higher reward to the trajectories of the expert than to those of the actor</strong> \(\sum^K_{n=1}R(\hat{\tau}_n) &gt; \sum^K_{n=1}R(\tau)\)</p> </li> <li> <p>The actor learns to maximize the reward based on the new reward function by RL</p> </li> </ul> </li> <li>Output the <strong>reward function</strong> and the <strong>actor</strong> learned from the reward function</li> </ul> <p>IRL 和 GAN 有异曲同工之妙，IRL 的 Actor 就是 GAN 的 Generator，Reward Function 就是 Discriminator。</p> <h3 id="12-lifelong-learning">12. Lifelong Learning</h3> <p>也可以叫做 Continual Learning。</p> <p><strong>Catastrophic Forgetting</strong>：机器学习了新的任务后就忘记了如何解决旧的任务，但机器是有足够的能力同时很好地解决新和旧的任务。</p> <p>一个可行的解决方案是 <span id="multi-task"><strong>Multi-Task Learning</strong>（把多个任务的有标记的训练数据合并当作一个任务进行训练）</span>，但是如果任务数过多，再学习新的任务则需要把之前学过的所有任务再看一遍，<strong>效率低</strong>且可能会导致 Storage issue 和 Computation issue。（相当于每次学习新知识前都要先复习，效果肯定好但是效率会低）</p> <p><strong>Multi-Task Learning can be considered as the upper bound of Lifelong Learning.</strong></p> <p>为什么不一个任务训练一个模型呢？我们希望最终的模型是可以胜任多种不同的任务，既然人脑可以，那为什么机器不行呢？而且一个任务训练一个模型就没办法从其他任务中学到从单一任务中无法学到的信息。<strong>和 Transfer Learning 相比，两者的关注点不同。</strong>Transfer Learning 关注的是机器在旧的任务上学到的知识能不能对新的任务有所帮助，我们在乎的是<strong>机器能否胜任新的任务</strong>；Lifelong Learning 关注的则是当机器学完新的任务后是否忘记了旧的任务，我们在乎的是<strong>机器还能否胜任旧的任务</strong>。</p> <h4 id="evaluation">Evaluation</h4> <p><a href="https://www.youtube.com/watch?v=rWF9sg5w6Zk"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>First of all, we need a bunch of tasks.</p> <div class="md-img"><img src="/assets/img/DL-img/lll1.png" alt="lll1" style="zoom:35%;"/></div> <p>\(R_{i, j}\): after training task \(i\), performance on task \(j\).</p> <p>If \(i &gt; j\): after training task \(i\), does task \(j\) be forgot.</p> <p>If \(i &lt; j\): task \(j\) has not been learned yet, can we transfer the skill of task \(i\) to task \(j\).</p> <p>Evaluation method:</p> <ul> <li>\(\text{Accuracy} = \frac{1}{T}\sum^T_{i=1}R_{T,i}\)，即在机器学完所有任务后，评估其在之前任务上的表现。</li> <li>\(\text{Backward Transfer} = \frac{1}{T-1}\sum^{T-1}_{i=1}R_{T,i}-R_{i,i}\)，即比较机器在学完所有任务后在某个任务上的表现与刚学完那个任务时的表现，从而评估当前遗忘的程度。这个值通常是负的，因为目前还是避免不了机器的遗忘，更不用提能够触类旁通使后来的表现比之前还有所提升。</li> <li>\(\text{Forward Transfer} = \frac{1}{T-1}\sum^{T}_{i=2}R_{i-1,i}-R_{0,i}\)，即在还没有看到某个任务时，机器依照之前学习过的任务可以对该任务学出什么样的结果。</li> </ul> <h4 id="regularization-based-approach">Regularization-based Approach</h4> <p><a href="https://www.youtube.com/watch?v=Y9Jay_vxOsM"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Why Catastrophic Forgetting?</p> <p>当模型在新任务上训练时，共享的权重会被更新以最小化新任务的损失。这些更新可能会破坏之前学到的、对旧任务有用的权重配置，导致遗忘。所以可能解决的办法是对参数加一些限制。</p> <p><strong>Basic idea:</strong> Some parameters are important to the previous tasks, so only change the unimportant parameters.</p> <p><strong>The new loss function is</strong> \(L'(\boldsymbol{\theta}) = L(\boldsymbol{\theta}) + \lambda\sum_ib_i(\theta_i - \theta^b_i)^2\)</p> <p>\(L'(\boldsymbol{\theta})\) is the loss function to be optimized, \(L(\boldsymbol{\theta})\) is the loss function for current task, \(\theta_i\) is the parameters to be learning, \(\theta^b_i\) is the parameters learned from previous tasks, \(i\) means the \(i\)-th parameter of \(\boldsymbol{\theta}\) or \(\boldsymbol{\theta^b}\), \(b_i\) is how important the parameter \(\theta^b_i\) is. If \(b_i\) is large, indicating that we hope \(\theta_i\) will be as close as possible to \(\theta^b_i\), i.e., \(\theta^b_i\) is important.</p> <p>\(\boldsymbol{\theta}\) should be close to \(\boldsymbol{\theta^b}\) in certain directions.</p> <p>\(b_i\) 的值通常是人为设定的，一个可能的做法是在模型训练好后观察 \(\boldsymbol{\theta^b}\) 在各个方向上移动是否对 loss 有明显的影响，从而决定 \(b_i\) 的大小。\(b_i\) 的值趋于 0，意味着对参数 \(\theta_i\) 的更新没有限制，会造成 Catastrophic Forgetting，导致遗忘掉旧任务；\(b_i\) 的值趋于无穷大，意味着参数 \(\theta_i\) 没有被更新，会造成 Intransigence，导致没有学到新任务。</p> <p>设定 \(b_i\) 的方法：<a href="https://arxiv.org/abs/1612.00796">Elastic Weight Consolidation (EWC)</a>, <a href="https://arxiv.org/abs/1703.04200">Synaptic Intelligence (SI)</a>, <a href="https://arxiv.org/abs/1711.09601">Memory Aware Synapses (MAS)</a>, etc.</p> <h4 id="memory-reply">Memory Reply</h4> <p>在训练旧任务的 classifier 时同时训练一个 <strong>generator</strong>，这个 generator 的任务是学习并生成旧任务的数据分布，然后在训练新任务时把这些生成的数据喂给新的 classifier 来避免 Catastrophic Forgetting。挑战在于需要额外的计算资源和保证生成数据的质量。</p> <hr/> <p>P.S. 上述只是 LLL 的其中一种情景，更多请参照 <a href="https://arxiv.org/abs/1904.07734">Three scenarios for continual learning</a>。</p> <p>P.S. 改变任务学习的顺序也会影响结果。研究哪种才是正确的顺序是 <strong>Curriculum Learning</strong> 关注的问题。Curriculum Learning 的基本原理是模仿人类的学习过程，即先从简单的任务（样本）开始学习，逐渐过渡到更复杂的任务（样本）。</p> <h3 id="13-network-compression">13. Network Compression</h3> <p>Deploying ML models in resource-constrained environments.</p> <h4 id="network-pruning">Network Pruning</h4> <p><a href="https://www.youtube.com/watch?v=utk3EnAUh-g"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Networks are typically over-parameterized.</p> <div class="math-scroller"> $$ \text{Pre-trained Network (Large)} \longrightarrow \text{Evaluate the Importance} \longrightarrow \text{Remove Parameters (or Neurons)} \longrightarrow \text{Fine-tune} \longrightarrow \text{Re-evaluate} \xrightarrow[]{\text{After several loops}} \text{Smaller Network} $$ </div> <p>Evaluate the Importance:</p> <ul> <li> <p>Importance of a weight: absolute values, LLL \(b_i\), etc.</p> </li> <li> <p>Importance of a neuron: the number of times it wasn’t zero on a given data set, etc.</p> </li> </ul> <p>After pruning, the accuracy will drop (hopefully not too much). So we need to fine-tune on training data for recover. After fine-tuning, we can re-evaluate the importance and do the loop many times. Notably, don’t prune too much at once, or the network won’t recover.</p> <p><strong>If we use weight pruning, there may be a practical issue.</strong> Because the nerwork architecture will become irregular, resulting in it being hard to implement (e.g., by PyTorch) and hard to speedup by GPU (hard to do matrix multiplication). 所以实际上做的时候为了可行性也是把 pruned weight 设为 0，而不是不存在，但是这样 network 其实并没有变小，速度也没有变快。</p> <p><strong>If we use neuron pruning, it will be easy to implement and speedup.</strong> 比如在 PyTorch 中只需要改输入和输出的 dimension 即可。</p> <hr/> <p><span sclass="my-large-text">Why Pruning? - <strong>Lottery Ticket Hypothesis</strong></span></p> <p>首先随机初始化一个大的 Network 的参数，然后训练它并经过 Pruning 后可以成功得到一个小的 Network，再将这个小的 Network 的参数变成随机初始化的，然后训练这个小的 Network 发现训练不起来。但是，如果这里小的 Network 随机初始化的参数用的是相对应的之前大的 Network 随机初始化的那个参数，反而就能够成功训练。所以，可以解释为这一组能够成功训练的随机初始化参数就是抽到的那个能够中奖的彩票，所以如果重新随机初始化，就很难再抽到了。因此，<strong>Network 可以从大变小，但从小变大很难达到同样的表现。</strong></p> <h4 id="knowledge-distillation">Knowledge Distillation</h4> <p><a href="https://www.youtube.com/watch?v=xrlbLPaq_Og"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Knowledge Distillation 中有一个大的 Network 叫做 Teacher Network 和一个小的 Network 叫做 Student Network。这里的 Student Network 是要根据 Teacher Network 来学习的。具体来说，给 Teacher Network 一个输入，它会给出一个输出，然后给 Student Network 同样的输入，要求它的输出要和 Teacher Network 的输出越接近越好（minimize cross-entropy）。这里的 Teacher Network 可以不仅仅是单一的 Network，也可以是 N 个 Network 的 Ensemble。</p> <p><strong><span class="my-large-text">Temperature for softmax</span></strong></p> \[y'_i = \frac{exp(y_i)}{\sum_jexp(y_j)} \longrightarrow y'_i = \frac{exp(y_i/T)}{\sum_jexp(y_j/T)}\] <p>如果 \(T &gt; 1\)，可以让原本的输出分布更平滑一点。例如用原本的 softmax，如果是 \(y_1 = 100, y_2 = 10, y_3 = 1\)，那么经过 softmax 后的输出为 \(y'_1 = 1, y'_2 \approx 0, y'_3 \approx 0\)，按照这样的结果 Student 就无法从 Teacher 那里学到各个类别之间不同的程度有多大，而是跟直接从正确答案学是一样的。但是如果加上 Temperature，令 \(y_1/T = 1, y_2/T = 0.1, y_3/T = 0.01\)，softmax 的输出就会变成 \(y'_1 = 0.56, y'_2 = 0.23, y'_3 = 0.21\)，分类结果的排序不会变但是会变得平滑，这样 Student 会学得更好。\(T\) 是一个 hyperparameter，也不能设太大，否则所有 class 的分数就会变得差不多。</p> <p>也可以拿 softmax 前的输出做训练，或者 Network 的每一层的输出都可以拿来做训练，比如 Teacher Network 有 12 层，Student Network 有 6 层，可以让 Student 的第 6 层像 Teacher 的第 12 层，Student 的第 3 层像 Teacher 的第 6 层，等等，这样比较多的限制往往会得到更好的结果。</p> <p>如果 Student 和 Teacher 差太多的话，还可以创建一个或多个中间大小的网络来进行逐步学习，这些网络介于大型的 Teacher Network 和小型的 Student Network 之间，先让中间网络学习 Teacher，再让 Student 学习这个中间网络。</p> <h4 id="parameter-quantization">Parameter Quantization</h4> <ol> <li> <p>Storing each weight with fewer bits, so it can decrease the size of the model and reduce the use of computational resources.</p> </li> <li> <p>Weight Clustering. 对模型增加了限制，可能会防止过拟合，从而提升模型的表现（Binary Weights）。</p> </li> <li> <p>Represent frequent clusters by less bits, represent rare clusters by more bits.</p> </li> </ol> <h4 id="architecture-design">Architecture Design</h4> <p><strong><span class="my-large-text">Depthwise Separable Convolution</span></strong></p> <ol> <li> <p><strong>Depthwise Convolution</strong></p> <p>有几个 channel 就有几个 filter，且每个 filter 只负责一个 channel（标准的 CNN 中 filter 的 channel 数需要与作为输入的 feature map 的 channel 数相同，且 filter 的数目不是固定的），但是这样就忽略了不同 channel 之间的关系。</p> </li> <li> <p><strong>Pointwise Convolution</strong></p> <p>用一堆 1x1 的 filter 去扫 Depthwise Convolution 后产生的 feature map（这里的 filter 同标准的 CNN 一样，它的 channel 数与要扫的 feature map 相同）来考虑不同 channel 之间的关系。</p> </li> </ol> <p>用 \(I\) 代表输入的 channel 数，\(O\) 代表输出的 channel 数，\(k \times k\) 代表 kernel size。标准的 CNN 的参数量是 \(k \times k \times I \times O\)，Depthwise Separable Convolution 的参数量是 \(k \times k \times I + I \times O\)，所以可计算两者的比值为 \(\frac{k \times k \times I + I \times O}{k \times k \times I \times O} = \frac{1}{O} + \frac{1}{k \times k}\)，\(O\) 通常较大（e.g., 128, 256）所以第一项很小可忽略，那么 kernel size 设为多少，Network 的大小就变为原来的几分之一。</p> <p><a href="https://arxiv.org/abs/1610.02357">Paper - Xception</a></p> <h4 id="dynamic-computation">Dynamic Computation</h4> <p>The network can freely adjust the computational resources it requires (e.g., different devices).</p> <ol> <li> <p><strong>Dynamic Depth</strong></p> <p>在 Network 的每一层之间再加上一个 Extra Layer，这个 Extra Layer 的作用是根据上一个 Hidden Layer 的输出来决定目前的分类结果是什么，这样当运算资源不充足时可以让 Network 自己决定在哪一层做输出。将每一个 Extra Layer 的输出和最终输出与 ground truth 的距离（cross-entropy）加起来作为 loss \(L = e_1 + e_2 + \cdots + e_N\)，然后 minimize \(L\) 即可。这个方法是可行的，更好的做法见 <a href="https://arxiv.org/abs/1703.09844">Multi-Scale Dense Network (MSDNet)</a>。</p> </li> <li> <p><strong>Dynamic Width</strong></p> <p>对同一个 Network 选择不同的宽度（神经元的数量 / dims）各得到一个输出，分别计算出 cross-entropy，加起来作为 loss。更好的做法见 <a href="https://arxiv.org/abs/1812.08928">Slimmable Neural Networks</a>。</p> </li> </ol> <h3 id="14-meta-learning">14. Meta-Learning</h3> <p><strong>Learning to learn</strong> 学习如何学习 and 万物皆可（在 Network 的任意 Component 中，只要是由人类设计出来的算法都可以尝试用 Meta-Learning 去学，以此作为替代品来达到相同的目标）</p> <blockquote> <p><a href="https://ai.stanford.edu/~cbfinn/"><strong>Chelsea Finn</strong>, Stanford</a>, <a href="https://wangyaqing.github.io/">Yaqing Wang, Baidu</a></p> </blockquote> <hr/> <p>超参数通常在学习开始之前需要手动选择和调整（依据经验、网格搜索、随机搜索、贝叶斯优化等），需要一定的时间和计算资源，这些超参数是不是也可以是模型自己学习的呢？这就是 Meta-Learning 想要解决的问题。</p> <p>手动设置超参数相当于“我”指导模型“如何去学习”，即使是像网格搜索这样的超参数调优策略，也只是相当于一个“超进化的我”在指导，整个过程依然是外部的、机械的，模型本身并没有参与超参数的选择，只是在被动的接受这些超参数。而元学习相当于让模型有能力”自己思考如何去学习“，使得模型能够根据不同的任务自动优化学习策略，即<strong>自动调整超参数</strong>，从而在新的、未知的任务上快速有效地学习和泛化（也有机会跳出思维的局限性）。</p> <hr/> <h4 id="meta-learning-framework-also-3-steps"><span id="episode">Meta-Learning Framework (Also 3 Steps)</span></h4> <p><a href="https://www.youtube.com/watch?v=xoastiYx9JU"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <div class="math-scroller"> $$ \text{Training Data (input)} \longrightarrow \text{Learning Algorithm} \ F \longrightarrow \text{Classifier} \ f^* \ \text{(output)} \\ \text{Test Data (input)} \longrightarrow \text{Classifier} \ f^* \longrightarrow \text{Class (output)} $$ </div> <p>Classifier \(f^*\) is <strong>learned from training data</strong>, Learning Algorithm \(F\) is <strong>hand-crafted</strong>. Considering \(F\) is also a function, can we still learn it?</p> <p><strong><span class="my-large-text">Training</span></strong></p> <ol> <li> <p><strong>What is learnable in a learning algorithm?</strong></p> <p>Gradient Descent Components (e.g., initialization parameters, optimization algorithm, network architecture). These can all be considered as “hyperparameters”, and we use \(\boldsymbol{\phi}\) to represent these learnable hyperparameters.</p> <p>不同的 Meta-Learning 方法其实就是基于想要学习的 hyperparameters 的不同来分类（<strong>Learning to Initialize</strong>，<strong>Learning to Optimize</strong>，<strong>Learning to Compare</strong>）。<a href="#meta_categories">What can we “meta learn”?</a></p> </li> <li> <p><strong>Define loss function for learning algorithm \(F_{\boldsymbol{\phi}}\)</strong></p> <p>Loss \(L(\boldsymbol{\phi})\) is a function of learnable hyperparameters \(\boldsymbol{\phi}\). In traditional ML, loss function \(L(\boldsymbol{\theta})\) is computed based on training data. However, <strong>loss function \(L(\boldsymbol{\phi})\) is computed based on test data of training tasks in Meta-Learning</strong>. Each training task has its own training data and test data, which are typically called the <strong>support set</strong> and <strong>query set</strong>, respectively.</p> <p>Feed the support set of task 1 as input into \(F_{\boldsymbol{\phi}}\), which then outputs a classifier \(f_{\boldsymbol{\theta^{1*}}}\). Here, \(\boldsymbol{\theta^{1*}}\) represents the parameters of the classifier \(f_{\boldsymbol{\theta^{1*}}}\) that are learned by \(F_{\boldsymbol{\phi}}\) through <strong>minimizing the loss function \(L(\boldsymbol{\theta})\) using the support set</strong>. We still don’t know whether the classifier \(f_{\boldsymbol{\theta^{1*}}}\) is good or bad, so it should <strong>be evaluated on the query set</strong> of task 1. To do this, we calculate the distance or difference (e.g., cross-entropy) between the output of \(f_{\boldsymbol{\theta^{1*}}}\) for each sample in the query set and the corresponding ground truth. <strong>Summing over these distances yields the loss \(l^1\) of task 1</strong>. Obviously, the smaller \(l^1\), the better \(f_{\boldsymbol{\theta^{1*}}}\), and the better \(F_{\boldsymbol{\phi}}\).</p> <p>Hence, \(L(\boldsymbol{\phi}) = \sum^N_{n=1}l^n\), \(N\) is the number of the training tasks.</p> </li> <li> <p><strong>Optimization</strong></p> <p>Find \(\boldsymbol{\phi}\) that can minimize \(L(\boldsymbol{\phi})\), i.e., \(\boldsymbol{\phi^*} = \arg \min\limits_{\boldsymbol{\phi}} L(\boldsymbol{\phi})\).</p> <p>\(L(\boldsymbol{\phi})\) is usually not differentiable, so we need to use <strong>RL or Evolutionary Algorithm (e.g., GA)</strong> to find \(\boldsymbol{\phi^*}\). Then we’ll have a learned “learning algorithm” \(F_{\boldsymbol{\phi^*}}\).</p> </li> </ol> <p><strong><span class="my-large-text">Testing</span></strong></p> <p>After training, we use <strong>test tasks</strong> for testing. <strong>Each test task also consists of a support set and a query set</strong>. Feed the support set of test task 1 as input into \(F_{\boldsymbol{\phi^*}}\), which then outputs a classifier \(f_{\boldsymbol{\theta^{1*}}}\) (i.e., it’s a within-task training). By applying this classifier to the query set of test task 1, we can obtain the predicted class. Notably, training tasks do not overlap with test tasks. Usually, the support set of test tasks <strong>only needs a little labeled data</strong>.</p> <hr/> <p><strong><span class="my-large-text" id="meta_categories">What can we “meta learn”?</span></strong></p> <ol> <li><strong>Model Parameters (suitable for Few-shot framework)</strong> <ul> <li>Initialization Parameters (<a href="#Learning to Initialize (Optimization-based) :star:">Learning to Initialize</a>)</li> <li>Embeddings / Representations (<a href="#Learning to Compare (Metric-based) :star:">Learning to Compare</a>)</li> <li>Optimizers (<a href="#Learning to Optimize">Learning to Optimize</a>)</li> <li>Policies (<a href="#Meta-Reinforcement Learning">Meta-RL</a>)</li> </ul> </li> <li><strong>Hyperparameters</strong> <ul> <li>Hyperparameters Search <a href="https://www.youtube.com/watch?v=kyX29rUntjM"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></li> <li><a href="#Neural Architecture Search">Neural Architecture Search</a></li> <li><a href="#AutoML">AutoML</a></li> </ul> </li> </ol> <hr/> <p><strong><span class="my-large-text">Meta-Learning v.s. Few-Shot Learning</span></strong></p> <p><strong><u>Few-Shot Learning 是目标，Meta-Learning 是达成目标的手段。</u></strong></p> <p>Few-Shot Learning 更专注于目标，即希望模型在只有非常少量数据（<strong>N-way K-shot</strong>, i.e., N classes and each has K examples）的情况下就可以有效的学习和预测。而 Meta-Learning 更专注于算法，即学习一种通用的 Learning Algorithm 可以帮助模型快速适应新任务。不过，目前如果想要达成 Few-Shot Learning 的目标，所使用的算法往往不是人类可以想出来的，通常都是用 Meta-Learning 得到的。</p> <p><strong>N-way K-shot 的可行性方案：</strong></p> <p>假设有 10 个端点（二分类，N=2）的数据集，先将这些端点划分为训练的端点和测试的端点（比如 8:2），然后从训练的端点中随机采样出一个端点，再从这个端点的中随机采样出 K 个样本，这样就构成了一个训练任务，每个任务都含有 N*K 个样本。不同训练任务之间的样本是可以重复的，也就是说，某些样本可能会在多个训练任务中出现。测试同理，并且在确保任务不重复的前提下，测试任务和训练任务之间的样本也是可以重复的。</p> <hr/> <p><strong><span class="my-large-text">Meta-Learning v.s. Machine Learning</span></strong></p> <table> <thead> <tr> <th style="text-align: center">Machine Learning</th> <th style="text-align: center">Meta-Learning</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">find a function \(f\)</td> <td style="text-align: center">find a function \(F\) that is able to find \(f\)</td> </tr> <tr> <td style="text-align: center">Within-task Training / Testing</td> <td style="text-align: center">Across-task Training / Testing</td> </tr> <tr> <td style="text-align: center">\(L(\boldsymbol{\theta}) = \sum^K_{k=1}e_k\)<br/>Sum over training examples in one task</td> <td style="text-align: center">\(L(\boldsymbol{\phi}) = \sum^N_{n=1}l^n\)<br/>Sum over test (query) examples in one task and then sum over training tasks</td> </tr> </tbody> </table> <p>在 Meta-Learning 上遇到同样的问题可以照搬 ML 的思路。比如解决 Overfitting 的方法就可以是 Get more training tasks 或 Task augmentation。</p> <p>Across-task training includes multiple within-task training and testing cycles. Across-task training and within-task training are also called “<strong>Outer Loop</strong>” and “<strong>Inner Loop</strong>”, respectively.</p> <p><strong><a href="#episode">Episode</a></strong>：Meta-Learning 的一个 Episode 就是指从<strong>某个任务</strong>的支持集学习并在查询集上测试的一个完整周期（Within-task Training + Within-task Testing），无论是 Training 还是 Testing，旨在模拟快速适应新任务的过程。</p> <hr/> <p><strong><span class="my-large-text">Meta-Learning v.s. Multi-Task Learning</span></strong></p> <p>Multi-Task Learning 可以同时处理多个任务，但是也仅限于此，如果要学新的任务，训练时通常需要再次利用旧任务的所有数据。而 Meta-Learning 可以快速适应新的任务。</p> <p>因此，在做 Meta-Learning 的研究时可以把 <a href="#multi-task">Multi-Task Learning</a> 的结果作为 baseline。</p> <hr/> <p><strong><span class="my-large-text">Sadly, there are still hyperparameters when learning a learning algorithm.:joy:</span></strong></p> <p>希望的是暴调一波超参数后能找到一个好的 learning algorithm，它可以用在任何新的任务上，这样在新的任务上就再也不用手动调超参数了，<strong>一劳永逸</strong>。</p> <p>既然如此，那 Meta-Learning 同样应该需要 <strong>Validation Tasks</strong> 来选择它的超参数（不过一些相关的文献可能并没有，可能是两种情况，一是没调超参数，二是用了测试任务来调超参数。如果模型性能良好，后者的做法是错误的会导致结果过于乐观，前者的做法则会导致结果相对较为保守，在模型性能可以接受的情况下 ok）。</p> <hr/> <p>Meta-Learning? Domain Adaptation? Transfer Learning? <strong>不必拘泥于名字，DL 一直会有新的名字出现，真正应该关注的是这些名字背后所代表的含义</strong></p> <h4 id="learning-to-initialize-optimization-based-star">Learning to Initialize (Optimization-based) :star:</h4> <p><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p><em>初始化的好坏就好比“有的人出生就在罗马，有的人出生就是牛马”。</em></p> <hr/> <p>在传统的 DL 中，初始化参数一般都是从一个固定的分布（正态、均匀）中随机采样得到的，这可能对新的任务来说并不是一个好的出发点。因此，需要学会找到一组通用的初始化参数，经过少量数据的少量更新后即可适应新任务，即 <span class="my-yellow-text">\(\boldsymbol{\phi} = \boldsymbol{\theta^0}\)</span>。</p> <p><a href="https://arxiv.org/abs/1703.03400"><strong>MAML</strong> (Model-Agnostic Meta-Learning)</a>, <a href="https://arxiv.org/abs/1803.02999"><strong>Reptile</strong></a>, <a href="https://arxiv.org/abs/1707.09835"><strong>Meta-SGD</strong></a>, <a href="https://arxiv.org/abs/1810.09502"><strong>MAML++</strong> (How to train your MAML)</a></p> <h5 id="maml">MAML</h5> <p>The loss function \(L(\boldsymbol{\phi}) = \sum^N_{n=1}l^n(\boldsymbol{\theta^{n*}})\) is the same as the framework mentioned above, and it uses <strong>gradient descent</strong> to minimize \(L(\boldsymbol{\phi})\), i.e., \(\boldsymbol{\phi} \leftarrow \boldsymbol{\phi} - \eta \nabla_{\boldsymbol{\phi}} L(\boldsymbol{\phi})\).</p> <p>Considering <strong>one-step training</strong> for task \(n\) (i.e., we obtain the final parameters \(\boldsymbol{\theta^{n*}}\) only after one update): \(\boldsymbol{\theta^{n*}} = \boldsymbol{\phi} - \varepsilon \nabla_{\boldsymbol{\phi}} l^n(\boldsymbol{\phi})\)</p> <p>The reasons of choosing one-step training: 1) Fast; 2) Limited training data; 3) This is the objective of MAML; 4) You can still update many times when testing.</p> <p><strong>Implementation:</strong> <a href="https://www.youtube.com/watch?v=3z997JhL9Oo"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <ol> <li>Sample a training task \(a\) (or a task mini-batch), and after one update (\(\boldsymbol{\theta^{a*}} = \boldsymbol{\phi^0} - \varepsilon \nabla_{\boldsymbol{\phi^0}} l^a(\boldsymbol{\phi^0})\)), we can obtain \(\boldsymbol{\theta^{a*}}\) from \(\boldsymbol{\phi^0}\);</li> <li>Update once more, we can obtain the gradient \(\nabla_{\boldsymbol{\theta^{a*}}} l^a(\boldsymbol{\theta^{a*}})\) when parameter is \(\boldsymbol{\theta^{a*}}\), \(- \nabla_{\boldsymbol{\theta^{a*}}} l^a(\boldsymbol{\theta^{a*}})\) is the direction of \(\boldsymbol{\phi^0}\) update, \(l^a(\boldsymbol{\theta^{a*}})\) is used to calculate \(L(\boldsymbol{\phi^0})\).</li> <li>Update \(\boldsymbol{\phi^0}\) by gradient descent (\(\boldsymbol{\phi^1} = \boldsymbol{\phi^0} - \eta \nabla_{\boldsymbol{\phi^0}} L(\boldsymbol{\phi^0})\)), we can obtain \(\boldsymbol{\phi^1}\).</li> <li>Sample another training task \(b\) to update \(\boldsymbol{\phi^1}\) to \(\boldsymbol{\phi^2}\).</li> </ol> <p>因为用 \(\nabla_{\boldsymbol{\phi}}\) 来更新参数时需要计算二次微分，所以 MAML 使用了一阶近似（first-order approximation）来简化计算（直接令二阶微分项的值为 0，得 \(\nabla_{\boldsymbol{\phi}} = \nabla_{\boldsymbol{\theta^{n*}}}\)），这个变种算法被称为 <strong>FOMAML</strong> (First-Order MAML)。<a href="https://www.youtube.com/watch?v=mxqzGwP_Qys"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p>Why MAML is good? 论文 <a href="https://arxiv.org/abs/1909.09157"><strong>ANIL</strong> (Almost No Inner Loop)</a> 提出了两种可能：1）Rapid Learning（MAML 找到的通用的初始化参数很 powerful，因此可以快速地找到每个任务所对应的好的初始化参数）；2）Feature Reuse（MAML 找到的通用的初始化参数已经很接近每个任务所对应的好的初始化参数），并认为是第二种可能。</p> <p><strong>MAML v.s. Transfer Learning (Pre-trained Model)</strong> <a href="https://www.youtube.com/watch?v=vUwOA3SNb_E">Timestamp - 6:27</a></p> <p>对于 MAML，我们并不关心我们要找的初始化参数 \(\boldsymbol{\phi}\) 在训练任务上的表现如何，我们关心的是用 \(\boldsymbol{\phi}\) 训练出来的 \(\boldsymbol{\theta^*}\) 的表现如何。例如 \(\boldsymbol{\phi}\) 可能在训练任务 \(n\) 上表现不好，但是却可以很容易地通过 gradient descent 找到一个让 \(l^n(\boldsymbol{\theta^{n*}})\) 很小的 \(\boldsymbol{\theta^{n*}}\)。（潜力 / 读博）</p> <p>对于 Transfer Learning（\(L(\boldsymbol{\phi}) = \sum^N_{n=1}l^n(\boldsymbol{\phi})\)），我们要找的初始化参数 \(\boldsymbol{\phi}\) 需要可以同时在所有的训练任务上都表现好，但并不能保证用 \(\boldsymbol{\phi}\) 去训练后一定会在每个任务上都能得到好的 \(\boldsymbol{\theta^{n*}}\)（有可能在某个任务上会卡在 local minima）。（即战力 / 工作）</p> <h5 id="reptile">Reptile</h5> <p>采样一个训练任务 \(a\)，Reptile 由 \(\boldsymbol{\phi^0}\) 到 \(\boldsymbol{\theta^{a*}}\) 的过程可以 update 很多次（MAML 通常是一次），最终两者直接连线的方向就是 \(\boldsymbol{\phi^0}\) 到 \(\boldsymbol{\phi^1}\) 的更新方向。然后再继续采样并更新。<a href="https://www.youtube.com/watch?v=9jJe2AD35P8"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <p><strong>FOMAML、Reptile 和 Pre-train 三者参数更新的比较：</strong></p> <div class="md-img"><img src="/assets/img/DL-img/maml_compare.png" alt="maml_compare" style="zoom:50%;"/></div> <h5 id="meta-sgd">Meta-SGD</h5> <p>在 MAML 中，模型参数在内循环中的更新是固定的学习率 \(\alpha\)，而在 Meta-SGD 中，每个参数都会学习一个专属的学习率 \(\alpha_{\boldsymbol{\theta}}\)，即 \(\boldsymbol{\theta^*_i} = \boldsymbol{\phi} - \alpha_{\boldsymbol{\phi}} \odot \nabla_{\boldsymbol{\phi}} \mathcal{L}_i(\boldsymbol{\phi})\)。[^符号说明]但是这样做效率并不高，相当于学了两倍的参数。</p> <h5 id="maml--bert">MAML + BERT</h5> <p>MAML learns the initialization parameters \(\boldsymbol{\phi}\) by gradient descent, <strong>but \(\boldsymbol{\phi}\) itself also needs initialization</strong>. Therefore, BERT can provide \(\boldsymbol{\phi^0}\) for MAML.</p> <p>通常，BERT 找初始化参数（预训练）的目标是让模型学习通用的语言理解能力，这与下游任务的目标存在一定差异，导致 BERT 找到的初始化参数 \(\boldsymbol{\phi}\) 不一定完全适用于下游任务（learning gap）。但是 MAML 找初始化参数的目标就是要在目标任务上具有好的表现，缺点是需要有标记的训练任务。两者各有利弊，结合或许更好（BERT + MAML &gt; BERT 在训练数据较少时效果更显著；MAML 的 \(\boldsymbol{\phi^0}\) 用 BERT 初始化也比 train from scratch 更好）。</p> <p><strong>大师的综述（2022）：</strong><a href="https://arxiv.org/abs/2205.01500">Meta Learning for Natural Language Processing: A Survey</a> <strong>3-stage Initialization</strong></p> <h4 id="learning-to-optimize">Learning to Optimize</h4> <p>在传统的 DL 中，模型的训练通常依赖于标准的优化算法（e.g., SGD, Adam）来调整模型参数，以最小化损失函数。但是这些优化算法都是人思考出来的（即预先设计好的），”Learning to Optimize” 旨在让机器自己学习一种优化算法，从而可以根据具体任务的需求自动调整优化策略，即 <span class="my-yellow-text">\(\boldsymbol{\phi} = \text{Optimizer}\)</span>。</p> <p><a href="https://arxiv.org/abs/1606.04474"><strong>LSTM</strong> (Learning to learn by gradient descent by gradient descent)</a></p> <h4 id="learning-to-compare-metric-based-star">Learning to Compare (Metric-based) :star:</h4> <p><a href="https://www.youtube.com/watch?v=yyKaACh_j3M">Metric-based Video1</a>, <a href="https://www.youtube.com/watch?v=scK2EIT7klw">Video2</a>, <a href="https://www.youtube.com/watch?v=semSxPP2Yzg">Video3</a>, <a href="https://www.youtube.com/watch?v=ePimv_k-H24">Video4</a></p> <p>前面的做法都是将训练和测试分为两个阶段，即 Learning Algorithm \(F\) 先用 Training data 训练输出 \(f^*\)，然后再用 \(f^*\) 做测试（<strong>\(F\) 负责学习，\(f^*\) 负责分类</strong>）。而 Learning to Compare 的做法是将训练和测试合并为一个阶段，即将 Training data 和 Test data 都作为 \(F\) 的输入，然后<strong>学习和分类都由 \(F\) 负责</strong>（训练 \(F\) 理解样本间的相似性或差异性，并利用这种理解来直接对新样本进行分类）。</p> <div class="math-scroller"> $$ \text{Training Data + Test Data (input)} \longrightarrow \text{Learning + Classification} \ (F) \longrightarrow \text{Class (output)} $$ </div> <p><strong><span class="my-large-text">Siamese Network</span></strong></p> <p><a href="https://www.semanticscholar.org/paper/Siamese-Neural-Networks-for-One-Shot-Image-Koch/f216444d4f2959b4520c61d20003fa30a199670a"><strong>Siamese Network</strong></a> <em>Siamese Network 实际上是一个 Binary Classification 的问题。</em></p> <pre><code class="language-mermaid">graph LR
    A(Compound A&lt;br&gt;Class: Active) --&gt;|Molecular&lt;br&gt;Representation| ML1(Machine Learning&lt;br&gt;Network)
    B(Compound B&lt;br&gt;Class: Active) --&gt;|Molecular&lt;br&gt;Representation| ML2(Machine Learning&lt;br&gt;Network)
    ML1 --&gt; E1(Embedding)
    ML2 --&gt; E2(Embedding)
    E1 --&gt; D("Similarity / Distance&lt;br&gt;(e.g., Cosine Similarity, Euclidean Distance,&lt;br&gt;Triplet Loss)")
    E2 --&gt; D
    D --&gt; O("Score&lt;br&gt;(Same Class, High Score;&lt;br&gt;Different Class, Low Score)")
</code></pre> <p>如果两个输入的模态相同 / 相似，可以考虑让两个 ML Network 之间<strong>共享参数</strong>。</p> <p>Siamese Network 将两个输入映射到同一个嵌入空间中，通过学习将相同的样本映射到空间中的相近点，将不同的样本映射到远离的点，从而可以用于判断两个输入是否相似。因此，Siamese Network 学出来的 Embedding 会包含用于分类的关键信息，而忽略那些不重要的信息（比如用于人像识别时的背景信息）。</p> <blockquote> <p>Triplet Loss：经常用在如何从输入数据中提取有用的特征以进行比较的场景中。一个 Triplet 由三部分组成：Anchor（参考数据点），Positive（与 Anchor 属于同一类别的数据点）和 Negative（与 Anchor 属于不同类别的数据点）。其思想是让 Positive 的嵌入更接近 Anchor 的嵌入，而 Negative 的嵌入更远离 Anchor 的嵌入，在训练过程中模型<strong>学习生成</strong>能够区分不同类别数据的<strong>嵌入</strong>。其公式如下：</p> \[L(A, P, N) = \max(\Vert f(A) - f(P) \Vert^2_2 - \Vert f(A) - f(N) \Vert^2_2 + margin, 0)\] <p>\(f\) 表示嵌入函数，将输入数据映射到嵌入空间，\(\Vert \cdot \Vert_2\) 表示 L2 范数（Euclidean Distance），\(A\) 表示 Anchor，\(P\) 表示 Positive，\(N\) 表示 Negative，\(margin\) 是一个超参数，用于确保 \(A\) 和 \(N\) 之间的距离至少比 \(A\) 和 \(P\) 之间的距离大一个特定的值，即确保同一类别的数据点总是更接近，用公式表示就是要满足 \(\Vert f(A) - f(P) \Vert^2_2 + margin &lt; \Vert f(A) - f(N) \Vert^2_2\)，此时，Loss 为 0。应用 Triplet Loss 时，往往需要构造难以区分的 Triplet（不容易满足上述不等式）使训练更具有挑战性，从而能够有效推动模型的学习。</p> </blockquote> <p><strong><span class="my-large-text">Prototypical Network</span></strong></p> <p><a href="https://arxiv.org/abs/1703.05175"><strong>Prototypical Network</strong></a></p> <div class="md-img"><img src="/assets/img/DL-img/proto.png" alt="proto" style="zoom:50%;"/></div> <p>对于每个 class，计算输入点的 embedding 的平均值（叫做 prototype），计算测试点与各个 prototype 的距离，将其分类到距离最近的 prototype 所在的 class。</p> <details> <summary>GPT-4 Summary</summary> Prototypical Networks 特别设计用于处理 few-shot learning 问题，其核心思想就是利用少量的样本（即“few shots”）来学习每个类别的代表性特征，称为原型（prototype）。 一、原理和应用 Prototypical Networks 通过以下步骤实现 few-shot learning： 1. 支持集（Support Set）：在每次训练或测试过程中，模型首先接收一个支持集，其中包含每个类的少量样本。这些样本数目通常很小，比如在 5-shot learning 的设置中，每个类有 5 个样本。 2. 计算原型：对于每个类，模型计算支持集中所有样本的嵌入（embedding）的平均值，这个平均值形成了该类的原型。这种方法假定类内的样本是相似的，因此通过平均化可以得到一个好的类表示。 3. 比较距离：在测试阶段，对于每一个测试样本（来自查询集，即 Query Set），模型计算其与每个类的原型之间的距离。距离可以使用欧氏距离或其他相似的度量。 4. 分类决策：测试样本被分类到与其最近的原型所代表的类别。 二、动机和优势 这种方法在 few-shot learning 场景中非常适用，因为它不需要大量的样本来进行有效的学习。通过集中于计算每个类的原型，Prototypical Networks 能够有效地总结和利用有限的数据信息。此外，原型的计算和距离的比较都是计算上非常高效的操作，使得模型即便在样本极少的情况下也能快速运作。 三、挑战 尽管 Prototypical Networks 在多个 few-shot learning 任务中表现出色，它仍然面临一些挑战，例如： 5. 类内差异性：如果一个类内部的样本差异较大，单一的原型可能不足以捕捉全部的类特性。 6. 特征表示的质量：模型的性能很大程度上依赖于输入样本特征的质量和表达能力。因此，如何有效地学习和提取特征显得尤为重要。 四、总结 Prototypical Networks 通过在支持集上为每个类计算原型，并在查询集上进行分类，为 few-shot learning 提供了一种简洁而有效的解决方案。这种方法通过聚焦于类原型的学习，使得即使在样本极其有限的情况下也能进行有效的学习和预测。 </details> <p><strong><em>Weighted Prototypical Network may be better?</em></strong></p> <p><strong><span class="my-large-text">Matching Network</span></strong></p> <p><a href="https://arxiv.org/abs/1606.04080"><strong>Matching Network</strong></a></p> <p>相比于 Prototypical Network，Matching Network 考虑输入数据之间也许是有顺序关系的，因此它的嵌入函数是 Bidirectional LSTM。但 Prototypical Network 认为改变输入数据的顺序不应该影响最后的输出结果。Prototypical Network 是后提出的，且其表现和速度都更好。</p> <p><strong><span class="my-large-text">Relation Network</span></strong></p> <p><a href="https://arxiv.org/abs/1711.06025"><strong>Relation Network</strong></a></p> <div class="md-img"><img src="/assets/img/DL-img/relation.png" alt="relation" style="zoom:50%;"/></div> <p>前面提到的 Network 计算训练样本和测试样本之间 Similarity 的方法都是由人定的，Relation Network 提出如何计算 Similarity 应该由一个 Network \(g\) 自己学出来，\(g\) 接受训练样本和测试样本拼接的 embedding 作为输入。这里的 \(g\) 和嵌入函数 \(f\) 是一起被学出来的。</p> <p><strong><span class="my-large-text">Imaginary Data</span></strong></p> <p><a href="https://arxiv.org/abs/1801.05401">Low-Shot Learning from Imaginary Data</a></p> <div class="md-img"><img src="/assets/img/DL-img/imaginary.png" alt="imaginary" style="zoom:70%;"/></div> <p>在训练数据后加一个 generator，对训练数据进行域内变换，相当于做 data augmentation，将增强后的训练数据和原训练数据合并再与测试数据输入到 Network \(F\) 中，这里的 generator 是和 \(F\) 一起学出来的。</p> <hr/> <p>像 Siamese Network 等 Learning to Compare 的 \(F\) 的架构其实都算是经过特定设计的，那 \(F\) 可不可以是一个 Generalized Network 呢？</p> <p><a href="https://arxiv.org/abs/1605.06065"><strong>MANN</strong></a>, <a href="https://arxiv.org/abs/1707.03141"><strong>SNAIL</strong></a></p> <h4 id="neural-architecture-search">Neural Architecture Search</h4> <p>在 Meta-Learning 中，如果 <span class="my-yellow-text">\(\boldsymbol{\phi} = \text{Network Structure}\)</span>，那就相当于在做 Neural Architecture Search (NAS)。对于 \(\boldsymbol{\phi^*} = \arg \min\limits_{\boldsymbol{\phi}} L(\boldsymbol{\phi})\)，因为网络架构 \(\boldsymbol{\phi}\) 是不可微分的，所以要用 RL 硬做。把 \(\boldsymbol{\phi}\) 当作是 RL 的 Agent，Agent 的输出是网络架构相关的超参数（e.g., 层数，每层的神经元数，kernel size），目标是训练 Agent 能够最大化 Reward，这里的 Reward 就设为 \(-L(\boldsymbol{\phi})\)，所以就可以相当于是最小化 \(L(\boldsymbol{\phi})\)。具体操作上，根据 Agent 的输出的超参数能构建一个网络，用训练任务的支持集去训练这个网络，然后以其在查询集上的 Accuracy 作为 Reward 来训练 Agent。</p> <h4 id="data-processing">Data Processing</h4> <p>Meta-Learning 也可以用于 Data Processing，即 <span class="my-yellow-text">\(\boldsymbol{\phi} = \text{Data Processing Strategy}\)</span>。</p> <ul> <li> <p>Data Augmentation：让机器学习如何在不同的任务上做最有效的 Data Augmentation（类型、程度、不同类型的顺序等）。</p> <p><a href="https://arxiv.org/abs/1805.09501">AutoAugment: Learning Augmentation Policies from Data</a></p> </li> <li> <p>Sample Reweighting：让机器学习根据数据的特性自己决定给予不同的样本以不同的权重，也许可以用在不平衡的数据集上。</p> <p><a href="https://arxiv.org/abs/1803.09050">Learning to Reweight Examples for Robust Deep Learning</a></p> <p><a href="https://arxiv.org/abs/1902.07379">Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting</a></p> </li> </ul> <h4 id="beyond-gradient-descent">Beyond Gradient Descent</h4> <p>上述所提到的 Meta-learning 的方法都是基于 Gradient Descent 来学习其中的一个 Component，有没有可能让机器舍弃掉 Gradient Descent，发明出全新的 Learning Algorithm，即 \(F_{\boldsymbol{\phi}}\) 仅需输入即可给出输出 \(f_{\boldsymbol{\theta^*}}\)。</p> <p><a href="https://arxiv.org/abs/1807.05960">Meta-Learning with Latent Embedding Optimization</a></p> <h4 id="automl">AutoML</h4> <p><a href="https://github.com/automl/auto-sklearn">auto-sklearn</a></p> <p><a href="https://www.automl.org/automl/">AutoML</a></p> <h4 id="meta-learning-for-active-learning">Meta-Learning for Active Learning</h4> <p>优化主动学习的样本选择策略？</p> <h4 id="meta-reinforcement-learning">Meta-Reinforcement Learning</h4> <p>优化强化学习的策略学习过程？</p> <p>RL 最耗费时间的部分在于与环境互动的过程，相当于在收集数据，所以可以用 Meta-Learning 的方法做 Few-Shot。</p> <p><a href="https://arxiv.org/abs/2301.08028">A Survey of Meta-Reinforcement Learning</a></p> <p><a href="https://paperswithcode.com/task/meta-reinforcement-learning">Papers With Code - Meta Reinforcement Learning</a></p> <p><a href="https://lilianweng.github.io/posts/2019-06-23-meta-rl/">Lil’Log - Meta Reinforcement Learning</a></p> <h4 id="meta-learning-for-gnn-star">Meta-Learning for GNN :star:</h4> <p><a href="https://arxiv.org/abs/2103.00137">Meta-Learning with Graph Neural Networks: Methods and Applications</a></p> <p><a href="https://arxiv.org/abs/2006.07889">Graph Meta Learning via Local Subgraphs</a></p> <p><a href="https://arxiv.org/abs/2306.16780">Graph Sampling-based Meta-Learning for Molecular Property Prediction</a></p> <p><a href="https://arxiv.org/abs/2402.01440">Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting</a></p> <p><a href="https://ieeexplore.ieee.org/document/10059171">Meta Learning With Graph Attention Networks for Low-Data Drug Discovery</a></p> <h4 id="meta-transfer-learning">Meta-Transfer Learning</h4> <p><a href="https://arxiv.org/abs/1812.02391">Meta-Transfer Learning for Few-Shot Learning</a></p> <h3 id="15-transfer-learning">15. Transfer Learning</h3> <p><a href="https://www.youtube.com/watch?v=qD6iD4TFsdQ"><img src="https://img.icons8.com/?size=100&amp;id=19318&amp;format=png&amp;color=000000" width="22" height="22" alt="Youtube Video"/></a></p> <h4 id="source-data-and-target-data-are-both-labeled">Source Data and Target Data are Both Labeled</h4> <p><strong><span class="my-large-text">Fine-tuning</span></strong></p> <p>There are a large amount of source data (not directly related to the task) and only a little target data. Training a model by source data as the initialization, then fine-tuning the model by target data. But be careful about overfitting.</p> <ol> <li> <p>Conservative Training</p> <p>限制用 target data 微调后的模型与用 source data 预训练的模型它们的输出或参数不要差得太多。</p> </li> <li> <p>Layer Transfer</p> <p>从预训练的模型中 copy 一些 layers，然后用 target data 去训练剩余的 layers（防止过拟合）。问题是哪些 layer 需要被 transferred（copied）？根据任务特性来定，可以 copy 的 layer 一般是能够识别通用的特征。</p> </li> </ol> <p><strong><span class="my-large-text">Multi-Task Learning</span></strong></p> <p>Fine-tuning 只关心在 target domain 上做的好不好，而 Multi-Task Learning 则同时关心 source domain 和 target domain。如果各个 task 的 input feature 是相同的，那么可以在 NN 的前几层同时使用这些 task 的数据来做训练，需要保证这些 task 之间具有共通性。如果各个 task 的 input feature 是不同的，可以先分别通过一个 NN 转移到同一个 domain 上，在这个 domain 上有些参数是可以共享的，然后再分别到一个 NN 上做分类/回归。</p> <h4 id="source-data-is-labeled-but-target-data-is-unlabeled">Source Data is Labeled but Target Data is Unlabeled</h4> <p><strong><span class="my-large-text">Domain-Adversarial Training</span></strong></p> <p>把 source data 当作 training data，target data 当作 test data，它们的 task 是一样的，但是 domain 会存在 mismatch。Domain-Adversarial Training 要做的是学一个 feature extractor，来消除 source domain 和 target domain 之间的 mismatch（通过 t-SNE 降维可以观察到不同 domain 混合在一起）。具体做法是把 feature extractor 的输出输入到一个 domain classifier 里来判断输入的 feature 来自于哪个 domain（即 feature extractor 输出的 feature 要能够使得 domain classifier 无法准确判断其来自于哪个 domain）。feature extractor 输出的 feature 同时还要保证 label predictor 的结果要好。训练时，feature extractor 要试图最小化 label predictor 的损失函数，同时最大化 domain classifier 的损失函数。</p> <p><strong><span class="my-large-text">Zero-Shot Learning</span></strong></p> <p>把 source data 当作 training data，target data 当作 test data，但是它们的 task 是不一样的。在 Zero-Shot Learning 中，需要 Represent each class by its attributes，所以会有一个 database 来储存 class 和 attribute 之间的映射关系（attribute 需要足够多），因此，NN 输出的不再是 class 而是 attribute（一个由 0 和 1 组成的向量代表各个 attribute 有无），测试时就可以 find the class with the most similar attributes。</p> <p><strong>Attribute Embedding</strong></p> <p>通过一个 NN \(f\) 将 input \(x^n\) 映射到一个 embedding space，同样地，attribute \(y^n\) 也通过一个 NN \(g\) 被映射到同一个 embedding space，希望 \(f(x^n)\) 和 \(g(y^n)\) 越接近越好。其 loss function 的形式为 \(f^*, g^* = \arg \min\limits_{f,g} \sum\limits_n \max(0, k - f(x^n) \cdot g(y^n) + \max\limits_{m \ne n}f(x^n) \cdot g(y^m))\)，如果想要 loss 为 0，则有 \(f(x^n) \cdot g(y^n) - \max\limits_{m \ne n}f(x^n) \cdot g(y^m) &gt; k\)，若此式成立，需要配对的 \(f(x^n)\) 和 \(g(x^n)\) 接近且其他不配对的 \(f(x^n)\) 和 \(g(y^m)\) 远离。</p> <h3 id="16-gnn">16. GNN</h3> <p>A node can learn the graph structure from its neighbors directly and indirectly. It can be considered as a kind of convolution, i.e., each convolution is equivalent to performing a message passing and an update for the node feature.</p> <p>The problem is how to embed the node into a feature space using convolution.</p> <h4 id="spatial-based-convolution">Spatial-based Convolution</h4> <p>直接在图的空间结构上操作，通过聚合（<strong>Aggregate</strong>）邻居节点的特征信息来更新当前节点的特征，比较灵活，适用于<strong>动态图</strong>或<strong>需要灵活定义邻居聚合方式</strong>的场景。</p> <p>Aggregation 更新的是每个节点的特征，但是如果想要的是整个图的特征（比如化学分子），就需要做 <strong>Readout</strong> 把所有节点的特征集合起来以代表整个图。</p> <table> <thead> <tr> <th style="text-align: center">Aggregation</th> <th style="text-align: center">Method</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Sum</td> <td style="text-align: center">NN4G</td> </tr> <tr> <td style="text-align: center">Mean</td> <td style="text-align: center">DCNN, DGC, <strong>GraphSAGE</strong></td> </tr> <tr> <td style="text-align: center"><strong>Weighted Sum</strong></td> <td style="text-align: center">MoNET, <strong>GAT</strong>, <strong>GIN</strong></td> </tr> <tr> <td style="text-align: center">Max Pooling</td> <td style="text-align: center"><strong>GraphSAGE</strong></td> </tr> <tr> <td style="text-align: center">LSTM</td> <td style="text-align: center"><strong>GraphSAGE</strong></td> </tr> </tbody> </table> <p><strong><span class="my-large-text">Implementation</span></strong></p> <p>分子在输入层时，首先通过用各种不同的化学性质来表示 node feature（RDKit / DGL-LifeSci），然后通过嵌入层让 node feature 变成 embedding（用 weight 做 transformation，嵌入层的权重矩阵大小为 <code class="language-plaintext highlighter-rouge">[num_nodes, embedding_dim]</code>），然后再通过任意次的 aggregation 来更新 embedding，最后做 Readout。（对于分子性质预测，一般用的是最后 readout 得到的图嵌入作为 ML 模型的输入去做下游的 Graph Classification / Regression，maybe 也可以端到端直接由 GNN 给出预测）</p> <p>像 GCN、GAT 这种作为网络的一层，可以考虑交替使用，从而允许模型在不同的层级上利用基于结构的特征聚合和基于注意力的特征聚合；或者合并它们的输出，提供更丰富的节点表示。</p> <p>GIN 适合捕捉全局图结构，可能适用于整体分子的性质；GCN、GAT 可能适用于理解分子中特定的局部结构。</p> <p><strong>常用：GCN, GAT, GIN, GraphSAGE, AttentiveFP</strong></p> <h5 id="graphsage">GraphSAGE</h5> <p><a href="https://arxiv.org/abs/1706.02216">Paper</a></p> <p>GraphSAGE (<strong>SA</strong>mple and aggre<strong>G</strong>at<strong>E</strong>) learns <strong>how to embed node features from neighbors</strong>. GraphSAGE 是归纳式（Inductive）的，它不是学习固定的图中每个节点的嵌入，而是学习一个嵌入函数，从而能够为未见过的节点生成嵌入，提高了泛化能力。</p> <ol> <li> <p>Sample: Ignore the order of neighbors for nodes</p> </li> <li> <p>Aggregation: Mean, Max Pooling, or LSTM</p> </li> </ol> <div class="md-img"><img src="/assets/img/DL-img/graphsage.png" alt="graphsage" style="zoom:45%;"/></div> <h5 id="gat">GAT</h5> <p><a href="https://arxiv.org/abs/1710.10903">Paper</a></p> <p>(Graph Attention Network) 不仅要做 Weighted Sum，并且 Weighted Sum 的 weight 是通过 Self-attention 让模型自己学到的。</p> <div class="md-img"><img src="/assets/img/DL-img/gat.png" alt="gat" style="zoom:50%;"/></div> <p>Note: 1) The weight vector \(\vec{\mathbf{a}}\) represents the parameters of a single-layer feedforward neural network; 2) The aggregated features from each head (different arrow styles denote independent heads, 3 heads here) are concatenated or averaged to obtain \(\vec{h'_1}\); 3) The multi-head attention allows for the parallel use of multiple independent attention within the same layer to update node features. 4) Terminology: The notation \(\Vert\) denotes the concatenation of vectors, \(\mathbf{W}\) denotes the weight matrix, \(\mathbf{W} \vec{h_i}\) denotes the linear transformation of \(\vec{h_i}\).</p> <h5 id="gin">GIN</h5> <blockquote> <p>Injection（单射）：从集合 \(A\) 到集合 \(B\) 的映射中，\(A\) 中的每个元素都映射到 \(B\) 中的唯一元素，不会有两个不同的元素映射到同一个元素，保证了一一对应的关系。即假设有一个函数 \(f: X \rightarrow Y\)，如果对于任意的 \(x_1, x_2 \in X\)，只要 \(x_1 \neq x_2\)，就有 \(f(x_1) \neq f(x_2)\)，那么函数 \(f\) 就是单射的。</p> </blockquote> <blockquote> <p>Surjection（满射）：从集合 \(A\) 到集合 \(B\) 的映射中，对于集合 \(B\) 中的每个元素，都至少存在一个集合 \(A\) 中的元素与之对应。即假设有一个函数 \(f: X \rightarrow Y\)，如果对于任意的 \(y \in Y\)，都存在一个 \(x \in X\) 使得 \(f(x) = y\)，那么函数 \(f\) 就是满射的。</p> </blockquote> <blockquote> <p>Bijection（双射）：集合 \(A\) 中的每个元素都与集合 \(B\) 中的唯一元素相对应，并且集合中 \(B\) 的每个元素也都与集合 \(A\) 中的唯一元素相对应，即同时满足了单射和满射的条件。</p> </blockquote> <blockquote> <p>Multiset: a set with possibly repeating elements.</p> </blockquote> <blockquote> <p><strong>Graph Isomorphism</strong>（图同构）：研究两个图在结构上是否完全相同，即<strong>两个图是否可以通过重新标记节点后变得无法区分</strong>。具体来说，给定两个图 \(G_1 = (V_1, E_1)\) 和 \(G_2 = (V_2, E_2)\)，如果存在一个双射 \(f: V_1 \rightarrow V_2\)，使得对于 \(G_1\) 中任意两个节点 \(u\) 和 \(v\)，它们之间存在边的条件是当且仅当 \(f(u)\) 和 \(f(v)\) 在 \(G_2\) 中存在边，则这两个图是同构的。图同构保留了节点和边的连接方式，但不一定保留节点或边的标签。（下图为一个简单的图同构例子，映射关系为：\(\text{A} - 3; \text{B} - 1; \text{C} - 2; \text{D} - 5; \text{E} -4\)）</p> <div class="md-img"><img src="/assets/img/DL-img/iso.png" alt="iso" style="zoom:25%;"/></div> </blockquote> <blockquote> <p><strong>Weisfeiler-Lehman test</strong>：是一种用于检测两个图是否同构的算法。WL test 基于 <strong>rooted subtree</strong>（也可以看作是一种 subgraph）考虑了每个节点及其邻域，通过迭代的方式，<strong>逐步更新图中每个节点的标签</strong>，直到达到一定的迭代次数或者所有节点的标签不再发生变化时，通过比较两个图中节点的<strong>标签分布</strong>是否相同来判断这两个图是否同构。WL test 一般是 1-dimensional 形式的，即在迭代过程中只考虑了每个节点自身及其一阶邻居的信息来更新节点的标签，并没有考虑更高阶的邻域（neighborhood）信息。下图为一个以 node 1 为根节点 height 为 2（迭代两次）的 rooted subtree。<a href="https://jmlr.csail.mit.edu/papers/v12/shervashidze11a.html">Weisfeiler-Lehman Graph Kernels</a></p> <div class="md-img"><img src="/assets/img/DL-img/subtree.png" alt="subtree" style="zoom:50%;"/></div> <p>在 GNN 的研究中，WL 测试常被用来衡量 GNN 模型的性能，<strong>一个 GNN 模型如果能够模拟 WL 测试的行为，那么就可以认为该模型能够很好地<u>捕捉图的结构信息</u>（特征提取 / 生成图的表示），从而应用于更广泛的下游任务</strong>。<a href="/assets/img/DL-img/WL test - GNN的性能上界.html" target="_blank">WL test - GNN的性能上界</a></p> </blockquote> <p><a href="https://arxiv.org/abs/1810.00826">Paper</a></p> <p>GIN (Graph Isomorphism Network) 的理论框架：</p> <div class="md-img"><img src="/assets/img/DL-img/gin1.png" alt="gin1" style="zoom:45%;"/></div> <p>一个好的 GNN 算法的<strong>聚合节点的邻域信息生成节点新的 representation 的过程应该是单射的</strong>，即永远不会将两个不同的邻域映射得到相同的 representation。对于 GIN 来说，旨在通过训练可以学习到一个近似单射的函数，使得不同的节点及其邻域信息能够被映射到特征空间中的唯一向量，即 \(h^k_v = \phi (h^{k-1}_v, f(\{h^{k-1}_u : u \in \mathcal{N}(v)\}))\)。上述公式中，\(h^k_v\) 表示节点 \(v\) 在第 \(k\) 次迭代中的特征向量；\(\phi\) 表示更新函数；\(f\) 表示聚合函数，作用于 multiset（即节点 \(v\) 所有邻居节点的特征向量所组成的集合）；\(\mathcal{N}(v)\) 表示节点 \(v\) 的邻域。</p> <p>GIN 使用 <strong>MLP</strong> 来建模和学习 \(f\) 和 \(\phi\)，使整个节点更新过程尽可能接近单射函数，而之所以用 MLP 是因为它能够近似任何连续函数的组合。\(\epsilon\) 可以是一个可学习的参数或固定的标量，用于<strong>调整节点自身特征与其邻居特征之和的贡献比例</strong>。</p> \[h^k_v = \text{MLP}^k((1 + \epsilon^k) \cdot h^{k-1}_v + \sum_{u \in \mathcal{N}(v)} h^{k-1}_u)\] <p>GIN 的 readout 的做法是对于每次迭代都使用 \(\text{READOUT}\) 函数来处理所有节点的嵌入，以生成该次迭代的图的嵌入，然后经过 \(K\) 次迭代后，将每次迭代生成的图的嵌入拼接起来作为最终的图的嵌入 \(h_G\)。这样做能够在最后的输出中捕捉到图在不同阶段的信息，而不会局限于最后一个阶段。论文中也写道 “A sufficient number of iterations is key to achieving good discriminative power. Yet, <strong>features from earlier iterations may sometimes generalize better</strong>.”，所以早期迭代的图的嵌入可能也很重要，我们不应该忽视。</p> \[h_G = \text{CONCAT}(\text{READOUT}(\{ h^k_v \mid v \in G \}) \mid k = 0,1,\dots, K)\] <p>对于 aggregation 的方式，<strong>sum 可以捕捉到 multiset 中的所有元素的完整信息</strong>；mean 可以捕捉到不同元素类型的比例或分布，但忽略了元素的具体数量（重复元素），这在需要邻域的整体性质时很有用；max 只能捕捉到最大元素的信息。因此，sum 的区分能力最强。</p> <div class="md-img"><img src="/assets/img/DL-img/gin2.png" alt="gin2" style="zoom:45%;"/></div> <h4 id="spectral-based-convolution">Spectral-based Convolution</h4> <blockquote> <p>傅里叶变换（Fourier Transform）的卷积定理：两个函数 \(x(t)\) 和 \(y(t)\) 在时域（Time Domain）的卷积等价于它们的傅里叶变换 \(X(f)\) 和 \(Y(f)\) 在频域（Frequency Domain）的乘积。乘积运算要比卷积运算简单得多，这可以帮助我们设计滤波器（filter），滤波器在频域中可以很简单地表示为乘一个函数。通过傅里叶变换，任何信号都可以表示为不同频率的正弦波和余弦波的线性组合。</p> </blockquote> <blockquote> <p>Eigenvalue Decomposition (EVD)：对于一个矩阵 \(A\)，特征值分解希望找到一组特征向量 \(u\) 和相应的特征值 \(\lambda\)，满足 \(Au = \lambda u\)。分解后，\(A\) 可以表示为 \(A = U \Lambda U^T\)，\(U = [u_0, u_1, \dots, u_{N-1}] \in \mathbb{R}^{N \times N}\) 是一个由特征向量组成的矩阵，\(\Lambda = \text{diag}(\lambda_0, \lambda_1, \dots, \lambda_{N-1}) \in \mathbb{R}^{N \times N}\) 是一个对角矩阵，其对角线上的元素是相应的特征值。</p> </blockquote> <h5 id="spectral-graph-theory">Spectral Graph Theory</h5> <p>目标：<strong>需要定义一个图的傅里叶变换，才能在图上做 filter。</strong>这个傅里叶变换涉及到将信号从图的 Vertex Domain（Time Domain）转换到 Spectral Domain（Frequency Domain）。</p> <p><strong>Terminology:</strong></p> <ol> <li> <p><strong>Graph</strong> \(G = (V,E)\), \(N = \vert V \vert\) is <strong>the number of vertices</strong>.</p> </li> <li> <p><strong>Adjacency Matrix</strong> \(A \in \mathbb{R}^{N \times N}\), \(A_{i,j} = \begin{cases} 0 &amp; \text{if } e_{i,j} \notin E \\ w(i,j) &amp; \text{else} \end{cases}\) is <strong>the weight of the edge between vertices \(i\) and \(j\)</strong>, and \(A\) is a <u>symmetric matrix</u> for an undirected graph.</p> </li> <li><strong>Degree Matrix</strong> \(D \in \mathbb{R}^{N \times N}\), \(D_{i,j} = \begin{cases} d(i) &amp; \text{if } i = j \\ 0 &amp; \text{else} \end{cases}\) is <strong>the degree of vertex \(i\)</strong>, \(d(i)\) is equivalent to the sum of row \(i\) in \(A\) (i.e., \(D_{ii} = \sum_jA_{ij}\)), and \(D\) is a <u>diagonal matrix</u>.</li> <li><strong>Signal on Graph</strong> \(f : V \rightarrow \mathbb{R}^N\), \(f(i)\) is <strong>the signal on vertex \(i\)</strong>. Specifically, the function \(f\) maps each vertex \(v \in V\) to an N-dimensional real number vector, where <strong>each dimension can represent different features or attributes of the vertex</strong>.</li> <li><strong>Graph Laplacian Matrix</strong> \(L = D - A\), when performing spectral decomposition (eigenvalue decomposition) on \(L\), i.e., \(L = U \Lambda U^T\), the obtained eigenvalue \(\lambda_i\) can be considered as the <strong>frequency of vertex \(i\)</strong>, while the eigenvector \(u_i\) corresponding to \(\lambda_i\) is the frequency-domain <strong>basis</strong>. <strong>Through these eigenvectors, it is possible to transform signals from the frequency domain back to the time domain</strong>, achieving signal reconstruction.</li> <li><strong>Nomalized Graph Laplacian Matrix</strong> \(L = I - D^{-1/2}AD^{-1/2}\), it can help to preserve the structural information of the graph while reducing the influence of varying graph sizes and node degree distributions.</li> </ol> <p>当将 Graph Laplacian Matrix 应用于图上的信号时，即 \(Lf(v_i) = \sum_{j \in \mathcal{N}(i)} w_{i,j}(f(v_i) - f(v_j))\)，这里的 \(Lf(v_i)\) 是节点 \(v_i\) 的拉普拉斯信号，反映的是能量的<strong>局部差异</strong>，即每个节点与其邻居之间的信号差异，但 \(Lf\) 的结果还是一个向量，每一行对应一个节点。</p> <div class="md-img"><img src="/assets/img/DL-img/sgt0.png" alt="sgt0" style="zoom:40%;"/></div> <p>如果要计算能量的<strong>全局差异</strong>，则需要计算 \(f^TLf = \frac{1}{2} \sum_{v_i \in V} \sum_{v_j \in V} w_{i,j} (f(v_i) - f(v_j))^2\)，这是一个点积操作，即原信号 \(f\) 的每个元素（节点自身的信号值）乘以其对应的局部差异（\(Lf\)）并求和。\(f^TLf\) 反映了<strong>整个图的信号平滑度</strong>，如果其值小，说明信号在图上相邻节点之间变化不大，信号比较平滑。<strong>信号越平滑，则频率越低</strong>。当用 \(L\) 的特征向量 \(u_i\) 替换 \(f\)，计算 \(u_i^TLu_i = \lambda_iu_i^Tu_i = \lambda_i\) 得到的是特征值 \(\lambda_i\)，即 \(\lambda_i\) 代表了能量差异，因此 \(\lambda_i\) 可以被看作是 \(u_i\) 的频率大小，较小的 \(\lambda_i\) 对应低频率，较大的 \(\lambda_i\) 对应高频率。</p> <p><strong>图的傅里叶变换依赖于图拉普拉斯矩阵的特征值和特征向量</strong>，主要由三个步骤组成：</p> <ol> <li> <p>Transform</p> <p><strong>Graph Fourier Transform</strong> of signal \(x\): \(\hat{x} = U^Tx\)，将原始信号从顶点域转换到谱域，可以得到信号 \(x\) 在各个频率 \(\lambda_i\) 上的成分（Component）大小 \(u_ix\) 是多少（\(U^T\) 的每一行对应一个特征向量 \(u_i\)，相当于信号在各个频率上的投影）。</p> </li> <li> <p><strong>Filter</strong></p> <p>图滤波器的频率响应（Frequency Response）描述了滤波器对于各个频率成分的增益或衰减程度，可以表示为对应于特征值 \(\Lambda\) 的函数 \(H(\Lambda)\)，与谱域信号 \(\hat{x}\) 直接相乘相当于做了卷积运算 \(\hat{y} = H(\Lambda)\hat{x}\) 。</p> </li> <li> <p>Inverse Transform</p> <p><strong>Inverse Graph Fourier Transform</strong> of signal \(\hat{x}\): \(x = U\hat{x}\)，将谱域信号转换回顶点域，重建原始信号。如果应用了滤波器，则公式为 \(y = U\hat{y}\)。</p> </li> </ol> <p>因此，可以推导出 \(y = U\hat{y} = UH(\Lambda)\hat{x} = UH(\Lambda)U^Tx = H(U\Lambda U^T)x = H(L)x\)，所以模型需要学一个有关 \(L\) 的函数 \(H(L)\)（即 filter），输入 \(x\) 后可以得到一个经过 filter 的 \(y\)。如果 \(H(L)\) 被参数化可以写作 \(g_{\boldsymbol{\theta}}(L)\)，即 \(y = g_{\boldsymbol{\theta}}(L)x\)。</p> <p>如果 \(H(L)\) 可以展开一直到 \(L^N\)（图有 \(N\) 个顶点），会导致模型的复杂度是跟输入的图的大小有关的，我们希望的则是不管输入的图有多大都可以用同样大小的模型去训练。另外，\(L^N\) 还会导致所有节点都能互相影响，而我们希望的是模型能够通过 filter 来捕获顶点的局部信息（类比 CNN 的 filter）。</p> <h5 id="chebynet">ChebyNet</h5> <p><a href="https://arxiv.org/abs/1606.09375">Paper</a></p> <p>由 \(y = g_{\boldsymbol{\theta}}(L)x = g_{\boldsymbol{\theta}}(U\Lambda U^T)x = Ug_{\boldsymbol{\theta}}(\Lambda)U^Tx\) 和 \(g_{\boldsymbol{\theta}}(\Lambda) = \text{diag}(\boldsymbol{\theta})\)，令 \(g_{\boldsymbol{\theta}}(\Lambda)\) 是 \(\Lambda\) 的多项式函数 \(g_{\boldsymbol{\theta}}(\Lambda) = \sum^{K-1}_{k=0}\theta_k\Lambda^k\) ，因此可以让 \(g_{\boldsymbol{\theta}}(\Lambda)\) 为 <strong>\(K\)-localized 且降低了复杂度</strong>。</p> <blockquote> <p>Chebyshev Polynomial: \(T_0(x) = 1, T_1(x) = x, T_k(x) = 2xT_{k-1}(x) - T_{k-2}(x), x \in [-1, 1]\)</p> </blockquote> <p>依照 Chebyshev Polynomial，有 \(T_0(\tilde{\Lambda}) = I, T_1(\tilde{\Lambda}) = \tilde{\Lambda}, T_k(\tilde{\Lambda}) = 2\tilde{\Lambda}T_{k-1}(\tilde{\Lambda}) - T_{k-2}(\tilde{\Lambda})\)，where \(\tilde{\Lambda} = \frac{2\Lambda}{\lambda_{max}} - I, \tilde{\lambda} \in [-1, 1]\)，\(I\) 是指 Identity Matrix。因此，原来的多项式函数会变为 \(g_{\boldsymbol{\theta'}}(\Lambda) = \sum^{K-1}_{k=0}\theta'_kT_k(\tilde{\Lambda})\)，这样做会比较好算，所以整个 filter 的操作可以被写成 \(y = g_{\boldsymbol{\theta'}}(L)x = \sum^{K-1}_{k=0}\theta'_kT_k(\tilde{L})x\)，而模型要学的参数就是 \(\boldsymbol{\theta'}\)。</p> <h5 id="gcn">GCN</h5> <p><a href="https://arxiv.org/abs/1609.02907">Paper</a></p> <p>令 ChebyNet 的 filter 公式中的 \(K = 1\)，有</p> \[\begin{align*} y = g_{\boldsymbol{\theta'}}(L)x &amp;= \theta'_0x + \theta'_1 \tilde{L}x \\ &amp;= \theta'_0x + \theta'_1(\frac{2L}{\lambda_{max}}-I)x \ , \ (\lambda_{max} \approx 2) \\ &amp;= \theta'_0x + \theta'_1(L-I)x \ , \ (L = I - D^{-1/2}AD^{-1/2}) \\ &amp;= \theta'_0x + \theta'_1(D^{-1/2}AD^{-1/2})x \ , \ (\theta = \theta'_0 = -\theta'_1, \text{for reducing the parameters}) \\ &amp;= \theta(I + D^{-1/2}AD^{-1/2})x \end{align*}\] <p>然后为每个节点加上一个自环（<strong>self-loop</strong>），即 \(\tilde{A} = A + I\)（<strong>对角线元素一定为 1</strong>） 和 \(\tilde{D}_{ii} = \sum_j\tilde{A}_{ij}\)，从而有 \(I + D^{-1/2}AD^{-1/2} \rightarrow \tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}\)，作者称之为 \(renormalization \ trick\)。所以 GCN 中一层的传播可以写为 \(H^{(l+1)} = \sigma(\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}H^{(l)}W^{(l)})\)，\(\sigma\) 是激活函数，\(H^{(l)}\) 是第 \(l\) 层的节点特征矩阵（\(x\)），\(W^{(l)}\) 是第 \(l\) 层的权重矩阵（\(\theta\)），即在每一层只考虑一个顶点的直接相连的邻居（1-localize）及其自身的特征来更新该顶点的特征。</p> <p>在第一层，每个节点只能捕捉到其一阶邻居和其自身的特征，在第二层，每个节点就能捕捉到其二阶邻居的特征（节点的一阶邻居的特征也更新了）。但是随着 GCN 层数的增加，每个节点的特征会越来越“全局化”，可能会导致所有节点的特征逐渐变得相似，从而失去了区分度（over-smoothing）。</p> <h5 id="gated-gcn">Gated-GCN</h5> <p><a href="https://arxiv.org/abs/1711.07553">Residual Gated Graph ConvNets</a></p> <p><a href="https://arxiv.org/abs/2003.00982">Benchmarking Graph Neural Networks</a></p> <h4 id="graph-generation">Graph Generation</h4> <ul> <li> <p>VAE-based model: Generate a whole graph in one step</p> <p><a href="https://arxiv.org/abs/1802.03480">GraphVAE</a></p> </li> <li> <p>GAN-based model: Generate a whole graph in one step</p> <p><a href="https://arxiv.org/abs/1805.11973">MolGAN</a></p> </li> <li> <p>Autoregressive-based model: Generate a node or an edge in one step</p> <p><a href="https://arxiv.org/abs/1803.03324">Learning Deep Generative Models of Graphs</a></p> </li> <li> <p>More</p> <p><a href="https://arxiv.org/abs/1901.00596">A Comprehensive Survey on Graph Neural Networks</a></p> </li> </ul> <h4 id="new">New</h4> <p><a href="https://arxiv.org/abs/2205.12454">GraphGPS</a></p> <p><a href="https://arxiv.org/abs/2110.07875">Graph Neural Networks with Learnable Structural and Positional Representations</a></p> <h3 id="appendix">Appendix</h3> <h4 id="hyperparameters">Hyperparameters</h4> <ul> <li>learning rate</li> <li>no. of sigmoid</li> <li>batch size</li> <li>no. of hidden layers</li> <li>momentum \(\lambda\)</li> <li>RMSProp \(\alpha\)</li> <li>CNN: kernel size, number of filters, stride, padding, pool size, pool stride, pooling type</li> <li>Multi-head self-attention: numbers of head</li> <li>temperature for softmax \(T\)</li> </ul> <h4 id="pytorch">PyTorch</h4> <p>Features: 1) Tensor computation with GPU acceleration; 2) autograd (Automatic Differentiation); 3) PyTorch for research, TensorFlow for Production</p> <h5 id="data-type">Data Type</h5> <table> <thead> <tr> <th style="text-align: center">Data Type</th> <th style="text-align: center">dtype</th> <th style="text-align: center">tensor</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">32-bit floating point</td> <td style="text-align: center">torch.float</td> <td style="text-align: center">torch.FloatTensor</td> </tr> <tr> <td style="text-align: center">64-bit integer (signed)</td> <td style="text-align: center">torch.long</td> <td style="text-align: center">torch.LongTensor</td> </tr> </tbody> </table> <h5 id="shape-of-tensors">Shape of Tensors</h5> <div class="md-img"><img src="/assets/img/DL-img/pytorch1.png" alt="pytorch1" style="zoom:25%;"/></div> <h5 id="creating-tensors">Creating Tensors</h5> <ul> <li> <p>Directly from data (list or numpy.ndarray)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]))</span>
</code></pre></div> </div> </li> <li> <p>Tensor of constant zeros &amp; ones</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</code></pre></div> </div> </li> </ul> <h5 id="common-operations">Common Operations</h5> <ul> <li> <p>Addition, Subtraction, Power, Summation, Mean</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
</code></pre></div> </div> </li> <li> <p>Transpose, Squeeze, Unsqueeze</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="c1"># transpose
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="c1"># squeeze the dimension that its size is 1
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="c1"># unsqueeze
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div> </div> </li> <li> <p>Cat</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># concatenate multiple tensors
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div> </div> </li> </ul> <h5 id="device">Device</h5> <p>Tensors &amp; modules will be computed with <strong>CPU</strong> by default, using <strong><em>.to()</em></strong> to move tensors to appropriate devices.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># Check if your computer has NVIDIA GPU
</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
<span class="c1"># Multiple GPUs need to specify 'cuda:0, 'cuda:1', 'cuda:2', ...
</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:0</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Why GPU? Parallel computing with more cores for arithmetic calculations and see <a href="https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d">‘What is a GPU and do you need one in deep learning?’</a></p> <h5 id="main-procedure">Main Procedure</h5> <h6 id="load-data">Load Data</h6> <p><strong><code class="language-plaintext highlighter-rouge">torch.utils.data.Dataset</code> &amp; <code class="language-plaintext highlighter-rouge">torch.utils.data.DataLoader</code></strong></p> <ul> <li> <p>Dataset: stores data samples and expected values</p> </li> <li> <p>Dataloader: groups data in batches, enables multiprocessing</p> <div class="md-img"><img src="/assets/img/DL-img/pytorch2.png" alt="pytorch2" style="zoom:30%;"/></div> <div class="md-img"><img src="/assets/img/DL-img/pytorch3.png" alt="pytorch3" style="zoom:30%;"/></div> </li> </ul> <h6 id="training">Training</h6> <ol> <li> <p>Define Neural Network:</p> <ul> <li> <p>Linear Layer (Fully-connected Layer)</p> <p><strong><code class="language-plaintext highlighter-rouge">torch.nn.Linear(in_features, out_features)</code></strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">layer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">layer</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">layer</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">64</span><span class="p">])</span>
</code></pre></div> </div> </li> <li> <p>Non-Linear Activation Function</p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">torch.nn.Sigmoid()</code></strong></p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">torch.nn.ReLU()</code></strong></p> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
           
<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
<span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>  <span class="c1"># super(MyModel, self).__init__()
</span><span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
<span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
<span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">(),</span>
<span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div> </div> </li> </ul> </li> <li> <p>Loss Function:</p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">torch.nn.MSELoss()</code></strong> for regression</p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">torch.nn.CrossEntropyLoss()</code></strong> for classification</p> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">model_output</span><span class="p">,</span> <span class="n">expected_value</span><span class="p">)</span>
</code></pre></div> </div> </li> <li> <p>Optimization:</p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">torch.optim.SGD(model.parameters(), lr, momentum=0)</code></strong></p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">torch.optim.Adam()</code></strong></p> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div> </div> <div class="md-img"><img src="/assets/img/DL-img/pytorch4.png" alt="pytorch4" style="zoom:30%;"/></div> </li> </ol> <p>For every batch of data:</p> <ol> <li> <p>Call <strong><code class="language-plaintext highlighter-rouge">optimizer.zero_grad()</code></strong> to reset gradients of model parameters.</p> </li> <li> <p>Call <strong><code class="language-plaintext highlighter-rouge">loss.backward()</code></strong> to backpropagate gradients of prediction loss.</p> </li> <li> <p>Call <strong><code class="language-plaintext highlighter-rouge">optimizer.step()</code></strong> to adjust model parameters.</p> </li> </ol> <div class="md-img"><img src="/assets/img/DL-img/pytorch5.png" alt="pytorch5" style="zoom:30%;"/></div> <h6 id="validation">Validation</h6> <div class="md-img"><img src="/assets/img/DL-img/pytorch6.png" alt="pytorch6" style="zoom:30%;"/></div> <h6 id="testing">Testing</h6> <div class="md-img"><img src="/assets/img/DL-img/pytorch7.png" alt="pytorch7" style="zoom:30%;"/></div> <h6 id="saveload-trained-models">Save/Load Trained Models</h6> <ul> <li> <p>Save</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
</code></pre></div> </div> </li> <li> <p>Load</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ckpt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>  <span class="c1"># checkpoint
</span><span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">)</span>
</code></pre></div> </div> </li> </ul> <h5 id="more">More</h5> <ul> <li>torchvision</li> <li>torchaudio</li> <li>torchtext</li> <li>Huggingface Transformers</li> <li>Fairseq</li> <li>torchdrug</li> </ul> <h5 id="common-errors">Common Errors</h5> <ol> <li>When the shape of a tensor is incorrect, use <strong>transpose</strong>, <strong>squeeze</strong>, <strong>unsqueeze</strong> to align the dimensions.</li> </ol> <h4 id="tensorboard">TensorBoard</h4> <ol> <li>VSCode: Terminal <code class="language-plaintext highlighter-rouge">tensorboard --logdir runs</code></li> </ol> <h4 id="colab">Colab</h4> <p>use <strong>%</strong> instead of <strong>!</strong> for <strong>cd</strong> command</p> <p>连接到自己的Google Drive</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="p">.</span><span class="nf">mount</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="md-img"><img src="/assets/img/DL-img/colab1.png" alt="colab1" style="zoom:30%;"/></div> <p>Colab保持运行：<a href="https://stackoverflow.com/questions/57113226/how-can-i-prevent-google-colab-from-disconnecting">方法</a></p> <h2 id="libraries">Libraries</h2> <p>PyTorch / TensorFlow</p> <p>Hugging Face</p> <p>PyG / DGL / DIG / NetworkX / DGL/DGL-lifesci</p> <p>Captum / SHAP</p> <p>scikit-learn</p> <p>NumPy / Pandas / Matplotlib / Seaborn / Plotly</p> <p>RDKit / DeepChem</p> <p>Hyperopt/Optuna</p> <p>learn2learn / Awesome-META+</p> <p>Flask / Streamlit / FastAPI</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:book" role="doc-endnote"> <p>《深度学习入门-斋藤康毅》P171 <a href="#fnref:book" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="DL"/><summary type="html"><![CDATA[Deep Learning Notes]]></summary></entry><entry><title type="html">Python</title><link href="https://xli7654321.github.io/blog/2023/python/" rel="alternate" type="text/html" title="Python"/><published>2023-07-20T12:00:00+00:00</published><updated>2023-07-20T12:00:00+00:00</updated><id>https://xli7654321.github.io/blog/2023/python</id><content type="html" xml:base="https://xli7654321.github.io/blog/2023/python/"><![CDATA[<style>h1,h2,h3,h4,h5,h6{color:var(--global-theme-color)}table{width:100%;margin:.5rem 0}th,td{padding:.5rem}</style> <h2 id="python-基本语法-">Python 基本语法 <sup id="fnref:book" role="doc-noteref"><a href="#fn:book" class="footnote" rel="footnote">1</a></sup></h2> <h3 id="对象">对象</h3> <p>在 Python 中一切都是对象</p> <h4 id="变量">变量</h4> <p>Python 中直接赋值即可创建任意类型的变量。Python 采用基于值的内存管理模式。赋值语句的执行过程是：首先把等号右侧表达式的值计算出来，然后在内存中寻找一个位置把值存放进去，最后创建变量并指向这个内存地址（给内存地址贴标签）。<strong>Python 中的变量并不直接存储值，而是存储值的内存地址。</strong>因此，变量类型可以随时改变。</p> <p class="mynote">变量名必须以字母或下划线开头。以下划线开头的变量具有<a href="/blog/2023/python/#python">特殊含义</a></p> <p>内置函数 <code class="language-plaintext highlighter-rouge">type(x)</code> 用于查看变量类型，或使用 <code class="language-plaintext highlighter-rouge">isinstance(x, int)</code> 来测试变量是否为指定类型。</p> <h4 id="数字">数字</h4> <ul> <li>整数 - int、 实数 - float、复数 - complex</li> </ul> <p>由于精度的问题，实数运算可能会有一定的误差。因此，应尽量避免在实数之间直接进行相等性比较，而是应该以两者之差的绝对值是否足够小作为两个实数是否相等的依据。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="mf">0.4</span> <span class="o">-</span> <span class="mf">0.1</span>
<span class="mf">0.30000000000000004</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">0.4</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">==</span> <span class="mf">0.3</span>
<span class="bp">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">abs</span><span class="p">(</span><span class="mf">0.4</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">-</span> <span class="mf">0.3</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-6</span>  <span class="c1"># or math.isclose(a, b)
</span><span class="bp">True</span>
</code></pre></div></div> <p>Python 3.6 支持在数字中间插入单个下划线来提高数字的可读性 <code class="language-plaintext highlighter-rouge">1_000_000</code>。</p> <ul> <li>分数 / 高精度实数</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="n">fractions</span> <span class="kn">import</span> <span class="n">Fraction</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="n">decimal</span> <span class="kn">import</span> <span class="n">Decimal</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="nc">Fraction</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># 分数
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">numerator</span>  <span class="c1"># 查看分子
</span><span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">denominator</span>  <span class="c1"># 查看分母
</span><span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="nc">Decimal</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">9</span><span class="p">)</span>  <span class="c1"># 高精度实数
</span></code></pre></div></div> <h4 id="字符串">字符串</h4> <p>Python 使用单引号、双引号、三单引号、三双引号作为定界符（delimiter）来表示字符串，并且不同的定界符之间可以互相嵌套。字符串之间拼接可以用 <code class="language-plaintext highlighter-rouge">+</code> 或 <code class="language-plaintext highlighter-rouge">''.join()</code>。</p> <p><code class="language-plaintext highlighter-rouge">str</code> 类型字符串与 <code class="language-plaintext highlighter-rouge">bytes</code> 类型字节串之间编码与解码</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="sh">'</span><span class="s">Hello World</span><span class="sh">'</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
<span class="sa">b</span><span class="sh">'</span><span class="s">Hello World</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">b</span><span class="sh">'</span><span class="s">Hello World</span><span class="sh">'</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">Hello World</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="列表元组字典集合">列表、元组、字典、集合</h4> <table> <thead> <tr> <th style="text-align: left">比较项</th> <th style="text-align: left">list</th> <th style="text-align: left">tuple</th> <th style="text-align: left">dict</th> <th style="text-align: left">set</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">定界符</td> <td style="text-align: left">[ ]</td> <td style="text-align: left">( )</td> <td style="text-align: left">{ }</td> <td style="text-align: left">{ }</td> </tr> <tr> <td style="text-align: left">是否可变</td> <td style="text-align: left">是</td> <td style="text-align: left">否</td> <td style="text-align: left">是</td> <td style="text-align: left">是</td> </tr> <tr> <td style="text-align: left">是否有序</td> <td style="text-align: left">是</td> <td style="text-align: left">是</td> <td style="text-align: left">否</td> <td style="text-align: left">否</td> </tr> <tr> <td style="text-align: left">是否支持下标</td> <td style="text-align: left">是（使用整数序号作为下标）</td> <td style="text-align: left">同 list</td> <td style="text-align: left">是（使用“键”作为下标）</td> <td style="text-align: left">否</td> </tr> <tr> <td style="text-align: left">元素是否可重复</td> <td style="text-align: left">是</td> <td style="text-align: left">是</td> <td style="text-align: left">“值”可重复，“键”不可</td> <td style="text-align: left">否</td> </tr> <tr> <td style="text-align: left">元素查找速度</td> <td style="text-align: left">非常慢</td> <td style="text-align: left">很慢</td> <td style="text-align: left">非常快</td> <td style="text-align: left">非常快</td> </tr> <tr> <td style="text-align: left">新增和删除元素速度</td> <td style="text-align: left">尾部操作快，其他位置慢</td> <td style="text-align: left">不允许</td> <td style="text-align: left">快</td> <td style="text-align: left">快</td> </tr> </tbody> </table> <p class="mynote">如果元组中只有一个元素，后面的逗号不能省略。例如，<code class="language-plaintext highlighter-rouge">(3,)</code>。</p> <h3 id="运算符">运算符</h3> <table> <thead> <tr> <th style="text-align: left">易忘运算符</th> <th style="text-align: left">功能</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">/</td> <td style="text-align: left">除法</td> </tr> <tr> <td style="text-align: left">//</td> <td style="text-align: left">求整商，如果操作数中有实数</td> </tr> <tr> <td style="text-align: left">%</td> <td style="text-align: left">求余数</td> </tr> <tr> <td style="text-align: left">**</td> <td style="text-align: left">幂</td> </tr> <tr> <td style="text-align: left">or</td> <td style="text-align: left">或</td> </tr> <tr> <td style="text-align: left">and</td> <td style="text-align: left">与</td> </tr> <tr> <td style="text-align: left">not</td> <td style="text-align: left">非</td> </tr> <tr> <td style="text-align: left">is</td> <td style="text-align: left">测试是否为同一个对象（如果两个对象是同一个，两者具有相同的内存地址）</td> </tr> </tbody> </table> <p><code class="language-plaintext highlighter-rouge">==</code> 用于判断两个对象的值是否相等，<code class="language-plaintext highlighter-rouge">is</code> 用于判断两个对象是否是同一个。</p> <h3 id="关键字">关键字</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">keyword</span>
<span class="nf">print</span><span class="p">(</span><span class="n">keyword</span><span class="p">.</span><span class="n">kwlist</span><span class="p">)</span>  <span class="c1"># 查看关键字
</span></code></pre></div></div> <h3 id="内置函数">内置函数</h3> <p>Python的内置函数封装在模块 <code class="language-plaintext highlighter-rouge">__builtins__</code> 中，用 C 语言实现，可通过内置函数 <code class="language-plaintext highlighter-rouge">dir(obj)</code> 查看所有内置函数和内置对象：<code class="language-plaintext highlighter-rouge">&gt;&gt;&gt; dir(__builtins__)</code>。</p> <h4 id="类型转换与类型判断">类型转换与类型判断</h4> <p><code class="language-plaintext highlighter-rouge">bin(x)</code>、<code class="language-plaintext highlighter-rouge">oct(x)</code>、<code class="language-plaintext highlighter-rouge">hex(x)</code> 分别用于将整数转换为二进制、八进制和十六进制，其参数必须为整数。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">bin</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="sh">'</span><span class="s">0b1010</span><span class="sh">'</span>  <span class="c1"># 0b开头表示二进制数，同理0o、0x开头表示八、十六进制数
</span></code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">int(x, base)</code>、<code class="language-plaintext highlighter-rouge">float(x)</code>、<code class="language-plaintext highlighter-rouge">complex(real, imag)</code> 分别用于将其他类型的数据转换为整数、实数和复数。<code class="language-plaintext highlighter-rouge">int('0b1010', 2)</code> 的第二个参数 <code class="language-plaintext highlighter-rouge">base</code> 用于说明 <code class="language-plaintext highlighter-rouge">x</code> 的进制。</p> <p><code class="language-plaintext highlighter-rouge">str(obj)</code>、<code class="language-plaintext highlighter-rouge">bytes(x)</code>、<code class="language-plaintext highlighter-rouge">list(x)</code> 、<code class="language-plaintext highlighter-rouge">tuple(x)</code>、<code class="language-plaintext highlighter-rouge">dict(x)</code>、<code class="language-plaintext highlighter-rouge">set(x)</code>、<code class="language-plaintext highlighter-rouge">frozenset(x)</code> 分别用于将其他类型数据转换为字符串、字节串、列表、元组、字典、可变集合和不可变集合，或创建空对象。</p> <h4 id="计算">计算</h4> <p><code class="language-plaintext highlighter-rouge">abs(x)</code> 用于返回 <code class="language-plaintext highlighter-rouge">x</code> 的绝对值或复数 <code class="language-plaintext highlighter-rouge">x</code> 的模。</p> <p><code class="language-plaintext highlighter-rouge">max(x, key=None)</code>、<code class="language-plaintext highlighter-rouge">min(x, key=None)</code>、<code class="language-plaintext highlighter-rouge">sum(x, start=0)</code> 用于计算包含有限个元素的可迭代对象中所有元素的最大值、最小值以及所有元素之和。<code class="language-plaintext highlighter-rouge">key</code> 参数用于指定比较大小的规则，<code class="language-plaintext highlighter-rouge">start</code> 参数用于指定求和的初始值（指定 <code class="language-plaintext highlighter-rouge">start</code> 时返回 <code class="language-plaintext highlighter-rouge">start + sum(x)</code>）。</p> <p><code class="language-plaintext highlighter-rouge">round(x, ndigits)</code> 用于对 <code class="language-plaintext highlighter-rouge">x</code> 进行四舍五入，<code class="language-plaintext highlighter-rouge">ndigits</code> 参数用于指定返回值的小数位数，默认返回整数。</p> <h4 id="基本输入与输出">基本输入与输出</h4> <p><code class="language-plaintext highlighter-rouge">input()</code> 用于接收用户的键盘输入，输入的内容以字符串类型对待。</p> <p><code class="language-plaintext highlighter-rouge">print(value, sep='', end='\n', file=sys.stdout)</code> 用于将内容输出到控制台或指定文件中。<code class="language-plaintext highlighter-rouge">sep</code> 参数用于指定数据之间的分隔符，默认为空格。<code class="language-plaintext highlighter-rouge">end</code> 参数用于指定输出后的结束字符串，默认为换行符。<code class="language-plaintext highlighter-rouge">file</code> 参数用于指定输出位置，默认为控制台。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">output.txt</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Hello, world!</span><span class="sh">"</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">f</span><span class="p">)</span>  <span class="c1"># 将内容写入到 output.txt 文件中
</span></code></pre></div></div> <h4 id="排序">排序</h4> <p><code class="language-plaintext highlighter-rouge">sorted(iterable, key=None, reverse=False)</code> 对可迭代对象进行排序并返回新列表。<code class="language-plaintext highlighter-rouge">key</code> 参数用于指定排序规则。<code class="language-plaintext highlighter-rouge">reverse</code> 参数用于指定升序或降序，默认为 False 表示升序。</p> <p><code class="language-plaintext highlighter-rouge">reversed(iterable)</code> 对可迭代对象进行翻转并返回可迭代的 reversed 对象。</p> <h4 id="具有惰性求值特性的函数">具有惰性求值特性的函数</h4> <p>惰性求值（Lazy Evaluation）：仅在结果真正需要被计算时才进行计算。</p> <p><code class="language-plaintext highlighter-rouge">range(start, stop, step)</code> 返回包含左闭右开区间 <code class="language-plaintext highlighter-rouge">[start, stop)</code> 内以 <code class="language-plaintext highlighter-rouge">step</code> 为步长的整数。<code class="language-plaintext highlighter-rouge">start</code> 默认为 0，<code class="language-plaintext highlighter-rouge">step</code> 默认为 1。常用于控制循环的次数。</p> <p><code class="language-plaintext highlighter-rouge">enumerate(iterable, start)</code> 用于枚举可迭代对象中的元素，返回可迭代的 enumerate 对象，其中每个元素都是包含索引和值的元组。<code class="language-plaintext highlighter-rouge">start</code> 参数用于指定 index 的起始值。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">)):</span>
	<span class="nf">print</span><span class="p">((</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">)</span>
<span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">14</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">zip(*iterables)</code> 用于把多个可迭代对象中的元素压缩到一起，返回一个可迭代的 zip 对象。其中每个元素都是包含原来对象的对应位置上元素的元组，最终结果中元素的个数取决于可迭代对象中最短的那个。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">list</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="sh">'</span><span class="s">abcd</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="p">[(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">map(func, *iterables)</code> 把一个函数 <code class="language-plaintext highlighter-rouge">func</code> 依次映射到可迭代对象的每个元素上，返回一个可迭代的 map 对象，其中每个元素是原对象经过函数 <code class="language-plaintext highlighter-rouge">func</code> 处理后的结果。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">list</span><span class="p">(</span><span class="nf">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nf">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="p">[</span><span class="sh">'</span><span class="s">0</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">3</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">4</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">filter(func, iterable)</code> 将一个单参数函数 <code class="language-plaintext highlighter-rouge">func</code> 作用到一个可迭代对象上，返回该对象中使得该函数返回值等价于 True 的元素所组成的 filter 对象。若指定函数为 None，则返回对象中等价于 True 的元素。</p> <h4 id="reduce"><code class="language-plaintext highlighter-rouge">reduce()</code></h4> <p><code class="language-plaintext highlighter-rouge">reduce(func, seq, initial=None)</code> 将双参数函数 <code class="language-plaintext highlighter-rouge">func</code> 以迭代的方式从左到右依次应用到序列 <code class="language-plaintext highlighter-rouge">seq</code> 中的每个元素，并把中间计算结果作为下一次计算的第一个操作数，最终返回单个值作为结果。<code class="language-plaintext highlighter-rouge">initial</code> 参数用于指定一个初始值。该函数从 <code class="language-plaintext highlighter-rouge">functools</code> 库中导入，并可以结合 <code class="language-plaintext highlighter-rouge">operator</code> 库中提供的多种运算使用。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="n">functools</span> <span class="kn">import</span> <span class="nb">reduce</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="n">operator</span> <span class="kn">import</span> <span class="n">add</span><span class="p">,</span> <span class="n">sub</span><span class="p">,</span> <span class="n">mul</span><span class="p">,</span> <span class="n">truediv</span><span class="p">,</span> <span class="n">floordiv</span><span class="p">,</span> <span class="n">mod</span><span class="p">,</span> <span class="nb">pow</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">seq</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">reduce</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="n">seq</span><span class="p">)</span>
<span class="mi">45</span>
</code></pre></div></div> <h4 id="len"><code class="language-plaintext highlighter-rouge">len()</code></h4> <p><code class="language-plaintext highlighter-rouge">len(obj)</code> 返回对象 <code class="language-plaintext highlighter-rouge">obj</code> 包含的元素的个数，适用于 list、tuple、dict、set、str 以及 range 对象，不适用于具有惰性求值特性的对象。</p> <h4 id="all-any"><code class="language-plaintext highlighter-rouge">all()</code>, <code class="language-plaintext highlighter-rouge">any()</code></h4> <p><code class="language-plaintext highlighter-rouge">all(iterable)</code> 如果可迭代对象 iterable 中所有元素 x 的 <code class="language-plaintext highlighter-rouge">bool(x)</code> 都为 True，则返回 True。对于空的可迭代对象也返回 True。</p> <p><code class="language-plaintext highlighter-rouge">any(iterable)</code> 只要可迭代对象 iterable 中存在元素 x 使得 <code class="language-plaintext highlighter-rouge">bool(x)</code> 为 True，则返回 True。对于空的可迭代对象返回 False。</p> <h4 id="help"><code class="language-plaintext highlighter-rouge">help()</code></h4> <p><code class="language-plaintext highlighter-rouge">help(obj)</code> 返回对象 <code class="language-plaintext highlighter-rouge">obj</code> 的帮助信息。</p> <p><a href="">用于查看函数的使用帮助</a></p> <h2 id="序列结构">序列结构</h2> <p>Python 中常用的序列结构包括列表、元组、字符串、字典、集合等，其中列表、元组、字符串等有序序列以及 range 对象均支持<strong>双向索引</strong>，即第一个元素索引为 0，第二个元素索引为 1，以此类推；若使用负数作为索引，则最后一个元素索引为 -1，倒数第二个元素索引为 -2，以此类推。</p> <h3 id="列表"><strong>列表</strong></h3> <p>列表是包含若干元素的有序连续内存空间。当列表增加或删除元素时，列表对象自动进行内存的扩展或收缩，从而保证相邻元素之间没有缝隙。列表应尽量从列表尾部进行元素的追加与删除操作。</p> <h4 id="列表的创建与删除">列表的创建与删除</h4> <p>使用“=”直接将一个列表赋值给变量即可创建列表对象。也可以使用 <code class="language-plaintext highlighter-rouge">list()</code> 把可迭代对象转换为列表。需要注意的是，把字典转换为列表时默认是将字典的”键“转换为列表，若想把字典的元素转换为列表，需要使用字典的 <code class="language-plaintext highlighter-rouge">dict.items()</code> 方法，也可以使用 <code class="language-plaintext highlighter-rouge">values()</code> 将字典的值转换为列表。当一个列表不再使用时，可以使用 <code class="language-plaintext highlighter-rouge">del</code> 命令删除。</p> <h4 id="列表常用方法">列表常用方法</h4> <ul> <li><code class="language-plaintext highlighter-rouge">append()</code>、<code class="language-plaintext highlighter-rouge">insert()</code>、<code class="language-plaintext highlighter-rouge">extend()</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">append(x)</code> 用于向列表尾部追加一个元素。<code class="language-plaintext highlighter-rouge">insert(index, x)</code> 用于向列表任意指定位置插入一个元素。<code class="language-plaintext highlighter-rouge">extend(x)</code> 用于将另一个可迭代对象中的所有元素追加到当前列表的尾部。这三个方法都不影响列表对象的内存地址（<code class="language-plaintext highlighter-rouge">id(obj)</code> 函数可以查看对象 <code class="language-plaintext highlighter-rouge">obj</code> 的内存地址）。</p> <ul> <li><code class="language-plaintext highlighter-rouge">pop()</code>、<code class="language-plaintext highlighter-rouge">remove()</code>、<code class="language-plaintext highlighter-rouge">clear()</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">pop([index])</code> 用于删除并返回列表指定位置上的元素，不指定参数时默认为 -1，即最后一个元素，对空列表调用会抛出异常。<code class="language-plaintext highlighter-rouge">remove(x)</code> 用于删除列表中首个与指定值相等的元素。若不存在则抛出异常。<code class="language-plaintext highlighter-rouge">clear()</code> 用于清空列表中的所有元素，保留列表对象。这三个方法同样都不影响列表对象的内存地址。同时，还可以使用 <code class="language-plaintext highlighter-rouge">del</code> 命令通过索引删除列表中指定位置的元素。</p> <ul> <li><code class="language-plaintext highlighter-rouge">count()</code>、<code class="language-plaintext highlighter-rouge">index()</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">count(x)</code> 用于返回列表中指定元素出现的次数，若不存在则返回 0。<code class="language-plaintext highlighter-rouge">index(x)</code> 返回指定元素在列表中首次出现的索引，若不存在则抛出异常。</p> <ul> <li><code class="language-plaintext highlighter-rouge">sort()</code>、<code class="language-plaintext highlighter-rouge">reverse()</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">sort(key=None, reverse=False)</code> 用于对列表中的元素进行排序，<code class="language-plaintext highlighter-rouge">key</code> 参数用于指定排序规则，<code class="language-plaintext highlighter-rouge">reverse</code> 参数默认为 False 表示升序，为 True 则表示降序。<code class="language-plaintext highlighter-rouge">reverse()</code> 用于将列表中的所有元素进行翻转，即首尾交换。</p> <p class="mynote"><code class="language-plaintext highlighter-rouge">sort()</code> 和 <code class="language-plaintext highlighter-rouge">reverse()</code> 对列表的排序都是原地排序，即列表的内存地址不变，但原列表中数据的顺序全部丢失，变为排序后的顺序。若不想丢失原来的顺序，则可以使用内置函数 <code class="language-plaintext highlighter-rouge">sorted()</code> 和 <code class="language-plaintext highlighter-rouge">reversed()</code>，分别返回新列表和 reversed 对象。</p> <ul> <li><code class="language-plaintext highlighter-rouge">copy()</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">copy()</code> 返回列表的浅复制。</p> <p class="mynote">浅复制是指生成一个新的列表并把原列表中所有元素的<strong>引用</strong>都复制到新列表中。若原列表中只包含不可变类型的数据则一般没有问题。但是，若原列表中包含可变类型的数据，由于浅复制只是复制元素的引用，于是修改任何一个都会影响到另外一个。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>  <span class="c1"># 浅复制
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># 对可变的数据进行修改
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>  <span class="c1"># 由于浅复制，原列表也会改变
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>  <span class="c1"># 对可变的数据进行修改
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="mi">6</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>  <span class="c1"># 不可变的数据不受影响
</span></code></pre></div></div> <p>列表的切片操作和标准库 copy 中的 <code class="language-plaintext highlighter-rouge">copy()</code> 函数都是返回浅复制。若想使用深复制，则可以使用标准库 copy 中的 <code class="language-plaintext highlighter-rouge">deepcopy()</code> 函数。所谓深复制，是指对原列表中的元素进行递归，把所有的值都复制到新列表中，不再是复制引用，从而新列表和原列表之间是相互独立的。</p> <h4 id="列表支持的运算符">列表支持的运算符</h4> <p>列表支持加法运算符 <code class="language-plaintext highlighter-rouge">+</code>，但该操作不属于原地操作，而是返回一个新列表，并且效率较低。更推荐使用复合赋值运算符 <code class="language-plaintext highlighter-rouge">+=</code> 实现列表追加元素，并且属于原地操作，与 <code class="language-plaintext highlighter-rouge">extend()</code> 方法一样高效。</p> <p>列表也支持乘法运算符 <code class="language-plaintext highlighter-rouge">*</code>，用于列表和整数相乘，表示序列重复，返回新列表。<code class="language-plaintext highlighter-rouge">*=</code>也可用于列表元素重复，与 <code class="language-plaintext highlighter-rouge">+=</code> 一样属于原地操作。</p> <p>成员测试运算符 <code class="language-plaintext highlighter-rouge">in</code> 可用于测试列表中是否包含某个元素，查询时间随着列表长度的增加而线性增加。但是同样的操作对于集合而言则是常数级的。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">id</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="mi">2832802183680</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">id</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="mi">2832798807040</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">+=</span> <span class="n">y</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">id</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 内存地址不变
</span><span class="mi">2832802183680</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">*=</span> <span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">id</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 内存地址不变
</span><span class="mi">2832802183680</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">5</span> <span class="ow">in</span> <span class="n">x</span>
<span class="bp">True</span>
</code></pre></div></div> <h4 id="列表推导式"><strong>列表推导式</strong></h4> <p>列表推导式（List Comprehensions）提供了一种创建列表的简洁方法，使用方括号作为定界符。其语法形式为：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="n">expression</span> <span class="k">for</span> <span class="n">variable1</span> <span class="ow">in</span> <span class="n">sequence1</span> <span class="k">if</span> <span class="n">condition1</span>
			<span class="k">for</span> <span class="n">variable2</span> <span class="ow">in</span> <span class="n">sequence2</span> <span class="k">if</span> <span class="n">condition2</span>
			<span class="k">for</span> <span class="n">variableN</span> <span class="ow">in</span> <span class="n">sequenceN</span> <span class="k">if</span> <span class="n">conditionN</span><span class="p">]</span>
</code></pre></div></div> <p>列表推导式在逻辑上等价于一个循环语句，但形式上更加简洁。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">aList</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="c1"># 等价于
</span><span class="n">aList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
	<span class="n">aList</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p>列表推导式常见的应用：</p> <ul> <li>实现嵌套列表的平铺</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">vec</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">num</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">vec</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">elem</span><span class="p">]</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="c1"># 也可以使用 itertools 库中的 chain() 函数
</span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="n">itertools</span> <span class="kn">import</span> <span class="n">chain</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">list</span><span class="p">(</span><span class="nf">chain</span><span class="p">(</span><span class="o">*</span><span class="n">vec</span><span class="p">))</span>  <span class="c1"># *vec 使用序列解包，将 vec 中的所有子列表作为单独的参数传递给 chain()
</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
</code></pre></div></div> <ul> <li>过滤不符合条件的元素</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">filename</span> <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="sh">'</span><span class="s">E:</span><span class="se">\\</span><span class="sh">'</span><span class="p">)</span> <span class="k">if</span> <span class="n">filename</span><span class="p">.</span><span class="nf">endswith</span><span class="p">((.</span><span class="n">png</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="n">jpg</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="n">gif</span><span class="sh">'</span><span class="s">))]
[</span><span class="sh">'</span><span class="n">logo</span><span class="p">.</span><span class="n">png</span><span class="sh">'</span><span class="s">]
</span></code></pre></div></div> <ul> <li>同时遍历多个列表</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="p">[(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">y</span><span class="p">]</span>
<span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
</code></pre></div></div> <ul> <li>实现矩阵转置</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">matrix</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">[[</span><span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">matrix</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
<span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]</span>
<span class="c1"># 也可以使用 zip() 和 list() 来实现
</span><span class="o">&gt;&gt;&gt;</span> <span class="nf">list</span><span class="p">(</span><span class="nf">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nf">zip</span><span class="p">(</span><span class="o">*</span><span class="n">matrix</span><span class="p">)))</span>
<span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]</span>
</code></pre></div></div> <h4 id="切片"><strong>切片</strong></h4> <p>切片不仅仅适用于列表，还适用于元组、字符串、range 对象，但是列表的切片操作具有最强大的功能。不仅可以使用切片来截取列表中的任何部分得到一个新列表，还可以来修改和删除列表中的部分元素，甚至可以为列表增加元素。</p> <p><strong>切片的语法：<code class="language-plaintext highlighter-rouge">[start:stop:step]</code></strong></p> <p><code class="language-plaintext highlighter-rouge">start</code> 表示切片开始的索引，默认为 0；<code class="language-plaintext highlighter-rouge">stop</code> 表示切片结束的索引（不包含），默认为列表的长度；<code class="language-plaintext highlighter-rouge">step</code> 表示切片的步长，默认为 1。当这三个为默认值时可以省略，省略步长的同时还可以省略第二个冒号。当 <code class="language-plaintext highlighter-rouge">step</code> 为负整数时，表示反向切片，即顺序变为从右向左，此时 <code class="language-plaintext highlighter-rouge">start</code> 应大于 <code class="language-plaintext highlighter-rouge">stop</code>。</p> <ul> <li>使用切片获取列表的部分元素</li> </ul> <p>切片可以返回列表中部分元素组成的新列表。与使用索引作为下标访问列表的元素不同，切片不会因为下标越界而抛出异常，而是简单地在列表尾部截断或返回一个空列表。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[::]</span>  <span class="c1"># 返回包含原列表中所有元素的新列表
</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[:]</span>  <span class="c1"># step 为 1 时，可以省略第二个冒号
</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># 返回包含原列表中所有元素的逆序列表
</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># 改变步长，隔一个取一个
</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>  <span class="c1"># 指定切片开始和结束的索引，左闭右开区间
</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># 步长为负整数时，从右侧（索引值大）向左侧（索引值小）挨个选取
</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span>  <span class="c1"># 切片结束索引大于列表长度，直接从尾部截断，不抛出异常
</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span>  <span class="c1"># 切片开始索引大于列表长度，返回空列表
</span><span class="p">[]</span>
</code></pre></div></div> <ul> <li>使用切片为列表添加元素</li> </ul> <p>使用切片为列表添加元素不影响列表对象的内存地址，属于原地操作。添加元素时需保证 <code class="language-plaintext highlighter-rouge">start</code> 和 <code class="language-plaintext highlighter-rouge">stop</code> 的值相等，通过为原列表的切片赋值另一个列表来完成。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>  <span class="c1"># 延续上一节
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[:</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">]</span>  <span class="c1"># 相当于 x[0:0]，start 默认为 0 可以省略
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">):]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># 同理，stop 默认为列表长度可以省略
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># 也可以一次性添加多个元素
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <ul> <li>使用切片替换和修改列表中的元素</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># 延续上一节
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># 替换列表元素，等号两边列表的长度相等
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">9</span><span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>  <span class="c1"># 切片是连续的，等号两边列表的长度可以不相等
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># 切片不连续（step = 2），等号两边列表的长度必须相等
</span><span class="nb">ValueError</span><span class="p">:</span> <span class="n">attempt</span> <span class="n">to</span> <span class="n">assign</span> <span class="n">sequence</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">1</span> <span class="n">to</span> <span class="n">extended</span> <span class="nb">slice</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">6</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
</code></pre></div></div> <ul> <li>使用切片删除列表中的元素</li> </ul> <p>可以通过赋值空列表的方法来删除元素，也可以使用 <code class="language-plaintext highlighter-rouge">del</code> 命令与切片结合来删除元素，并且切片可以不连续。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>  <span class="c1"># 延续上一节
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 删除列表中前三个元素
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">del</span> <span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span>  <span class="c1"># 切片连续时 del 生效
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 切片不连续时赋值空列表的方法失效
</span><span class="nb">ValueError</span><span class="p">:</span> <span class="n">attempt</span> <span class="n">to</span> <span class="n">assign</span> <span class="n">sequence</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">0</span> <span class="n">to</span> <span class="n">extended</span> <span class="nb">slice</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">del</span> <span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># 切片不连续时 del 生效
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</code></pre></div></div> <ul> <li>切片得到的是列表的浅复制</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[::]</span>  <span class="c1"># 切片，浅复制
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">==</span> <span class="n">y</span>  <span class="c1"># 两个列表的值相等
</span><span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="ow">is</span> <span class="n">y</span>  <span class="c1"># 两个列表并不是同一个对象
</span><span class="bp">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">id</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nf">id</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># 两个列表对象的内存地址（值的引用）不相等
</span><span class="bp">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">id</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="nf">id</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># 但是相同的值在内存中只有一份
</span><span class="bp">True</span>
</code></pre></div></div> <h3 id="元组">元组</h3> <p>元组同样支持使用双向索引来访问其中的元素，但元组属于不可变序列，不可以直接修改元组中元素的值，也无法为元组增加或删除元素，只能使用 <code class="language-plaintext highlighter-rouge">del</code> 命令删除整个元组。元组的切片只能用来访问元组中的元素。从一定程度上讲，元组可以看作是轻量级的列表或”常量“列表，因此元组的访问速度要比列表更快。</p> <h4 id="生成器推导式">生成器推导式</h4> <p>生成器推导式使用圆括号作为定界符，与列表推导式最大的不同是，生成器推导式的结果是一个<strong>生成器对象</strong>。生成器对象属于迭代器对象，具有<strong>惰性求值</strong>的特点，只在需要时生成新元素，比列表推导式具有更高的效率。</p> <p>使用生成器对象的元素时，可以将其转化为列表或元组，也可以使用生成器对象的 <code class="language-plaintext highlighter-rouge">__next__()</code> 方法或内置函数 <code class="language-plaintext highlighter-rouge">next()</code> 进行遍历，或直接使用 for 循环来遍历。不管使用哪种方法，都只能从<strong>前向后正向访问</strong>其中的元素，<strong>没有任何方法可以再次访问已经访问过的元素（一个生成器对象中的元素只能访问一次），也不支持使用下标直接访问其中任意位置的元素</strong>。若需要重新访问元素，必须重新创建该生成器对象。enumerate、filter、map、zip 等对象也具有同样的特点。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">g</span> <span class="o">=</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>  <span class="c1"># 创建生成器对象
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">g</span>
<span class="o">&lt;</span><span class="n">generator</span> <span class="nb">object</span> <span class="o">&lt;</span><span class="n">genexpr</span><span class="o">&gt;</span> <span class="n">at</span> <span class="mh">0x00000293920A5890</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">tuple</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>  <span class="c1"># 将生成器对象转换为元组
</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">81</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">121</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">list</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>  <span class="c1"># 生成器对象已遍历结束，没有元素了
</span><span class="p">[]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">g</span> <span class="o">=</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>  <span class="c1"># 重新创建生成器对象
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">g</span><span class="p">.</span><span class="nf">__next__</span><span class="p">()</span>  <span class="c1"># 使用生成器对象的 __next__() 方法来获取元素
</span><span class="mi">4</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">g</span><span class="p">.</span><span class="nf">__next__</span><span class="p">()</span>
<span class="mi">9</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">next</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>  <span class="c1"># 使用内置函数 next() 来获取元素
</span><span class="mi">16</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="o">&lt;</span><span class="nb">map</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x00000293925182B0</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">next</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="sh">'</span><span class="s">0</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sh">'</span><span class="s">0</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">x</span>  <span class="c1"># 访问过的元素无法再次访问
</span><span class="bp">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sh">'</span><span class="s">1</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">x</span>  <span class="c1"># 未访问的元素
</span><span class="bp">True</span>
</code></pre></div></div> <h3 id="字典">字典</h3> <p>字典中元素的”键“可以是任意不可变数据，如整数、实数、复数、字符串、元组等类型的<strong>可哈希</strong>数据，但不能使用如列表、集合、字典等可变类型的数据。字典的”键“不允许重复，而”值“可以重复。字典在内部维护的哈希表使得检索操作非常快。使用内置字典类型 <code class="language-plaintext highlighter-rouge">dict</code> 时不必太在乎元素的顺序。如果需要一个可以严格记住元素插入顺序的字典，可以使用标准库 <code class="language-plaintext highlighter-rouge">collections</code> 中的 <code class="language-plaintext highlighter-rouge">OrderedDict</code> 类。</p> <p class="mynote">哈希是指能将大量的信息压缩成一个小的、固定大小的值的函数。如果一个对象是可哈希的，则其具有一个固定的哈希值，该值在该对象的整个生命周期都不会改变，即无论何时计算这个对象的哈希值，都会得到相同的结果（不可变的对象是可哈希的）。字典的键和集合的元素必须是可哈希的，才能借此进行快速查找。内置函数 <code class="language-plaintext highlighter-rouge">hash()</code> 可以用于测试一个对象是否可哈希，不必关心函数的返回值是什么，重点是对象是否可哈希，若对象不可哈希则会抛出异常。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">hash</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
<span class="o">-</span><span class="mi">6644214454873602895</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">hash</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">TypeError</span><span class="p">:</span> <span class="n">unhashable</span> <span class="nb">type</span><span class="p">:</span> <span class="sh">'</span><span class="s">list</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="字典元素的访问">字典元素的访问</h4> <p>字典中的每个元素表示一种映射关系，根据提供的”键“作为下标可以访问对应的”值“，若”键“不存在会抛出异常。字典提供了一个 <code class="language-plaintext highlighter-rouge">get(key)</code> 方法用于返回指定”键“对应的”值“，并且允许指定该”键“不存在时返回指定的”值“。字典还提供了 <code class="language-plaintext highlighter-rouge">setdefault(key, value)</code> 方法用于返回指定”键“对应的”值“，若该”键“不存在，就添加一个新元素并设置该”键“对应的”值“（默认为 None）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">]</span>
<span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">]</span>
<span class="nb">KeyError</span><span class="p">:</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">)</span>
<span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Not Exists.</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">Not Exists.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">setdefault</span><span class="p">(</span><span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
</code></pre></div></div> <p>对字典直接进行遍历时默认是遍历字典的”键“，若要遍历字典的元素需要使用字典的 <code class="language-plaintext highlighter-rouge">items()</code> 方法，若要遍历字典的”值“需要使用字典的 <code class="language-plaintext highlighter-rouge">values()</code> 方法。</p> <h4 id="字典元素的添加修改与删除">字典元素的添加、修改与删除</h4> <p>当以指定”键“为下标为字典元素赋值时，若该”键“存在，表示修改该”键“所对应的值，若不存在则表示添加一个新的”键值对“。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span>  <span class="c1"># 指定的键存在
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># 指定的键不存在
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
</code></pre></div></div> <p>字典的 <code class="language-plaintext highlighter-rouge">update()</code> 方法可以将另一个字典的元素一次性全部添加到当前字典中，若两个字典中存在相同的”键“，则以另一个字典中的”值“为准对当前字典进行更新。另外，也可以用上述的 <code class="language-plaintext highlighter-rouge">setdefault()</code> 方法来为字典添加新元素。<code class="language-plaintext highlighter-rouge">update()</code> 可以一次性添加多个元素，而 <code class="language-plaintext highlighter-rouge">setdefault()</code> 一次只能添加一个元素。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">update</span><span class="p">({</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">123</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">123</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
</code></pre></div></div> <p>字典的 <code class="language-plaintext highlighter-rouge">popitem()</code> 和 <code class="language-plaintext highlighter-rouge">pop(key[, default])</code> 方法可以弹出并删除指定的元素。<code class="language-plaintext highlighter-rouge">popitem()</code> 方法无参数，删除并返回最后添加进字典的元素，对空字典会抛出异常。<code class="language-plaintext highlighter-rouge">pop()</code> 方法弹出指定”键“对应的元素，<code class="language-plaintext highlighter-rouge">default</code> 参数指定若”键“不存在时返回的指定的值。当然，也可以用 <code class="language-plaintext highlighter-rouge">del</code> 命令来删除指定的元素。字典的 <code class="language-plaintext highlighter-rouge">clear()</code> 方法用于清空字典中的所有元素，<code class="language-plaintext highlighter-rouge">copy()</code> 方法用于返回字典的浅复制。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="sh">'</span><span class="s">e</span><span class="sh">'</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">popitem</span><span class="p">()</span>
<span class="p">(</span><span class="sh">'</span><span class="s">e</span><span class="sh">'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">)</span>
<span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">clear</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{}</span>
</code></pre></div></div> <h3 id="集合">集合</h3> <p>集合中的元素必须是不可变类型的数据，并且元素之间不允许重复。</p> <h4 id="集合元素的添加与删除">集合元素的添加与删除</h4> <p>集合的 <code class="language-plaintext highlighter-rouge">add()</code> 方法用于添加新元素，若该元素已存在则忽略该操作，不会抛弃异常。<code class="language-plaintext highlighter-rouge">update()</code> 方法用于合并另一个集合中的元素到当前集合中，并自动去除重复元素。</p> <p>集合的 <code class="language-plaintext highlighter-rouge">pop()</code> 方法会从前向后删除并返回集合中的一个元素，若集合为空则抛出异常。<code class="language-plaintext highlighter-rouge">remove(x)</code> 方法用于删除集合中特定值的元素，若不存在则抛出异常。<code class="language-plaintext highlighter-rouge">discard(x)</code> 方法功能同 <code class="language-plaintext highlighter-rouge">remove()</code>，但若元素不存在会自动忽略，而不会抛出异常。<code class="language-plaintext highlighter-rouge">clear()</code> 用于清空集合。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">update</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
<span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
<span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">KeyError</span><span class="p">:</span> <span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">discard</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="p">{</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">clear</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="nf">set</span><span class="p">()</span>
</code></pre></div></div> <h4 id="集合运算">集合运算</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b_set</span> <span class="o">=</span> <span class="p">{</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span> <span class="o">|</span> <span class="n">b_set</span>  <span class="c1"># 并集
</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span><span class="p">.</span><span class="nf">union</span><span class="p">(</span><span class="n">b_set</span><span class="p">)</span>
<span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span> <span class="o">&amp;</span> <span class="n">b_set</span>  <span class="c1"># 交集
</span><span class="p">{</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span><span class="p">.</span><span class="nf">intersection</span><span class="p">(</span><span class="n">b_set</span><span class="p">)</span>
<span class="p">{</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span> <span class="o">-</span> <span class="n">b_set</span>  <span class="c1"># 差集（A - B 返回包含在集合 A 中但不包含在集合 B 中的所有元素）
</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span><span class="p">.</span><span class="nf">difference</span><span class="p">(</span><span class="n">b_set</span><span class="p">)</span>
<span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span> <span class="o">^</span> <span class="n">b_set</span>  <span class="c1"># 对称差集（A 的差集与 B 的差集的并集，即 (A - B) | (B - A)）
</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a_set</span><span class="p">.</span><span class="nf">symmetric_difference</span><span class="p">(</span><span class="n">b_set</span><span class="p">)</span>
<span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span> <span class="o">=</span> <span class="p">{</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">y</span>  <span class="c1"># 子集
</span><span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="nf">issubset</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">&gt;</span> <span class="n">x</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="p">.</span><span class="nf">issuperset</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="p">.</span><span class="nf">isdisjoint</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>  <span class="c1"># 测试交集是否为空
</span><span class="bp">True</span>
</code></pre></div></div> <h3 id="序列解包"><strong>序列解包</strong></h3> <p>序列解包也可以称为多重赋值。星号 <code class="language-plaintext highlighter-rouge">*</code> 在列表、元组、字典（默认为对”键“操作）、集合、字符串等可迭代对象前使用，表示序列解包，即将其中的元素一一展开。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span>  <span class="c1"># 多个变量同时赋值
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span>
<span class="sh">'</span><span class="s">a</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span>  <span class="c1"># 交换两个变量的值
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="mi">4</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># * 表示可迭代对象的序列解包
</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="mi">4</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</code></pre></div></div> <h2 id="字符串-1">字符串</h2> <p>字符串属于<strong>不可变有序</strong>序列，同样支持双向索引、比较大小、计算长度、元素访问、切片、成员测试（in）等。由于字符串不可变，所以所有对字符串对象涉及“修改”的方法都是返回修改后的新字符串，原字符串并无任何改变。</p> <h3 id="字符串编码格式">字符串编码格式</h3> <p><code class="language-plaintext highlighter-rouge">UTF-8</code> 以一个字节表示英语字符，以三个字节表示常用汉字。</p> <p><code class="language-plaintext highlighter-rouge">GB2312/GBK</code> 前者是我国制定的中文编码，以一个字节表示英语字符，以两个字节表示常用汉字。</p> <p>Python 3 完全支持中文字符，默认使用 <code class="language-plaintext highlighter-rouge">UTF-8</code> 编码格式，无论是一个数字、英文字母，还是一个汉字，计算字符串长度时都按一个字符处理。</p> <h3 id="转义字符">转义字符</h3> <table> <thead> <tr> <th style="text-align: left">转义字符</th> <th style="text-align: left">含义</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\n</code></td> <td style="text-align: left">换行符</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\f</code></td> <td style="text-align: left">换页符</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\t</code></td> <td style="text-align: left">制表符（Tab）</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\r</code></td> <td style="text-align: left">回车</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\\</code></td> <td style="text-align: left">一个反斜线</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\'</code></td> <td style="text-align: left">一个单引号</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\"</code></td> <td style="text-align: left">一个双引号</td> </tr> </tbody> </table> <p>在使用文件路径、URL和正则表达式等场景下时，为了避免对字符串中的转义字符进行转义，可以使用原始字符串。在字符串的前面加上字母 r 或 R 表示原始字符串。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">C:\Windows</span><span class="se">\n</span><span class="s">otepad.exe</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">C</span><span class="p">:</span>\<span class="n">Windows</span>
<span class="n">otepad</span><span class="p">.</span><span class="n">exe</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">path</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">'</span><span class="s">C:\Windows\notepad.exe</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">C</span><span class="p">:</span>\<span class="n">Windows</span>\<span class="n">notepad</span><span class="p">.</span><span class="n">exe</span>
</code></pre></div></div> <h3 id="字符串格式化">字符串格式化</h3> <h4 id="-formatting"><code class="language-plaintext highlighter-rouge">%-formatting</code></h4> <p>格式规范：<code class="language-plaintext highlighter-rouge">'%[-][+][0][m][.n][格式字符]' % x</code></p> <p><code class="language-plaintext highlighter-rouge">[-]</code> 用于指定<code class="language-plaintext highlighter-rouge">x</code>为左对齐。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Hello, %-10s</span><span class="sh">'</span> <span class="o">%</span> <span class="n">a</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="sh">'</span><span class="s">Hello, Leon      </span><span class="sh">'</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[+]</code> 用于对正数加正号。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">1234</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="sh">'</span><span class="s">%+d</span><span class="sh">'</span> <span class="o">%</span> <span class="n">a</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="sh">'</span><span class="s">+1234</span><span class="sh">'</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[0]</code> 用于指定空位填0，适用于数值型的格式符（<code class="language-plaintext highlighter-rouge">%d</code>、<code class="language-plaintext highlighter-rouge">%f</code>）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">7</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="sh">'</span><span class="s">%03d</span><span class="sh">'</span> <span class="o">%</span> <span class="n">a</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="sh">'</span><span class="s">007</span><span class="sh">'</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[m]</code> 用于指定最小宽度。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Hello, %10s</span><span class="sh">'</span> <span class="o">%</span> <span class="n">a</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="sh">'</span><span class="s">Hello,       Leon</span><span class="sh">'</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[.n]</code> 用于指定浮点数的精度。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">1234</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="sh">'</span><span class="s">%.2f</span><span class="sh">'</span> <span class="o">%</span> <span class="n">a</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="sh">'</span><span class="s">1234.00</span><span class="sh">'</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[格式字符]</code></p> <table> <thead> <tr> <th style="text-align: left">格式字符</th> <th style="text-align: left">含义</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">s</code></td> <td style="text-align: left">字符串</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">c</code></td> <td style="text-align: left">整数转化为 Unicode 字符、字符串转化为其第一个字符</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">d</code></td> <td style="text-align: left">十进制整数</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">o</code></td> <td style="text-align: left">八进制整数</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">x</code></td> <td style="text-align: left">十六进制整数</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">e</code></td> <td style="text-align: left">以 e 为底的指数</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">f</code></td> <td style="text-align: left">浮点数</td> </tr> </tbody> </table> <p><code class="language-plaintext highlighter-rouge">x</code> 待格式化的内容，需与格式字符一一对应。</p> <h4 id="strformat"><strong><code class="language-plaintext highlighter-rouge">str.format()</code></strong></h4> <p>格式规范：<code class="language-plaintext highlighter-rouge">"{[field_name]:[format_spec]}".format(x)</code></p> <p><code class="language-plaintext highlighter-rouge">[field_name]</code> 用于指定要插入的变量 <code class="language-plaintext highlighter-rouge">x</code> 的名称或用数字表示索引（从 0 开始）。</p> <p><code class="language-plaintext highlighter-rouge">[format_spec]</code> = <code class="language-plaintext highlighter-rouge">[[fill]align][sign][#][0][width][grouping_option][.precision][type]</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 使用数字表示索引
</span><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">0: {0:.4s}, 1: {1:.4s}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">))</span>
<span class="mi">0</span><span class="p">:</span> <span class="n">drea</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="n">drug</span>

<span class="c1"># 使用关键字参数和属性（ arg_name.attr_name ）
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Person</span><span class="p">:</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">age</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
		<span class="n">self</span><span class="p">.</span><span class="n">age</span> <span class="o">=</span> <span class="n">age</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">person</span> <span class="o">=</span> <span class="nc">Person</span><span class="p">(</span><span class="sh">"</span><span class="s">Leon</span><span class="sh">"</span><span class="p">,</span> <span class="mi">22</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">msg</span> <span class="o">=</span> <span class="sh">"</span><span class="s">My name is {person.name}, and I am {person.age} years old.</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">person</span><span class="o">=</span><span class="n">person</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="n">My</span> <span class="n">name</span> <span class="ow">is</span> <span class="n">Leon</span><span class="p">,</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">am</span> <span class="mi">22</span> <span class="n">years</span> <span class="n">old</span><span class="p">.</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[fill]</code> 填充字符，用于填充空白部分的单个字符，可以为任意字符，默认为空格。</p> <p><code class="language-plaintext highlighter-rouge">[align]</code> 对齐方式，<code class="language-plaintext highlighter-rouge">&lt;</code> 表示左对齐，<code class="language-plaintext highlighter-rouge">&gt;</code> 表示右对齐，<code class="language-plaintext highlighter-rouge">^</code> 表示居中对齐，<code class="language-plaintext highlighter-rouge">=</code> 表示将填充字符放在符号和数字之间（仅适用于数值类型）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">{:*^20}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">PYTHON</span><span class="sh">"</span><span class="p">))</span>  <span class="c1"># 填充字符为 * 并居中对齐
</span><span class="o">*******</span><span class="n">PYTHON</span><span class="o">*******</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[sign]</code> 符号，<code class="language-plaintext highlighter-rouge">+</code> 表示在正数前面显示正号和负号，<code class="language-plaintext highlighter-rouge">-</code> 表示只在负数前显示负号（默认行为），<code class="language-plaintext highlighter-rouge"> </code> 空格表示在正数前面留空格。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">{:=+10}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="mi">22</span><span class="p">))</span>  <span class="c1"># 将填充字符（空格）放在正号与数字之间
</span><span class="o">+</span>       <span class="mi">22</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[#]</code> 对于二进制、八进制、十六进制，如果加上 <code class="language-plaintext highlighter-rouge">#</code>，则会加上 <code class="language-plaintext highlighter-rouge">0b</code>、<code class="language-plaintext highlighter-rouge">0o</code> 或 <code class="language-plaintext highlighter-rouge">0x</code> 前缀。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">{:#b}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="mi">22</span><span class="p">))</span>
<span class="mb">0b10110</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[0]</code> 用于指定空位填充为0（仅对数值类型有效）。</p> <p><code class="language-plaintext highlighter-rouge">[width]</code> 用于指定输出的最小字符宽度。如果输出的值小于这个数，将会使用填充字符补足。</p> <p><code class="language-plaintext highlighter-rouge">[grouping_option]</code> 指定数字的千位分隔符为 <code class="language-plaintext highlighter-rouge">_</code> 或 <code class="language-plaintext highlighter-rouge">,</code>。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">{:_}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="mi">5000000</span><span class="p">))</span>
<span class="mi">5_000_000</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[.precision]</code> 精度，对于浮点数，表示小数点后的位数。对于字符串，表示输出的最大字符数。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">{:.2f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="mf">3.1415926</span><span class="p">))</span>
<span class="mf">3.14</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">{:.3s}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">ecust</span><span class="sh">'</span><span class="p">))</span>
<span class="n">ecu</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[type]</code></p> <table> <thead> <tr> <th style="text-align: left">格式字符</th> <th style="text-align: left">含义</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">b</code></td> <td style="text-align: left">二进制整数</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">%</code></td> <td style="text-align: left">输出百分比形式的浮点数（<code class="language-plaintext highlighter-rouge">"{:.2%}".format(0.25)</code>）</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">s</code>、<code class="language-plaintext highlighter-rouge">d</code>、<code class="language-plaintext highlighter-rouge">o</code>、<code class="language-plaintext highlighter-rouge">x</code>、<code class="language-plaintext highlighter-rouge">e</code>、<code class="language-plaintext highlighter-rouge">f</code>、<code class="language-plaintext highlighter-rouge">c</code></td> <td style="text-align: left">同 <a href="#-formatting"><code class="language-plaintext highlighter-rouge">%-formatting</code></a></td> </tr> </tbody> </table> <h4 id="f-string"><strong><code class="language-plaintext highlighter-rouge">f-string</code></strong></h4> <p>格式规范：<code class="language-plaintext highlighter-rouge">f"{[f_expression]:[format_spec]}"</code>，更详细见 <a href="https://docs.python.org/3.7/reference/lexical_analysis.html#formatted-string-literals">Python 官方教程 - Literals - Formatted string literals</a>。</p> <p><code class="language-plaintext highlighter-rouge">[f_expression]</code> 可以是任何有效的 Python 表达式，如变量名、算术表达式、调用函数、条件表达式、访问对象属性等。当<code class="language-plaintext highlighter-rouge">f-string</code> 被计算时，这个表达式的值会被计算并转换为字符串。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 变量名 / 方法调用
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Leon</span><span class="sh">"</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="sh">"</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">name</span><span class="p">.</span><span class="nf">upper</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span>

<span class="c1"># 算术表达式
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">20</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="si">}</span><span class="sh">"</span>

<span class="c1"># 列表和字典访问
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">numbers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">info</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">:</span> <span class="mi">22</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">numbers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span>

<span class="c1"># 调用函数
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
	<span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Hello, </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">!</span><span class="sh">"</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Leon</span><span class="sh">"</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="nf">greet</span><span class="p">(</span><span class="n">name</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span>

<span class="c1"># 条件表达式（三元运算符）
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">x</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="k">else</span> <span class="sh">'</span><span class="s">x is less than or equal to 10</span><span class="sh">'</span><span class="si">}</span><span class="sh">"</span>

<span class="c1"># 访问对象属性
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Person</span><span class="p">:</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">age</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
		<span class="n">self</span><span class="p">.</span><span class="n">age</span> <span class="o">=</span> <span class="n">age</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">person</span> <span class="o">=</span> <span class="nc">Person</span><span class="p">(</span><span class="sh">"</span><span class="s">Leon</span><span class="sh">"</span><span class="p">,</span> <span class="mi">22</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sa">f</span><span class="sh">"</span><span class="s">My name is </span><span class="si">{</span><span class="n">person</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s">, and I am </span><span class="si">{</span><span class="n">person</span><span class="p">.</span><span class="n">age</span><span class="si">}</span><span class="s"> years old.</span><span class="sh">"</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">[format_spec]</code> 同 <a href="#strformat"><code class="language-plaintext highlighter-rouge">str.format()</code></a>。</p> <h3 id="字符串常用操作">字符串常用操作</h3> <h4 id="查找">查找</h4> <p><code class="language-plaintext highlighter-rouge">find()</code>、<code class="language-plaintext highlighter-rouge">rfind()</code> 用于查找一个字符串在另一个字符串指定范围（默认为整个字符串）中首次和最后一次出现的位置，若不存在则返回 -1。<code class="language-plaintext highlighter-rouge">rfind()</code> 相当于从右向左查找。</p> <p>参数：<code class="language-plaintext highlighter-rouge">find(sub[, start[, end]]) -&gt; int</code> <sup id="fnref:args" role="doc-noteref"><a href="#fn:args" class="footnote" rel="footnote">2</a></sup></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">apple, peach, banana, peach, pear</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="sh">'</span><span class="s">p</span><span class="sh">'</span><span class="p">)</span>
<span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="sh">'</span><span class="s">p</span><span class="sh">'</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="mi">7</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">index()</code>、<code class="language-plaintext highlighter-rouge">rindex()</code> 用法同上，不同之处在于，若不存在则抛出异常。</p> <p><code class="language-plaintext highlighter-rouge">count()</code> 用于查找一个字符串在另一个字符串中出现的次数，若不存在则返回 0。</p> <h4 id="分隔">分隔</h4> <p><code class="language-plaintext highlighter-rouge">split()</code>、<code class="language-plaintext highlighter-rouge">rsplit()</code> 用于以指定的分隔符，从字符串的左端和右端开始将其分隔成多个字符串，并以列表形式返回。</p> <p>参数：<code class="language-plaintext highlighter-rouge">split([sep[, maxsplit]])</code> <code class="language-plaintext highlighter-rouge">sep</code> 参数指定分隔符，<code class="language-plaintext highlighter-rouge">maxsplit</code> 参数指定分隔的最大次数，默认为 -1，即没有限制。若不指定分隔符，则字符串中任何空白符号（包括空格、换行符、制表符等）都将被认为是分隔符（多个连续的空白符号视为一个），返回不含空字符串的列表。但是，明确传递 <code class="language-plaintext highlighter-rouge">sep</code> 参数时，连续的相邻分隔符之间会得到空字符串。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">apple, peach, banana, peach, pear</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">)</span>
<span class="p">[</span><span class="sh">'</span><span class="s">apple</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s"> peach</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s"> banana</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s"> peach</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s"> pear</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">e</span><span class="sh">'</span><span class="p">)</span>
<span class="p">[</span><span class="sh">'</span><span class="s">appl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">, p</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ach, banana, p</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ach, p</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ar</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">partition()</code>、<code class="language-plaintext highlighter-rouge">rpartition()</code> 用于以指定的分隔符将原字符串分隔为三部分，即分隔符之前的字符串、分隔符字符串、分隔符之后的字符串，并以元组的形式返回。若指定的分隔符不存在，则返回原字符串和两个空字符串。若存在多个指定的分隔符，<code class="language-plaintext highlighter-rouge">partition()</code> 以从左向右的第一个分隔符作为分隔符，<code class="language-plaintext highlighter-rouge">rpartition()</code> 则相反。</p> <h4 id="连接"><strong>连接</strong></h4> <p><code class="language-plaintext highlighter-rouge">join()</code> 以指定的连接符将多个字符串（多为列表形式）连接，返回新字符串。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">li</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">apple</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">peach</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">banana</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">pear</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">li</span><span class="p">)</span>  <span class="c1"># 以空格作为连接符
</span><span class="sh">'</span><span class="s">apple peach banana pear</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">li</span><span class="p">)</span>
<span class="sh">'</span><span class="s">apple,peach,banana,pear</span><span class="sh">'</span>  <span class="c1"># 以逗号作为连接符
</span></code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">join()</code> 和 <code class="language-plaintext highlighter-rouge">split()</code> 可以一起用于删除字符串中多余的空白字符，如果有连续多个空白字符，只保留一个。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">aaa     bb   c d eee  </span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">s</span><span class="p">.</span><span class="nf">split</span><span class="p">())</span>
<span class="sh">'</span><span class="s">aaa bb c d eee</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="大小写转换">大小写转换</h4> <p><code class="language-plaintext highlighter-rouge">lower()</code>、<code class="language-plaintext highlighter-rouge">upper()</code> 用于将字符串转换为小写、大写的字符串。</p> <p><code class="language-plaintext highlighter-rouge">capitalize()</code> 用于将字符串的首字母转换为大写。</p> <p><code class="language-plaintext highlighter-rouge">title()</code> 用于将字符串中的每个单词的首字母转换为大写。</p> <p><code class="language-plaintext highlighter-rouge">swapcase()</code> 用于将大小写互换。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">What is Your Name?</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
<span class="sh">'</span><span class="s">what is your name?</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">upper</span><span class="p">()</span>
<span class="sh">'</span><span class="s">WHAT IS YOUR NAME?</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">capitalize</span><span class="p">()</span>
<span class="sh">'</span><span class="s">What is your name?</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">title</span><span class="p">()</span>
<span class="sh">'</span><span class="s">What Is Your Name?</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">swapcase</span><span class="p">()</span>
<span class="sh">'</span><span class="s">wHAT IS yOUR nAME?</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="替换">替换</h4> <p><code class="language-plaintext highlighter-rouge">replace()</code> 用于替换字符串中的指定字符，每次只能替换一种指定的字符。</p> <p>参数：<code class="language-plaintext highlighter-rouge">replace(old, new[, count])</code> 若提供了 <code class="language-plaintext highlighter-rouge">count</code> 参数，则只替换前 <code class="language-plaintext highlighter-rouge">count</code> 次出现的 <code class="language-plaintext highlighter-rouge">old</code> 字符。<code class="language-plaintext highlighter-rouge">count</code> 参数默认为 -1，即全部替换。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">a, b, c, a, a, d</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">123</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">123, b, c, 123, 123, d</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">123</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="sh">'</span><span class="s">123, b, c, a, a, d</span><span class="sh">'</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">maketrans()</code>、<code class="language-plaintext highlighter-rouge">translate()</code> 前者用于生成一个字符映射表，指定字符的一一对应的转换关系。而后者用于按照映射表的对应关系来替换字符串中的字符。这两个方法组合可以同时处理多个不同的单字符。</p> <p>参数：<code class="language-plaintext highlighter-rouge">maketrans(input, output[, delete])</code> 可选参数 <code class="language-plaintext highlighter-rouge">delete</code> 用于指定将在 <code class="language-plaintext highlighter-rouge">translate()</code> 后被删除的字符。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">My favorite color is purple.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">table</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">maketrans</span><span class="p">(</span><span class="sh">'</span><span class="s">abcdefghij</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">0123456789</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 创建转换表，也可以用 str.maketrans()
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">translate</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="sh">'</span><span class="s">My 50vor8t4 2olor 8s purpl4.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">table</span> <span class="o">=</span> <span class="nb">str</span><span class="p">.</span><span class="nf">maketrans</span><span class="p">(</span><span class="sh">'</span><span class="s">abcdefghij</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">0123456789</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">l</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">translate</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="sh">'</span><span class="s">My 50vor8t4 2oor 8s purp4.</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="修剪"><strong>修剪</strong></h4> <p><code class="language-plaintext highlighter-rouge">strip()</code>、<code class="language-plaintext highlighter-rouge">rstrip()</code>、<code class="language-plaintext highlighter-rouge">lstrip()</code> 用于删除字符串两端、右端和左端的连续的空白字符或指定字符。其参数所指定的字符并不视为整体，而是单独一个一个删除。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">  12345 </span><span class="se">\n\n</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>
<span class="sh">'</span><span class="s">12345</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">aaahelloworlddddaa</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">helloworldddd</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'</span><span class="s">ad</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 删除 'a' 和 'd'
</span><span class="sh">'</span><span class="s">helloworl</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="判断">判断</h4> <p><code class="language-plaintext highlighter-rouge">startswith()</code>、<code class="language-plaintext highlighter-rouge">endswith()</code>用于判断字符串的前缀和后缀是否是指定的字符串，返回 True 或 False。</p> <p>参数：<code class="language-plaintext highlighter-rouge">s.startswith(prefix[, start[, end]]) -&gt; bool</code>、<code class="language-plaintext highlighter-rouge">s.endswith(suffix[, start[, end]]) -&gt; bool</code> <code class="language-plaintext highlighter-rouge">start</code> 和 <code class="language-plaintext highlighter-rouge">end</code> 参数用于指定字符串的检测范围。</p> <p><code class="language-plaintext highlighter-rouge">endswith()</code> 可接收字符串元组作为参数来判断文件的扩展名。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">filename</span> <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="sh">'</span><span class="s">E:</span><span class="se">\\</span><span class="sh">'</span><span class="p">)</span> <span class="k">if</span> <span class="n">filename</span><span class="p">.</span><span class="nf">endswith</span><span class="p">((.</span><span class="n">png</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="n">jpg</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="n">gif</span><span class="sh">'</span><span class="s">))]
[</span><span class="sh">'</span><span class="n">logo</span><span class="p">.</span><span class="n">png</span><span class="sh">'</span><span class="s">]
</span></code></pre></div></div> <h4 id="检查">检查</h4> <p>通过运算符 <code class="language-plaintext highlighter-rouge">in</code> 可以判断一个字符串是否出现在另一个字符串中，返回 True 或 False。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="sh">'</span><span class="s">e</span><span class="sh">'</span> <span class="ow">in</span> <span class="sh">'</span><span class="s">Dreamless Drugs</span><span class="sh">'</span>
<span class="bp">True</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">isalnum()</code> 用于检查字符串中的所有字符是否都是字母或数字，返回 True 或 False。</p> <p><code class="language-plaintext highlighter-rouge">isalpha()</code> 用于检查字符串中的所有字符是否都是字母，返回 True 或 False。</p> <p><code class="language-plaintext highlighter-rouge">isdigit()</code> 用于检查字符串中的所有字符是否都是数字，返回 True 或 False。</p> <p><code class="language-plaintext highlighter-rouge">isdecimal()</code> 用于检查字符串中的所有字符是否都是十进制数字，返回 True 或 False。它比 <code class="language-plaintext highlighter-rouge">isdigit()</code> 更严格。</p> <p><code class="language-plaintext highlighter-rouge">isnumeric()</code> 用于检查字符串中的所有字符是否都是数字或用 Unicode 表示的数字，返回 True 或 False。</p> <p><code class="language-plaintext highlighter-rouge">isspace()</code> 用于检查字符串中的所有字符是否都是空白字符，返回 True 或 False。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="sh">"</span><span class="se">\t\n\r</span><span class="sh">"</span><span class="p">.</span><span class="nf">isspace</span><span class="p">()</span>
<span class="bp">True</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">isupper()</code> 、<code class="language-plaintext highlighter-rouge">islower()</code> 用于检查字符串中的所有字符是否都是大写、小写，返回 True 或 False。</p> <h4 id="排版">排版</h4> <p><code class="language-plaintext highlighter-rouge">center()</code>、<code class="language-plaintext highlighter-rouge">ljust()</code>、<code class="language-plaintext highlighter-rouge">rjust()</code> 返回指定宽度的新字符串，原字符串以居中、左对齐、右对齐的对齐方式出现在新字符串中。若指定的宽度大于原字符串长度，则用指定的字符填充。</p> <p>参数：<code class="language-plaintext highlighter-rouge">s.center(width[, fillchar]) -&gt; copy of s</code></p> <p><code class="language-plaintext highlighter-rouge">zfill()</code> 返回指定宽度的字符串，在左侧以字符 0 填充。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Dreamless Drugs</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">center</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="sh">'</span><span class="s">  Dreamless Drugs   </span><span class="sh">'</span>  <span class="c1"># 默认以空格填充
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">center</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">==Dreamless Drugs===</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">ljust</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">Dreamless Drugs=====</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">rjust</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">=====Dreamless Drugs</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="nf">zfill</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="sh">'</span><span class="s">00000Dreamless Drugs</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="切片-1">切片</h4> <p>字符串同样能使用切片功能，但仅限于读取其中的元素，不支持字符串修改。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Dreamless Drugs</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="sh">'</span><span class="s">Dream</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="输入转换">输入转换</h4> <p>用户通过 <code class="language-plaintext highlighter-rouge">input()</code> 的输入都为字符串类型，对于整数、实数和复数可以直接使用<code class="language-plaintext highlighter-rouge">int()</code>、<code class="language-plaintext highlighter-rouge">float()</code> 和 <code class="language-plaintext highlighter-rouge">complex()</code> 进行转换，而对于列表、元组等需要使用 <code class="language-plaintext highlighter-rouge">eval()</code> 进行转换而不能直接使用 <code class="language-plaintext highlighter-rouge">list()</code> 和 <code class="language-plaintext highlighter-rouge">tuple()</code>。为了检查用户输入的字符串是否是安全的，可以使用标准库 <code class="language-plaintext highlighter-rouge">ast</code> 中的安全函数 <code class="language-plaintext highlighter-rouge">literal_eval()</code>。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="nf">input</span><span class="p">()</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="sh">'</span><span class="s">[1, 3, 5, 7, 9]</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">eval</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">ast</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ast</span><span class="p">.</span><span class="nf">literal_eval</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 更推荐
</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
</code></pre></div></div> <h2 id="正则表达式">正则表达式</h2> <p>正则表达式（Regular Expression）可以使用预定义的模式去匹配一类具有共同特征的字符串，其功能通过标准库 <code class="language-plaintext highlighter-rouge">re</code> 提供。【<a href="https://docs.python.org/3/howto/regex.html?highlight=regular%20expression#regular-expression-howto">官方教程</a>】</p> <h3 id="正则表达式语法">正则表达式语法</h3> <table> <thead> <tr> <th style="text-align: left">元字符</th> <th style="text-align: left">说明</th> <th style="text-align: left">示例</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">.</code></td> <td style="text-align: left">默认模式下，匹配除换行符之外的任意单个字符</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">[]</code></td> <td style="text-align: left">匹配位于 <code class="language-plaintext highlighter-rouge">[]</code> 中的任意一个字符</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">[a-z]</code> 匹配任意一个小写字母、<code class="language-plaintext highlighter-rouge">[0-5][0-9]</code> 匹配所有两位数 00 到 59</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">-</code></td> <td style="text-align: left">在 <code class="language-plaintext highlighter-rouge">[]</code> 之内用于表示范围</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">[a\-z]</code> 使用转义后可匹配字符 <code class="language-plaintext highlighter-rouge">-</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">^</code></td> <td style="text-align: left">匹配以 <code class="language-plaintext highlighter-rouge">^</code> 后面的字符串开头的字符串</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">^http</code> 只匹配以 <code class="language-plaintext highlighter-rouge">'http'</code> 开头的字符串</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">[^]</code></td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">^</code> 放在 <code class="language-plaintext highlighter-rouge">[]</code> 内表示反向字符集</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">[^xyz]</code> 匹配除了 <code class="language-plaintext highlighter-rouge">'x'</code>、<code class="language-plaintext highlighter-rouge">'y'</code> 和 <code class="language-plaintext highlighter-rouge">'z'</code> 之外的任何字符</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">$</code></td> <td style="text-align: left">匹配在换行符之前以 <code class="language-plaintext highlighter-rouge">$</code> 前面的字符串结束的字符串</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">foo.$</code> 在 <code class="language-plaintext highlighter-rouge">'foo1\n'</code> 中的匹配结果为 <code class="language-plaintext highlighter-rouge">'foo1'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">|</code></td> <td style="text-align: left">匹配位于 <code class="language-plaintext highlighter-rouge">|</code> 之前或之后的字符（正则表达式），可以用 <code class="language-plaintext highlighter-rouge">|</code> 分隔任意数量，匹配时将从左向右依次尝试，当完全匹配时后面的分支将不会被进一步测试</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">A|B|C|D</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">*</code></td> <td style="text-align: left">匹配位于 <code class="language-plaintext highlighter-rouge">*</code> 之前的单个字符或模式的 0 次或多次重复</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">ca*t</code> 可以匹配 <code class="language-plaintext highlighter-rouge">'ct'</code>（0 次 <code class="language-plaintext highlighter-rouge">'a'</code>）、<code class="language-plaintext highlighter-rouge">'cat'</code>（1 次 <code class="language-plaintext highlighter-rouge">'a'</code>）和 <code class="language-plaintext highlighter-rouge">'caaat'</code>（3 次 <code class="language-plaintext highlighter-rouge">'a'</code>）等</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">+</code></td> <td style="text-align: left">匹配位于 <code class="language-plaintext highlighter-rouge">+</code> 之前的单个字符或模式的 1 次或多次重复</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">ca+t</code> 不会匹配 <code class="language-plaintext highlighter-rouge">'ct'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">?</code></td> <td style="text-align: left">表示 <code class="language-plaintext highlighter-rouge">?</code> 之前的字符是可选的，即它可以出现 0 次或 1 次</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">ab?</code> 可以匹配 <code class="language-plaintext highlighter-rouge">'a'</code> 或 <code class="language-plaintext highlighter-rouge">'ab'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">*?</code>、<code class="language-plaintext highlighter-rouge">+?</code>、<code class="language-plaintext highlighter-rouge">??</code></td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">?</code> 在其他元字符之后表示非贪婪模式，即匹配尽可能少的字符串，而 <code class="language-plaintext highlighter-rouge">*</code>、<code class="language-plaintext highlighter-rouge">+</code>、<code class="language-plaintext highlighter-rouge">?</code> 都是匹配尽可能多的字符串</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">&lt;.*&gt;</code> 在 <code class="language-plaintext highlighter-rouge">'&lt;a&gt; b &lt;c&gt;'</code> 中将匹配整个字符串，而 <code class="language-plaintext highlighter-rouge">&lt;.*?&gt;</code> 将只匹配 <code class="language-plaintext highlighter-rouge">'&lt;a&gt;'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">{m}</code></td> <td style="text-align: left">指定 <code class="language-plaintext highlighter-rouge">{m}</code> 前一个字符的匹配次数</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">a{6}</code> 将恰好匹配 6 个 <code class="language-plaintext highlighter-rouge">'a'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">{m,n}</code></td> <td style="text-align: left">指定匹配 <code class="language-plaintext highlighter-rouge">{m,n}</code> 前一个字符 m 到 n 次，将尝试匹配尽可能多的重复，若省略 m 则指定下限为零，若省略 n 则指定无上限</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">a{4,}b</code> 将匹配 <code class="language-plaintext highlighter-rouge">'aaaab'</code> 以及在 <code class="language-plaintext highlighter-rouge">'b'</code> 前面有更多 <code class="language-plaintext highlighter-rouge">'a'</code> 的字符串，但不会匹配 <code class="language-plaintext highlighter-rouge">'aaab'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">{m,n}?</code></td> <td style="text-align: left">使 <code class="language-plaintext highlighter-rouge">{m,n}</code> 尝试匹配尽可能少的重复</td> <td style="text-align: left">对于字符串 <code class="language-plaintext highlighter-rouge">'aaaaaa'</code>，<code class="language-plaintext highlighter-rouge">a{3,5}</code> 将匹配 5 个 <code class="language-plaintext highlighter-rouge">'a'</code>，<code class="language-plaintext highlighter-rouge">a{3,5}?</code> 将匹配 3 个 <code class="language-plaintext highlighter-rouge">'a'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\</code></td> <td style="text-align: left">用于转义所有元字符，以及 <code class="language-plaintext highlighter-rouge">\</code> 后面可以跟各种字符来表示各种特殊序列</td> <td style="text-align: left">使用 <code class="language-plaintext highlighter-rouge">\\$</code> 来匹配 <code class="language-plaintext highlighter-rouge">'$'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\A</code></td> <td style="text-align: left">确保匹配将从字符串的开头位置开始</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\b</code></td> <td style="text-align: left">表示单词边界，匹配单词头或单词尾</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">r'\bcat\b'</code> 只匹配包含单词 <code class="language-plaintext highlighter-rouge">'cat'</code> 的字符串，但不会匹配 <code class="language-plaintext highlighter-rouge">'concatenate'</code> 中的 <code class="language-plaintext highlighter-rouge">'cat'</code> 部分</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\B</code></td> <td style="text-align: left">与 <code class="language-plaintext highlighter-rouge">\b</code> 含义相反，表示非单词边界</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">r'\Bcat\B'</code> 会匹配 <code class="language-plaintext highlighter-rouge">'concatenate'</code> 中的 <code class="language-plaintext highlighter-rouge">'cat'</code> 部分，但不会匹配独立的单词 <code class="language-plaintext highlighter-rouge">'cat'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\d</code></td> <td style="text-align: left">匹配任何数字，相当于 <code class="language-plaintext highlighter-rouge">[0-9]</code></td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\d</code> 会在字符串 <code class="language-plaintext highlighter-rouge">'apple123'</code> 中匹配 <code class="language-plaintext highlighter-rouge">'1'</code>、<code class="language-plaintext highlighter-rouge">'2'</code> 和 <code class="language-plaintext highlighter-rouge">'3'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\D</code></td> <td style="text-align: left">与 <code class="language-plaintext highlighter-rouge">\d</code> 含义相反，相当于 <code class="language-plaintext highlighter-rouge">[^0-9]</code></td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\D</code> 会在字符串 <code class="language-plaintext highlighter-rouge">'apple123'</code> 中匹配 <code class="language-plaintext highlighter-rouge">'a'</code>、<code class="language-plaintext highlighter-rouge">'p'</code>、<code class="language-plaintext highlighter-rouge">'p'</code>、<code class="language-plaintext highlighter-rouge">'l'</code> 和 <code class="language-plaintext highlighter-rouge">'e'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\s</code></td> <td style="text-align: left">匹配任何空白字符，包括空格、制表符、换行符等，相当于 <code class="language-plaintext highlighter-rouge">[ \t\n\r\f\v]</code></td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\s</code> 会匹配字符串 <code class="language-plaintext highlighter-rouge">'Hello\tWorld\n'</code> 中的 <code class="language-plaintext highlighter-rouge">\t</code> 和 <code class="language-plaintext highlighter-rouge">\n</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\S</code></td> <td style="text-align: left">与 <code class="language-plaintext highlighter-rouge">\s</code> 含义相反，匹配任何非空白字符，相当于 <code class="language-plaintext highlighter-rouge">[^ \t\n\r\f\v]</code></td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\w</code></td> <td style="text-align: left">匹配任何字母、数字以及下划线，相当于 <code class="language-plaintext highlighter-rouge">[a-zA-Z0-9_]</code></td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\w+</code> 表示 <code class="language-plaintext highlighter-rouge">\w</code> 模式可以连续出现一次或多次</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\W</code></td> <td style="text-align: left">与 <code class="language-plaintext highlighter-rouge">\w</code> 含义相反，相当于 <code class="language-plaintext highlighter-rouge">[^a-zA-Z0-9_]</code></td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\Z</code></td> <td style="text-align: left">确保匹配将从字符串的末尾位置开始</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\number</code></td> <td style="text-align: left">引用相同编号组（<code class="language-plaintext highlighter-rouge">()</code>）中的内容，<code class="language-plaintext highlighter-rouge">number</code> 为正整数</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(\w+)\s+\1</code> 可以匹配任何两个相同的连续单词， <code class="language-plaintext highlighter-rouge">\1</code> 表示引用第一个子模式 <code class="language-plaintext highlighter-rouge">(\w+)</code> 中的内容，即 <code class="language-plaintext highlighter-rouge">(\w+)</code> 可以匹配一个单词，<code class="language-plaintext highlighter-rouge">\1</code> 同 <code class="language-plaintext highlighter-rouge">(\w+)</code> 也可以匹配一个相同的单词</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">\n</code>、<code class="language-plaintext highlighter-rouge">\f</code>、<code class="language-plaintext highlighter-rouge">\r</code>、<code class="language-plaintext highlighter-rouge">\t</code></td> <td style="text-align: left">也支持字符串的标准转义字符，分别匹配一个换行符、换页符、回车符、制表符</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">()</code></td> <td style="text-align: left">表示一个子模式（组），圆括号中的内容作为一个整体对待，可以使用 <code class="language-plaintext highlighter-rouge">\number</code> 进行匹配</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(cat)+</code> 可以匹配 <code class="language-plaintext highlighter-rouge">'catcat'</code>、<code class="language-plaintext highlighter-rouge">'catcatcat'</code> 等一个或多个连续 <code class="language-plaintext highlighter-rouge">'cat'</code> 的情况</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?:...)</code></td> <td style="text-align: left">表示非捕获组，即匹配圆括号中的正则表达式但不捕获</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?#...)</code></td> <td style="text-align: left">一般位于正则表达式最后来表示注释，从而允许在正则表达式内部添加注释，不会被返回</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?=...)</code></td> <td style="text-align: left">用于想要匹配的正则表达式之后，如果 <code class="language-plaintext highlighter-rouge">=</code> 后的内容在字符串中紧跟着出现则匹配，但并不返回 <code class="language-plaintext highlighter-rouge">=</code> 之后的内容</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">abc(?=def)</code> 在字符串 <code class="language-plaintext highlighter-rouge">'abcdef'</code> 中匹配并返回 <code class="language-plaintext highlighter-rouge">'abc'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?&lt;=...)</code></td> <td style="text-align: left">用于想要匹配的正则表达式之前，如果 <code class="language-plaintext highlighter-rouge">&lt;=</code> 后的内容在字符串中紧跟着出现则匹配，但并不返回 <code class="language-plaintext highlighter-rouge">&lt;=</code> 之后的内容</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?&lt;=abc)def</code> 在字符串 <code class="language-plaintext highlighter-rouge">'abcdef'</code> 中匹配并返回 <code class="language-plaintext highlighter-rouge">'def'</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?!...)</code></td> <td style="text-align: left">用于想要匹配的正则表达式之后，如果 <code class="language-plaintext highlighter-rouge">!</code> 后的内容在字符串中<strong>不</strong>紧跟着出现则匹配，但并不返回 <code class="language-plaintext highlighter-rouge">！</code> 之后的内容</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">abc(?!def)</code> 只有在字符串 <code class="language-plaintext highlighter-rouge">'abc'</code> 之后没有 <code class="language-plaintext highlighter-rouge">'def'</code> 时才会匹配</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?&lt;!...)</code></td> <td style="text-align: left">用于想要匹配的正则表达式之前，如果 <code class="language-plaintext highlighter-rouge">!=</code> 后的内容在字符串中<strong>不</strong>紧跟着出现则匹配，但并不返回 <code class="language-plaintext highlighter-rouge">!=</code> 之后的内容</td> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?!=abc)def</code> 只有在字符串 <code class="language-plaintext highlighter-rouge">'def'</code> 之前没有 <code class="language-plaintext highlighter-rouge">'abc'</code> 时才会匹配</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?P&lt;name&gt;)</code></td> <td style="text-align: left">为组命名</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?P=name)</code></td> <td style="text-align: left">匹配之前命名为 name 的组所匹配的任何字符串</td> <td style="text-align: left"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">(?aiLmsux)</code></td> <td style="text-align: left">设置匹配标志，可以是单个字母，也可以是多个字母的组合，每个字母的含义与<a href="#编译标志">编译标志</a>相同</td> <td style="text-align: left"> </td> </tr> </tbody> </table> <p class="mynote">元字符在 <code class="language-plaintext highlighter-rouge">[]</code> 不起作用，只是表示普通的字符，如 <code class="language-plaintext highlighter-rouge">[ak$]</code> 会匹配<code class="language-plaintext highlighter-rouge">'a'</code>、<code class="language-plaintext highlighter-rouge">'k'</code> 和 <code class="language-plaintext highlighter-rouge">'$'</code>，<code class="language-plaintext highlighter-rouge">$</code> 通常是一个元字符，但在 <code class="language-plaintext highlighter-rouge">[]</code> 中它被剥夺了它的特殊性质。</p> <p class="mynote">为什么使用 <code class="language-plaintext highlighter-rouge">\\\\</code> 来匹配 <code class="language-plaintext highlighter-rouge">'\'</code>：在 Python 字符串中，反斜杠是一个转义字符，为了在字符串中表示一个字面的反斜杠，需要使用 <code class="language-plaintext highlighter-rouge">\\</code>。在正则表达式中，反斜杠也是一个转义字符，为了在正则表达式中匹配一个字面的反斜杠，也需要使用 <code class="language-plaintext highlighter-rouge">\\</code>。因此，为了在 Python 字符串中表示一个正则表达式，该正则表达式可以匹配一个字面的反斜杠，则需要使用 <code class="language-plaintext highlighter-rouge">\\\\</code>，当然也可以使用原始字符串 <code class="language-plaintext highlighter-rouge">r'\\'</code>。</p> <h3 id="正则表达式模块-re">正则表达式模块 <code class="language-plaintext highlighter-rouge">re</code></h3> <p>Python 标准库 <code class="language-plaintext highlighter-rouge">re</code> 提供了正则表达式操作所需要的功能，既可以直接使用其中的函数处理字符串，也可以使用编译后的正则表达式对象处理字符串。</p> <h4 id="编译标志">编译标志</h4> <p>编译标志（flags）会影响正则表达式的匹配行为。</p> <table> <thead> <tr> <th style="text-align: left">flags</th> <th style="text-align: left">说明</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">re.ASCII</code> or <code class="language-plaintext highlighter-rouge">re.A</code></td> <td style="text-align: left">表示 <code class="language-plaintext highlighter-rouge">\b</code>、<code class="language-plaintext highlighter-rouge">\d</code>、<code class="language-plaintext highlighter-rouge">\s</code> 和 <code class="language-plaintext highlighter-rouge">\w</code> 将只匹配 ASCII 字符，而不是整个 Unicode 字符集</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">re.IGNORECASE</code> or <code class="language-plaintext highlighter-rouge">re.I</code></td> <td style="text-align: left">令匹配对大小写不敏感</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">re.LOCALE</code> or <code class="language-plaintext highlighter-rouge">re.L</code></td> <td style="text-align: left">支持本地字符集的字符（不常用）</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">re.MULTILINE</code> or <code class="language-plaintext highlighter-rouge">re.M</code></td> <td style="text-align: left">多行匹配模式，可以使 <code class="language-plaintext highlighter-rouge">^</code> 和 <code class="language-plaintext highlighter-rouge">$</code> 能够匹配字符串中每一行的开头和结尾</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">re.DOTALL</code> or <code class="language-plaintext highlighter-rouge">re.S</code></td> <td style="text-align: left">使 <code class="language-plaintext highlighter-rouge">.</code> 能够匹配任何字符，包括换行符</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">re.UNICODE</code> or <code class="language-plaintext highlighter-rouge">re.U</code></td> <td style="text-align: left">匹配 Unicode 字符集（默认标志）</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">re.VERBOSE</code> or <code class="language-plaintext highlighter-rouge">re.X</code></td> <td style="text-align: left">允许在正则表达式中加入空白字符和注释</td> </tr> </tbody> </table> <h4 id="常用函数">常用函数</h4> <ul> <li><code class="language-plaintext highlighter-rouge">re.search(pattern, string, flags=0)</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">pattern</code> 参数指正则表达式，可用原始字符串防止转义，<code class="language-plaintext highlighter-rouge">string</code> 参数指用于匹配的字符串，<code class="language-plaintext highlighter-rouge">flags</code> 参数的值可以是上述的各个编译标志。<code class="language-plaintext highlighter-rouge">search()</code> 函数用于在整个字符串中搜索正则表达式的首个匹配项，如果匹配成功就返回 Match 对象，否则返回 <code class="language-plaintext highlighter-rouge">None</code>。返回的 Match 对象可以用 <code class="language-plaintext highlighter-rouge">group()</code> 方法查看内容。</p> <ul> <li><code class="language-plaintext highlighter-rouge">re.match(pattern, string, flags=0)</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">match()</code> 函数从字符串的开始处进行匹配，如果匹配成功就返回 Match 对象，否则返回 <code class="language-plaintext highlighter-rouge">None</code>。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">hello</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Say hello!</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># search() 在整个字符串中匹配
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">text</span><span class="p">.</span><span class="nf">group</span><span class="p">()</span>
<span class="sh">'</span><span class="s">hello</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">hello</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Say hello!</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># match() 从字符串的开头匹配，匹配失败
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">text</span><span class="p">.</span><span class="nf">group</span><span class="p">()</span>
<span class="nb">AttributeError</span><span class="p">:</span> <span class="sh">'</span><span class="s">NoneType</span><span class="sh">'</span> <span class="nb">object</span> <span class="n">has</span> <span class="n">no</span> <span class="n">attribute</span> <span class="sh">'</span><span class="s">group</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">hello</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">hello Say hello!</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># match() 匹配成功
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">text</span><span class="p">.</span><span class="nf">group</span><span class="p">()</span>
<span class="sh">'</span><span class="s">hello</span><span class="sh">'</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">re.fullmatch(pattern, string, flags=0)</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">fullmatch()</code> 只在正则表达式匹配整个字符串时才返回 Match 对象，否则返回 <code class="language-plaintext highlighter-rouge">None</code>。因此，可以用于确保整个字符串都符合特定的格式。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">fullmatch</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\d+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">12345</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 确保整个字符串都由数字 [0-9] 构成
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">if</span> <span class="n">text</span><span class="p">:</span>
	<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The string is made of digits.</span><span class="sh">'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
	<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The string has non-digit characters.</span><span class="sh">'</span><span class="p">)</span>
<span class="n">The</span> <span class="n">string</span> <span class="ow">is</span> <span class="n">made</span> <span class="n">of</span> <span class="n">digits</span><span class="p">.</span>
</code></pre></div></div> <ul> <li><span id="re-split"><code class="language-plaintext highlighter-rouge">re.split(pattern, string, maxsplit=0, flags=0)</code></span></li> </ul> <p><code class="language-plaintext highlighter-rouge">split()</code> 根据正则表达式的匹配项来分隔字符串，返回一个列表。<code class="language-plaintext highlighter-rouge">maxsplit</code> 参数指定字符串的最大分隔次数，并且字符串的其余部分作为列表的最终元素返回。如果在 <code class="language-plaintext highlighter-rouge">pattern</code> 中使用元字符 <code class="language-plaintext highlighter-rouge">()</code>（捕获组），那么分隔符也会作为结果返回，并且分隔符如果在字符串的开头或结尾得到匹配，那么结果则会以空字符串开头或结尾。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\W+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Words, words, ws.</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 最后一个匹配项是 '.'，但是在 '.' 之后字符串没有内容，因此返回的最后一项为空字符串
</span><span class="p">[</span><span class="sh">'</span><span class="s">Words</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ws</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(\W+)</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Words, words, ws.</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 正则表达式使用了 ()，分隔符也被返回
</span><span class="p">[</span><span class="sh">'</span><span class="s">Words</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ws</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\W+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Words, words, ws.</span><span class="sh">'</span><span class="p">,</span> <span class="n">maxsplit</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 指定最大分隔次数为 1，字符串的剩余部分以一个整体作为最后一项返回
</span><span class="p">[</span><span class="sh">'</span><span class="s">Words</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">words, ws.</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <ul> <li><span id="re-findall"><code class="language-plaintext highlighter-rouge">re.findall(pattern, string, flags=0)</code></span></li> </ul> <p><code class="language-plaintext highlighter-rouge">findall()</code> 以列表的形式按照匹配的顺序返回字符串中的所有匹配项。相对于 <code class="language-plaintext highlighter-rouge">search()</code> 只返回第一个匹配项，<code class="language-plaintext highlighter-rouge">findall()</code> 则会返回所有匹配项。如果 <code class="language-plaintext highlighter-rouge">pattern</code> 中有一个或多个捕获组，则会返回一个元组列表。如果没有匹配，则会返回一个空列表。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Emails: example1@gmail.com, example2@163.com</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="p">.</span><span class="nf">findall</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(\w+)@(\w+)\.(\w+)</span><span class="sh">'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>  <span class="c1"># 多个捕获组，返回元组列表
</span><span class="p">[(</span><span class="sh">'</span><span class="s">example1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">gmail</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">com</span><span class="sh">'</span><span class="p">),</span> <span class="p">(</span><span class="sh">'</span><span class="s">example2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">163</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">com</span><span class="sh">'</span><span class="p">)]</span>
</code></pre></div></div> <ul> <li><span id="re-finditer"><code class="language-plaintext highlighter-rouge">re.finditer(pattern, string, flags=0)</code></span></li> </ul> <p><code class="language-plaintext highlighter-rouge">finditer()</code> 返回包含所有匹配项的迭代器，而不是由字符串组成的列表，其中每个匹配项都是 <a href="#match-对象">Match 对象</a>。相比于 <code class="language-plaintext highlighter-rouge">findall()</code>，<code class="language-plaintext highlighter-rouge">finditer()</code> 可以对得到的匹配项使用更全面的功能。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="sh">'</span><span class="s">The rain in Spain falls mainly in the plain.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">matches</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">finditer</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\b\w+ain\b</span><span class="sh">'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>  <span class="c1"># 获取每个匹配项的内容
</span>	<span class="nf">print</span><span class="p">(</span><span class="n">match</span><span class="p">.</span><span class="nf">group</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">)</span>
<span class="n">rain</span> <span class="n">Spain</span> <span class="n">plain</span> 

<span class="c1"># 注意！迭代器 matches 的元素只能访问一次
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>  <span class="c1"># 获取每个匹配项的起始和结束位置
</span>	<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Match: </span><span class="si">{</span><span class="n">match</span><span class="p">.</span><span class="nf">group</span><span class="p">()</span><span class="si">}</span><span class="s">, Start: </span><span class="si">{</span><span class="n">match</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span><span class="si">}</span><span class="s">, End: </span><span class="si">{</span><span class="n">match</span><span class="p">.</span><span class="nf">end</span><span class="p">()</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="n">Match</span><span class="p">:</span> <span class="n">rain</span><span class="p">,</span> <span class="n">Start</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">End</span><span class="p">:</span> <span class="mi">8</span>
<span class="n">Match</span><span class="p">:</span> <span class="n">Spain</span><span class="p">,</span> <span class="n">Start</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span> <span class="n">End</span><span class="p">:</span> <span class="mi">17</span>
<span class="n">Match</span><span class="p">:</span> <span class="n">plain</span><span class="p">,</span> <span class="n">Start</span><span class="p">:</span> <span class="mi">38</span><span class="p">,</span> <span class="n">End</span><span class="p">:</span> <span class="mi">43</span>
</code></pre></div></div> <ul> <li><span id="re-sub"><code class="language-plaintext highlighter-rouge">re.sub(pattern, repl, string, count=0, flags=0)</code></span></li> </ul> <p><code class="language-plaintext highlighter-rouge">sub()</code> 使用 <code class="language-plaintext highlighter-rouge">repl</code> 替换字符串中的所有匹配项，返回新字符串，如果没有匹配则返回原字符串。<code class="language-plaintext highlighter-rouge">repl</code> 参数可以是字符串或返回字符串的可调用对象（例如函数），该可调用对象作用于每个匹配的 Match 对象。<code class="language-plaintext highlighter-rouge">count</code> 参数表示替换的最大次数，默认为 0，即替换所有的匹配项。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">clouds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Dreamless drugs are the best drugs ever.</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span>
<span class="sh">'</span><span class="s">Dreamless clouds are the best clouds ever.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">clouds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Dreamless drugs are the best drugs ever.</span><span class="sh">'</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 指定最大替换次数
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">text</span>
<span class="sh">'</span><span class="s">Dreamless clouds are the best drugs ever.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">upper_func</span><span class="p">(</span><span class="n">match</span><span class="p">):</span>  <span class="c1"># 接收匹配的 Match 对象为参数
</span>	<span class="k">return</span> <span class="n">match</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">upper</span><span class="p">()</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\b[a-z]+\b</span><span class="sh">'</span><span class="p">,</span> <span class="n">upper_func</span><span class="p">,</span> <span class="sh">'</span><span class="s">hello world</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># repl 为函数
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">text</span>
<span class="sh">'</span><span class="s">HELLO WORLD</span><span class="sh">'</span>
</code></pre></div></div> <ul> <li><span id="re-subn"><code class="language-plaintext highlighter-rouge">re.subn(pattern, repl, string, count=0, flags=0)</code></span></li> </ul> <p><code class="language-plaintext highlighter-rouge">subn()</code> 执行与 <code class="language-plaintext highlighter-rouge">sub()</code> 相同的操作，只不过返回的是一个元组，包括新字符串和替换次数。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">subn</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">clouds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Dreamless drugs are the best drugs ever.</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span>
<span class="p">(</span><span class="sh">'</span><span class="s">Dreamless clouds are the best clouds ever.</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">re.escape(pattern)</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">escape()</code> 用于将字符串中所有特殊的正则表达式字符转义成普通字符，可以用于处理用户输入的数据，因为不知道输入的字符串中可能包含哪些特殊字符。主要目的是让一个字符串在任何正则表达式中都能被当作字面量（即不具有特殊含义）来看待。例如，有一个包含 <code class="language-plaintext highlighter-rouge">.*?</code> 这三种特殊字符的字符串，若想在文本中查找这个确切的字符串，而不是它作为正则表达式所代表的 <code class="language-plaintext highlighter-rouge">pattern</code>，就可以使用 <code class="language-plaintext highlighter-rouge">escape()</code> 来正确转义后再进行匹配。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="p">.</span><span class="nf">escape</span><span class="p">(</span><span class="sh">'</span><span class="s">http://www.python.org</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">http://www</span><span class="se">\\</span><span class="s">.python</span><span class="se">\\</span><span class="s">.org</span><span class="sh">'</span>  <span class="c1"># 双反斜杠 \\ 表示一个字面的反斜杠 \，然后 \. 表示字面的 .，因此 \\. 才能匹配 .
</span></code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">re.compile(pattern, flags=0)</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">compile()</code> 用于将正则表达式 <code class="language-plaintext highlighter-rouge">pattern</code> 编译为<strong>正则表达式对象</strong>，便于表达式在单个程序中的多次使用。</p> <h3 id="正则表达式对象">正则表达式对象</h3> <p>通过 <code class="language-plaintext highlighter-rouge">compile()</code> 函数将正则表达式 <code class="language-plaintext highlighter-rouge">pattern</code> 编译成正则表达式对象后，可以使用更多的方法来处理字符串。</p> <h4 id="searchmatchfullmatchfindallfinditer"><code class="language-plaintext highlighter-rouge">search()</code>、<code class="language-plaintext highlighter-rouge">match()</code>、<code class="language-plaintext highlighter-rouge">fullmatch()</code>、<code class="language-plaintext highlighter-rouge">findall()</code>、<code class="language-plaintext highlighter-rouge">finditer()</code></h4> <ul> <li><code class="language-plaintext highlighter-rouge">Pattern.search(string[, pos[, endpos]]</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">search()</code> 用于在整个字符串或指定范围中进行搜索，返回第一个匹配的 Match 对象，若没有匹配则返回 <code class="language-plaintext highlighter-rouge">None</code>。<code class="language-plaintext highlighter-rouge">pos</code> 参数给出开始搜索的索引，默认为 0。<code class="language-plaintext highlighter-rouge">endpos</code> 参数限制字符串的搜索范围。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Dreamless drugs are the best drugs ever.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">p</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">re</span><span class="p">.</span><span class="n">Match</span> <span class="nb">object</span><span class="p">;</span> <span class="n">span</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="n">match</span><span class="o">=</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">p</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>  <span class="c1"># 设定搜索从 20 开始
</span><span class="o">&lt;</span><span class="n">re</span><span class="p">.</span><span class="n">Match</span> <span class="nb">object</span><span class="p">;</span> <span class="n">span</span><span class="o">=</span><span class="p">(</span><span class="mi">29</span><span class="p">,</span> <span class="mi">34</span><span class="p">),</span> <span class="n">match</span><span class="o">=</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="o">&gt;</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">Pattern.match(string[, pos[, endpos]]</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">match()</code> 从字符串开头或指定位置进行搜索，且必须以模式开头，才会返回 Match 对象，其余同 <code class="language-plaintext highlighter-rouge">search()</code>。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Dreamless drugs are the best drugs ever.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>  <span class="c1"># 无匹配返回 None
</span><span class="bp">None</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">p</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">re</span><span class="p">.</span><span class="n">Match</span> <span class="nb">object</span><span class="p">;</span> <span class="n">span</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="n">match</span><span class="o">=</span><span class="sh">'</span><span class="s">drugs</span><span class="sh">'</span><span class="o">&gt;</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">Pattern.fullmatch(string[, pos[, endpos]]</code></li> </ul> <p>如果整个字符串与该正则表达式匹配，则返回相应的 Match 对象。</p> <ul> <li><code class="language-plaintext highlighter-rouge">Pattern.findall(string[, pos[, endpos]]</code>、<code class="language-plaintext highlighter-rouge">Pattern.finditer(string[, pos[, endpos]]</code></li> </ul> <p>同 <a href="#re-findall"><code class="language-plaintext highlighter-rouge">re.findall()</code></a> 和 <a href="#re-finditer"><code class="language-plaintext highlighter-rouge">re.finditer()</code></a>，只是增加了 <code class="language-plaintext highlighter-rouge">pos</code> 和 <code class="language-plaintext highlighter-rouge">endpos</code> 参数。</p> <h4 id="split"><code class="language-plaintext highlighter-rouge">split()</code></h4> <p><code class="language-plaintext highlighter-rouge">Pattern.split(string, maxsplit=0)</code> 同 <a href="#re-split"><code class="language-plaintext highlighter-rouge">re.split()</code></a>。</p> <h4 id="subsubn"><code class="language-plaintext highlighter-rouge">sub()</code>、<code class="language-plaintext highlighter-rouge">subn()</code></h4> <p><code class="language-plaintext highlighter-rouge">Pattern.sub(repl, string, count=0)</code> 和 <code class="language-plaintext highlighter-rouge">Pattern.subn(repl, string, count=0)</code> 同 <a href="#re-sub"><code class="language-plaintext highlighter-rouge">re.sub()</code></a> 和 <a href="#re-subn"><code class="language-plaintext highlighter-rouge">re.subn()</code></a>。</p> <h4 id="groupspattern-属性"><code class="language-plaintext highlighter-rouge">groups</code>、<code class="language-plaintext highlighter-rouge">pattern</code> 属性</h4> <p><code class="language-plaintext highlighter-rouge">Pattern.groups</code> 返回捕获组的数量，<code class="language-plaintext highlighter-rouge">Pattern.pattern</code> 返回编译后正则表达式对象的模式字符串。</p> <h3 id="match-对象">Match 对象</h3> <h4 id="groupgroupsgroupdict"><code class="language-plaintext highlighter-rouge">group()</code>、<code class="language-plaintext highlighter-rouge">groups()</code>、<code class="language-plaintext highlighter-rouge">groupdict()</code></h4> <p><code class="language-plaintext highlighter-rouge">Match.group([group1, ...])</code> 返回匹配的一个或多个子模式内容，<code class="language-plaintext highlighter-rouge">group1</code> 默认为 0（返回整个模式内容）；<code class="language-plaintext highlighter-rouge">Match.groups()</code> 返回一个包含所有匹配的子模式内容的元组；<code class="language-plaintext highlighter-rouge">Match.groupdict()</code> 返回一个包含所有匹配的命名的子模式内容的字典。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(\w+) (\w+)</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Dreamless Drugs, harmless</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">()</span>  <span class="c1"># 返回整个模式内容
</span><span class="sh">'</span><span class="s">Dreamless Drugs</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 返回第一个子模式内容
</span><span class="sh">'</span><span class="s">Dreamless</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 返回第二个子模式内容
</span><span class="sh">'</span><span class="s">Drugs</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># 以元组形式返回指定的多个子模式内容
</span><span class="p">(</span><span class="sh">'</span><span class="s">Dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Drugs</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">groups</span><span class="p">()</span>  <span class="c1"># 以元组形式返回所有匹配的子模式内容
</span><span class="p">(</span><span class="sh">'</span><span class="s">Dreamless</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Drugs</span><span class="sh">'</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(?P&lt;first_name&gt;\w+) (?P&lt;last_name&gt;\w+)</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Melanie C</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="sh">'</span><span class="s">first_name</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 使用命名的子模式
</span><span class="sh">'</span><span class="s">Melanie</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="sh">'</span><span class="s">last_name</span><span class="sh">'</span><span class="p">)</span>
<span class="sh">'</span><span class="s">C</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">groupdict</span><span class="p">()</span>
<span class="p">{</span><span class="sh">'</span><span class="s">first_name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Melanie</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">last_name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">}</span>
</code></pre></div></div> <h4 id="startendspan"><code class="language-plaintext highlighter-rouge">start()</code>、<code class="language-plaintext highlighter-rouge">end()</code>、<code class="language-plaintext highlighter-rouge">span()</code></h4> <p><code class="language-plaintext highlighter-rouge">Match.start([group])</code> 和 <code class="language-plaintext highlighter-rouge">Match.end([group])</code> 返回匹配的子字符串的起始位置和结束位置后一位的索引。<code class="language-plaintext highlighter-rouge">group</code> 参数用于指定第几个捕获组，默认为 0，表示整个匹配的子字符串。<code class="language-plaintext highlighter-rouge">Match.span([group])</code> 返回一个包含 <code class="language-plaintext highlighter-rouge">start()</code> 和 <code class="language-plaintext highlighter-rouge">end()</code> 的元组。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(\w+) (\w+)</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Dreamless Drugs, harmless</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>
<span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">end</span><span class="p">()</span>
<span class="mi">15</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">span</span><span class="p">()</span>  <span class="c1"># 整个匹配的子字符串
</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">span</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 第一个捕获组匹配的子字符串
</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">span</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 第二个捕获组匹配的子字符串
</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
</code></pre></div></div> <h4 id="expand"><code class="language-plaintext highlighter-rouge">expand()</code></h4> <p><code class="language-plaintext highlighter-rouge">Match.expand(template)</code> 用于通过一个模板字符串进行正则表达式的替换操作，其中该模板字符串可以包含正则表达式的捕获组，捕获组可以用 <code class="language-plaintext highlighter-rouge">\number</code> 或捕获组名（<code class="language-plaintext highlighter-rouge">\g&lt;name&gt;</code>）的方式进行引用。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(\w+) (\w+)</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Dreamless Drugs, harmless</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">()</span>  <span class="c1"># 查看匹配结果
</span><span class="sh">'</span><span class="s">Dreamless Drugs</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">expand</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\2 \1</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 使用 \number 引用捕获组进行替换
</span><span class="sh">'</span><span class="s">Drugs Dreamless</span><span class="sh">'</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">match</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(?P&lt;first_name&gt;\w+) (?P&lt;last_name&gt;\w+)</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Melanie C</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">group</span><span class="p">()</span>  <span class="c1"># 查看匹配结果
</span><span class="sh">'</span><span class="s">Melanie C</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="p">.</span><span class="nf">expand</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\g&lt;last_name&gt; \g&lt;first_name&gt;</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 使用捕获组名来引用捕获组进行替换
</span><span class="sh">'</span><span class="s">C Melanie</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="lastindexlastgrouprestring-属性"><code class="language-plaintext highlighter-rouge">lastindex</code>、<code class="language-plaintext highlighter-rouge">lastgroup</code>、<code class="language-plaintext highlighter-rouge">re</code>、<code class="language-plaintext highlighter-rouge">string</code> 属性</h4> <p><code class="language-plaintext highlighter-rouge">Match.lastindex</code> 返回最后匹配的捕获组的索引，若无匹配则为 <code class="language-plaintext highlighter-rouge">None</code>；<code class="language-plaintext highlighter-rouge">Match.lastgroup</code> 返回最后匹配的捕获组的名称；<code class="language-plaintext highlighter-rouge">Match.re</code> 返回生成此 Match 对象的正则表达式对象，从而可得到<code class="language-plaintext highlighter-rouge">pattern</code>；<code class="language-plaintext highlighter-rouge">Match.string</code> 返回传递给生成此 Match 对象的正则表达式对象的字符串。</p> <h2 id="程序控制结构">程序控制结构</h2> <p>在程序控制结构中，都要根据条件表达式的值来确定下一步的执行流程。条件表达式的值只要不是 False、0、空值 None、空列表、空元组、空字典、空集合、空字符串等其他空可迭代对象，Python 均认为与 True 等价。</p> <h3 id="选择结构">选择结构</h3> <h4 id="单分支选择结构">单分支选择结构</h4> <p>当表达式的值为 True 或其他与 True 等价的值时，表示条件满足，语句块被执行。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">expression</span><span class="p">:</span>
	<span class="c1"># 语句块
</span></code></pre></div></div> <h4 id="双分支选择结构">双分支选择结构</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">expression</span><span class="p">:</span>
	<span class="c1"># 语句块 1
</span><span class="k">else</span><span class="p">:</span>
	<span class="c1"># 语句块 2
</span></code></pre></div></div> <p><strong>三元运算符</strong>构成的表达式也属于双分支选择结构，其语法为：<code class="language-plaintext highlighter-rouge">value1 if condition else value2</code>。当条件表达式 <code class="language-plaintext highlighter-rouge">condition</code> 的值与 True 等价时，表达式的值为 <code class="language-plaintext highlighter-rouge">value1</code>，否则表达式的值为 <code class="language-plaintext highlighter-rouge">value2</code>。<code class="language-plaintext highlighter-rouge">value1</code> 和 <code class="language-plaintext highlighter-rouge">value2</code> 本身也可以是复杂表达式，也可以包含函数调用，甚至是三元运算符构成的表达式。此外，三元运算符构成的表达式也具有惰性求值的特点。</p> <h4 id="多分支选择结构">多分支选择结构</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">expression1</span><span class="p">:</span>
	<span class="c1"># 语句块 1
</span><span class="k">elif</span> <span class="n">expression2</span><span class="p">:</span>
	<span class="c1"># 语句块 2
</span><span class="k">elif</span> <span class="n">expression3</span><span class="p">:</span>
	<span class="c1"># 语句块 3
</span><span class="k">else</span><span class="p">:</span>
	<span class="c1"># 语句块 n
</span></code></pre></div></div> <h4 id="选择结构的嵌套">选择结构的嵌套</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">expression1</span><span class="p">:</span>
	<span class="c1"># 语句块 1
</span>	<span class="k">if</span> <span class="n">expression2</span><span class="p">:</span>
		<span class="c1"># 语句块 2
</span>	<span class="k">else</span><span class="p">:</span>
		<span class="c1"># 语句块 3
</span><span class="k">else</span><span class="p">:</span>
	<span class="k">if</span> <span class="n">expression4</span><span class="p">:</span>
		<span class="c1"># 语句块 4
</span></code></pre></div></div> <h3 id="循环结构">循环结构</h3> <h4 id="for-循环与-while-循环"><code class="language-plaintext highlighter-rouge">for</code> 循环与 <code class="language-plaintext highlighter-rouge">while</code> 循环</h4> <p><code class="language-plaintext highlighter-rouge">for</code> 循环一般用于循环次数可以提前确定的情况，尤其适用于<strong>枚举</strong>或<strong>遍历</strong>可迭代对象中元素的场合。<code class="language-plaintext highlighter-rouge">while</code> 循环一般用于根据一定的条件重复执行一段代码的情况，并且往往难以提前确定循环次数。对于带有 <code class="language-plaintext highlighter-rouge">else</code> 子句的循环结构，如果循环因为条件表达式不成立或序列遍历结束而<strong>自然结束</strong>时则执行 <code class="language-plaintext highlighter-rouge">else</code> 中的语句，如果循环是因为执行了 <code class="language-plaintext highlighter-rouge">break</code> 语句而导致循环<strong>提前结束</strong>则不会执行 <code class="language-plaintext highlighter-rouge">else</code> 中的语句。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># for 循环
</span><span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">:</span>
	<span class="c1"># 循环体
</span><span class="p">[</span><span class="k">else</span><span class="p">:</span>
	<span class="c1"># 代码块]
</span>	
<span class="c1"># while 循环
</span><span class="k">while</span> <span class="n">condition</span><span class="p">:</span>
	<span class="c1"># 循环体
</span><span class="p">[</span><span class="k">else</span><span class="p">:</span>
	<span class="c1"># 代码块]
</span></code></pre></div></div> <p class="mynote">使用 <code class="language-plaintext highlighter-rouge">while True:</code> 可以构建一个无限循环。</p> <h4 id="break-与-continue-语句"><code class="language-plaintext highlighter-rouge">break</code> 与 <code class="language-plaintext highlighter-rouge">continue</code> 语句</h4> <p><code class="language-plaintext highlighter-rouge">break</code> 与 <code class="language-plaintext highlighter-rouge">continue</code> 语句一般常与<strong>选择结构</strong>或<strong>异常处理结构</strong>结合使用。<code class="language-plaintext highlighter-rouge">break</code> 语句被执行会使得<strong>所属层次的循环</strong>提前结束，即完全跳出当前循环，不再执行剩余的迭代。<code class="language-plaintext highlighter-rouge">continue</code> 语句被执行会使得<strong>本次循环</strong>提前结束，忽略 <code class="language-plaintext highlighter-rouge">continue</code> 之后的语句，提前进入下一次循环。<code class="language-plaintext highlighter-rouge">break</code> 与 <code class="language-plaintext highlighter-rouge">continue</code> 语句都只对最内层的循环有效。</p> <h4 id="循环优化技巧">循环优化技巧</h4> <p class="myimportant">在多重循环嵌套的情况下，要尽量减少内层循环中不必要的计算，尽可能地将计算向外提。</p> <p class="myimportant">在使用模块中的方法时，可以通过将其转换为局部变量来提高运行速度。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">math</span>  <span class="c1"># 或者使用 from math import sin[ as loc_sin]，效果一样
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000000</span><span class="p">):</span>
	<span class="n">math</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
	
<span class="n">loc_sin</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sin</span>  <span class="c1"># 将 math.sin 转换为局部变量
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000000</span><span class="p">):</span>
	<span class="nf">loc_sin</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</code></pre></div></div> <p class="mynote">如果需要测试一个序列是否包含一个元素应尽量使用字典或集合，将多个字符串连接成一个字符串时应尽量使用 <code class="language-plaintext highlighter-rouge">join()</code> 方法而不是运算符 <code class="language-plaintext highlighter-rouge">+</code>，对列表进行元素的插入和删除应尽量从尾部进行。最终的最终，首先应将代码写对，保证完全符合功能要求，再进行必要的优化来提高性能。</p> <h2 id="异常处理结构">异常处理结构</h2> <p>Python 内置异常类的<a href="https://docs.python.org/3.7/library/exceptions.html#exception-hierarchy">继承层次</a>，其中 <code class="language-plaintext highlighter-rouge">BaseException</code> 是所有内置异常类的基类。在使用异常处理结构捕获和处理异常时，应尽量具体一点，建议先尝试捕获派生类，再捕获基类。最常用的是 <code class="language-plaintext highlighter-rouge">Exception</code> 类。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">BaseException</span>
 <span class="o">+--</span> <span class="nb">SystemExit</span>
 <span class="o">+--</span> <span class="nb">KeyboardInterrupt</span>
 <span class="o">+--</span> <span class="nb">GeneratorExit</span>
 <span class="o">+--</span> <span class="nb">Exception</span>
      <span class="o">+--</span> <span class="nb">StopIteration</span>
      <span class="o">+--</span> <span class="nb">StopAsyncIteration</span>
      <span class="o">+--</span> <span class="nb">ArithmeticError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">FloatingPointError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">OverflowError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ZeroDivisionError</span>
      <span class="o">+--</span> <span class="nb">AssertionError</span>
      <span class="o">+--</span> <span class="nb">AttributeError</span>
      <span class="o">+--</span> <span class="nb">BufferError</span>
      <span class="o">+--</span> <span class="nb">EOFError</span>
      <span class="o">+--</span> <span class="nb">ImportError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ModuleNotFoundError</span>
      <span class="o">+--</span> <span class="nb">LookupError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">IndexError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">KeyError</span>
      <span class="o">+--</span> <span class="nb">MemoryError</span>
      <span class="o">+--</span> <span class="nb">NameError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">UnboundLocalError</span>
      <span class="o">+--</span> <span class="nb">OSError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">BlockingIOError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ChildProcessError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ConnectionError</span>
      <span class="o">|</span>    <span class="o">|</span>    <span class="o">+--</span> <span class="nb">BrokenPipeError</span>
      <span class="o">|</span>    <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ConnectionAbortedError</span>
      <span class="o">|</span>    <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ConnectionRefusedError</span>
      <span class="o">|</span>    <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ConnectionResetError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">FileExistsError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">FileNotFoundError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">InterruptedError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">IsADirectoryError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">NotADirectoryError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="n">PermissionError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">ProcessLookupError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">TimeoutError</span>
      <span class="o">+--</span> <span class="nb">ReferenceError</span>
      <span class="o">+--</span> <span class="nb">RuntimeError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">NotImplementedError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">RecursionError</span>
      <span class="o">+--</span> <span class="nb">SyntaxError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">IndentationError</span>
      <span class="o">|</span>         <span class="o">+--</span> <span class="nb">TabError</span>
      <span class="o">+--</span> <span class="nb">SystemError</span>
      <span class="o">+--</span> <span class="nb">TypeError</span>
      <span class="o">+--</span> <span class="nb">ValueError</span>
      <span class="o">|</span>    <span class="o">+--</span> <span class="nb">UnicodeError</span>
      <span class="o">|</span>         <span class="o">+--</span> <span class="nb">UnicodeDecodeError</span>
      <span class="o">|</span>         <span class="o">+--</span> <span class="nb">UnicodeEncodeError</span>
      <span class="o">|</span>         <span class="o">+--</span> <span class="nb">UnicodeTranslateError</span>
      <span class="o">+--</span> <span class="nb">Warning</span>
           <span class="o">+--</span> <span class="nb">DeprecationWarning</span>
           <span class="o">+--</span> <span class="nb">PendingDeprecationWarning</span>
           <span class="o">+--</span> <span class="nb">RuntimeWarning</span>
           <span class="o">+--</span> <span class="nb">SyntaxWarning</span>
           <span class="o">+--</span> <span class="nb">UserWarning</span>
           <span class="o">+--</span> <span class="nb">FutureWarning</span>
           <span class="o">+--</span> <span class="nb">ImportWarning</span>
           <span class="o">+--</span> <span class="nb">UnicodeWarning</span>
           <span class="o">+--</span> <span class="nb">BytesWarning</span>
           <span class="o">+--</span> <span class="nb">ResourceWarning</span>
</code></pre></div></div> <p>异常处理结构的基本思路是先尝试运行代码，如果没有问题就正常执行，如果发生了错误就尝试着去捕获和处理，最后实在没办法才崩溃。在函数中简易地抛出异常也可以使用 <code class="language-plaintext highlighter-rouge">raise</code> 关键字，其基本语法为 <code class="language-plaintext highlighter-rouge">raise ExceptionType('message')</code>。</p> <h3 id="try---except"><code class="language-plaintext highlighter-rouge">try - except</code></h3> <p>该异常处理结构类似于单分支选择结构，<code class="language-plaintext highlighter-rouge">try</code> 子句中的代码块包含可能会引发异常的语句，<code class="language-plaintext highlighter-rouge">except</code> 子句用于捕获相应的异常。如果 <code class="language-plaintext highlighter-rouge">try</code> 子句中的代码引发异常并被 <code class="language-plaintext highlighter-rouge">except</code> 子句捕获，就执行 <code class="language-plaintext highlighter-rouge">except</code> 子句中的代码块。如果 <code class="language-plaintext highlighter-rouge">try</code> 子句中的代码没有出现异常就继续执行异常处理结构之后的代码。如果出现异常但没有被 <code class="language-plaintext highlighter-rouge">except</code> 捕获，则继续向外层抛出。如果所有层都没有捕获并处理该异常，则程序崩溃。基本语法如下：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span><span class="p">:</span>
	<span class="c1"># 可能会引发异常的代码
</span><span class="k">except</span> <span class="n">ExceptionType</span><span class="p">[</span> <span class="k">as</span> <span class="n">e</span><span class="p">]:</span>
	<span class="c1"># 如果 try 中的代码出现异常并被 except 捕获，执行此处的代码
</span></code></pre></div></div> <p class="mynote"><code class="language-plaintext highlighter-rouge">except</code> 后跟想要捕获的异常类型，常用的为 <code class="language-plaintext highlighter-rouge">Exception</code> 类，当然异常类型越具体越好，具体的类型<a href="#异常处理结构">见上</a>。<code class="language-plaintext highlighter-rouge">e</code> 是被抛出的异常类型的实例，可以访问其属性和方法，以获取更多关于异常的信息。</p> <h3 id="try---except---else"><code class="language-plaintext highlighter-rouge">try - except - else</code></h3> <p>该异常处理结构类似于双分支选择结构，如果 <code class="language-plaintext highlighter-rouge">try</code> 中的代码没有引发异常，则执行 <code class="language-plaintext highlighter-rouge">else</code> 中的代码。如果 <code class="language-plaintext highlighter-rouge">try</code> 中的代码抛出了异常并被 <code class="language-plaintext highlighter-rouge">except</code> 捕获则不会执行 <code class="language-plaintext highlighter-rouge">else</code> 中的代码。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span><span class="p">:</span>
	<span class="c1"># 可能会引发异常的代码
</span><span class="k">except</span> <span class="n">ExceptionType</span><span class="p">[</span> <span class="k">as</span> <span class="n">e</span><span class="p">]:</span>
	<span class="c1"># 如果 try 中的代码出现异常并被 except 捕获，执行此处的代码
</span><span class="k">else</span><span class="p">:</span>
	<span class="c1"># 如果 try 中的代码没有出现异常，就继续执行此处的代码
</span></code></pre></div></div> <p class="mynote"><code class="language-plaintext highlighter-rouge">try</code> 中不应该放太多代码，而是应该放最有可能引发异常的代码。</p> <h3 id="try---except---finally"><code class="language-plaintext highlighter-rouge">try - except - finally</code></h3> <p>在该异常处理结构中，无论 <code class="language-plaintext highlighter-rouge">try</code> 中的代码是否发生异常，也不管抛出的异常是否成功被 <code class="language-plaintext highlighter-rouge">except</code> 捕获，<code class="language-plaintext highlighter-rouge">finally</code> 子句中的代码都会被执行。因此，<code class="language-plaintext highlighter-rouge">finally</code> 中的代码常用来做一些清理或释放资源的工作。当然，也可以结合 <code class="language-plaintext highlighter-rouge">else</code> 子句使用。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span><span class="p">:</span>
	<span class="c1"># 可能会引发异常的代码
</span><span class="k">except</span> <span class="n">ExceptionType</span><span class="p">[</span> <span class="k">as</span> <span class="n">e</span><span class="p">]:</span>
	<span class="c1"># 如果 try 中的代码出现异常并被 except 捕获，执行此处的代码
</span><span class="k">else</span><span class="p">:</span>
	<span class="c1"># 也可以结合 else 子句
</span><span class="k">finally</span><span class="p">:</span>
	<span class="c1"># 无论如何此处的代码都会被执行
</span></code></pre></div></div> <h3 id="可以捕获多种异常的异常处理结构">可以捕获多种异常的异常处理结构</h3> <p>使用多个 <code class="language-plaintext highlighter-rouge">except</code> 子句即可实现捕获多种异常，一旦 <code class="language-plaintext highlighter-rouge">try</code> 子句中的代码抛出异常，就按照顺序依次检查与哪一个 <code class="language-plaintext highlighter-rouge">except</code> 的异常类型匹配，一旦捕获到异常，其他 <code class="language-plaintext highlighter-rouge">except</code> 子句将不会再尝试捕获。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span><span class="p">:</span>
	<span class="c1"># 可能会引发异常的代码
</span><span class="k">except</span> <span class="n">ExceptionType1</span><span class="p">:</span>
	<span class="c1"># 处理异常类型 1 的代码
</span><span class="k">except</span> <span class="n">ExceptionType2</span><span class="p">:</span>
	<span class="c1"># 处理异常类型 2 的代码
</span><span class="k">except</span> <span class="n">ExceptionType3</span><span class="p">:</span>
	<span class="c1"># 处理异常类型 3 的代码
</span></code></pre></div></div> <h2 id="函数">函数</h2> <h3 id="函数定义">函数定义</h3> <p>函数使用 <code class="language-plaintext highlighter-rouge">def</code> 关键字来定义，函数名尽量小写并用下划线 <code class="language-plaintext highlighter-rouge">_</code> 来连接单词。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">函数名</span><span class="p">([</span><span class="n">参数列表</span><span class="p">]):</span>
	<span class="sh">'''</span><span class="s">注释</span><span class="sh">'''</span>
	<span class="n">函数体</span>
</code></pre></div></div> <p>定义函数时，开头部分的注释可以为用户提供提示和使用帮助。使用 <code class="language-plaintext highlighter-rouge">help()</code> 或 <code class="language-plaintext highlighter-rouge">print(函数名.__doc__)</code> 来查看函数的使用帮助，会返回函数开头注释的内容。并且在调用该函数时输入左侧左侧圆括号之后，会立刻显示该函数的使用说明。</p> <p>定义函数时使用 <code class="language-plaintext highlighter-rouge">return</code> 语句结束函数执行的同时返回任意类型的值，函数返回值的类型与 <code class="language-plaintext highlighter-rouge">return</code> 语句返回表达式的类型一致。不论 <code class="language-plaintext highlighter-rouge">return</code> 语句出现在函数的什么位置，一旦得到执行将直接结束函数的执行。如果函数没有 <code class="language-plaintext highlighter-rouge">return</code> 语句、有 <code class="language-plaintext highlighter-rouge">return</code> 语句但是没有执行或者 <code class="language-plaintext highlighter-rouge">return</code> 语句执行了但是没有返回任何值，解释器都会认为该函数以 <code class="language-plaintext highlighter-rouge">return None</code> 结束，即返回空值。</p> <h3 id="装饰器">装饰器</h3> <p>装饰器（decorator）本身也是一个函数，它接受其他函数作为参数并对其进行一定的改造之后返回新函数，如<a href="">类方法</a>、静态方法等。在函数前使用 <code class="language-plaintext highlighter-rouge">@</code> 来执行。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 定义装饰器 before
</span><span class="k">def</span> <span class="nf">before</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
<span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
	<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Before function called.</span><span class="sh">'</span><span class="p">)</span>
	<span class="k">return</span> <span class="nf">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="k">return</span> <span class="n">wrapper</span>

<span class="c1"># 使用 before 装饰器修饰函数
</span><span class="nd">@before</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
	<span class="k">return</span> <span class="mi">3</span>

<span class="c1"># 调用函数
</span><span class="nf">test</span><span class="p">()</span>

<span class="c1"># 运行结果
</span><span class="n">Before</span> <span class="n">function</span> <span class="n">called</span><span class="p">.</span>
<span class="mi">3</span>
</code></pre></div></div> <h3 id="递归函数">递归函数</h3> <p>递归函数是指在函数内部调用自身，并需要存在一种递归结束条件。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 定义一个计算阶乘的递归函数
</span><span class="k">def</span> <span class="nf">factorial</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
	<span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
		<span class="k">return</span> <span class="mi">1</span>  <span class="c1"># 0 的阶乘为 1
</span>	<span class="k">else</span><span class="p">:</span>
		<span class="k">return</span> <span class="n">n</span> <span class="o">*</span> <span class="nf">factorial</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># n 的阶乘为 n 乘 (n-1) 的阶乘
</span></code></pre></div></div> <h3 id="函数参数">函数参数</h3> <p>一般来说，在函数内部直接修改形参的值不会影响实参。但是，如果传递给函数的是列表、字典、集合等可变序列，并且在函数内部使用索引或序列自身支持的方式为可变序列增加、删除元素或修改元素的值时，修改后的结果是可以反映到函数之外的，即不仅形参得到了修改，实参也得到了相应的修改。</p> <p class="mynote">如果一个函数需要以多种形式来接收参数，一般按照把位置参数放在最前面，然后是默认参数，接下来是一个星号的可变参数，最后是两个星号的可变参数的顺序。</p> <h4 id="位置参数">位置参数</h4> <p>位置参数在调用函数时形参和实参的顺序必须严格一致，并且形参和实参的数量必须相同。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">student</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">age</span><span class="p">):</span>
	<span class="nf">return </span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">age</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">(</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span> <span class="mi">22</span><span class="p">)</span>
<span class="p">(</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span> <span class="mi">22</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">()</span>
<span class="nb">TypeError</span><span class="p">:</span> <span class="nf">student</span><span class="p">()</span> <span class="n">missing</span> <span class="mi">3</span> <span class="n">required</span> <span class="n">positional</span> <span class="n">arguments</span><span class="p">:</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">gender</span><span class="sh">'</span><span class="p">,</span> <span class="ow">and</span> <span class="sh">'</span><span class="s">age</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="默认参数">默认参数</h4> <p>默认参数是指在定义函数时可以为形参设置默认值，若为形参设置了默认值，则可以不用必须为其传递实参，此时函数会直接使用函数定义时设置的默认值，当然也可以通过传递实参来替换默认值。需要注意的是，在定义带有默认参数的函数时，<strong>任何一个默认参数的右边都不能再出现没有默认值的普通位置参数</strong>。可以使用 <code class="language-plaintext highlighter-rouge">函数名.__defaults__</code> 来查看函数所有默认参数的当前值，其返回值为一个元组。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">student</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">age</span><span class="p">,</span> <span class="n">s_id</span><span class="o">=</span><span class="sh">'</span><span class="s">1901</span><span class="sh">'</span><span class="p">):</span>
	<span class="nf">return </span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">age</span><span class="p">,</span> <span class="n">s_id</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">student</span><span class="p">.</span><span class="n">__defaults__</span>
<span class="p">(</span><span class="sh">'</span><span class="s">1901</span><span class="sh">'</span><span class="p">,)</span>
</code></pre></div></div> <p>多次调用函数并且不为默认参数传递值时，默认参数只在函数定义时进行一次初始化，后续的调用不会再初始化。这对于像列表等可变类型的默认参数可能会导致逻辑错误。因此，要避免使用列表等可变序列作为函数参数的默认值。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">li</span><span class="o">=</span><span class="p">[]):</span>  <span class="c1"># 默认参数为可变类型
</span>	<span class="n">li</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">li</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">])</span>  <span class="c1"># 为默认参数传递了值，所以每次调用函数都会初始化
</span><span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">)</span>
<span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># 没有为默认参数传递值，所以这一次调用函数时默认参数没有初始化，即返回的列表还是上一次的列表，因此结果不是想要的 ['b']，而是 ['a', 'b']
</span><span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># 对上述 demo() 函数的改进，不使用可变序列作为函数参数的默认值
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">li</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
	<span class="k">if</span> <span class="n">li</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>  <span class="c1"># 如果 li 为 None，则 li 赋值为空列表；如果 li 不为 None，则 item 会添加到现有的列表 li 中
</span>		<span class="n">li</span> <span class="o">=</span> <span class="p">[]</span>
	<span class="n">li</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">li</span>
</code></pre></div></div> <p>此外，若在定义函数时某个参数的默认值为另一个变量的值，那么该参数的默认值只依赖于函数定义时该变量的值，即函数的默认参数是在函数定义时确定值的，所以只会被初始化一次。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">i</span><span class="p">):</span>  <span class="c1"># 默认参数 n 的值取决于变量 i 的当前值
</span>	<span class="k">return</span> <span class="n">n</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">()</span>
<span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">()</span>  <span class="c1"># 函数定义后再改变 i 的值不影响参数 n 的默认值
</span><span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">i</span><span class="p">):</span>  <span class="c1"># 重新定义函数
</span>	<span class="k">return</span> <span class="n">n</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">()</span>
<span class="mi">5</span>
</code></pre></div></div> <h4 id="关键字参数">关键字参数</h4> <p>关键字参数主要指<strong>调用函数时参数的传递方式</strong>，与函数定义无关。通过关键字参数可以按照参数名字来传递值，明确指定哪个值传递给哪个参数，从而可以使实参的顺序与形参的顺序不一致，但不会影响传递结果。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">student</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">age</span><span class="p">,</span> <span class="n">s_id</span><span class="o">=</span><span class="sh">'</span><span class="s">1901</span><span class="sh">'</span><span class="p">):</span>
	<span class="nf">return </span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">age</span><span class="p">,</span> <span class="n">s_id</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="n">gender</span><span class="o">=</span><span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>  <span class="c1"># 按照关键字参数来传递参数的值
</span><span class="p">(</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="sh">'</span><span class="s">1901</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h4 id="可变参数">可变参数</h4> <p>可变参数主要有两种形式：<strong><code class="language-plaintext highlighter-rouge">*args</code></strong> 和 <strong><code class="language-plaintext highlighter-rouge">**kwargs</code></strong>，前者用于接收任意多个位置实参并将其放在元组中，后者用于接收类似于关键字参数的多个实参并将其放入字典中（args 和 kwargs 只是常用名字，可以取其他任意名字替代）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
	<span class="k">return</span> <span class="n">args</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># 接收多个位置参数并放在元组中
</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># 接收多个关键字参数并放在字典中
</span>	<span class="k">return</span> <span class="n">kwargs</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="p">{</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
</code></pre></div></div> <h4 id="传递参数时的序列解包">传递参数时的序列解包</h4> <p>传递参数时的序列解包是针对于<strong>实参</strong>来说。在调用含有多个位置参数的函数时，若实参为列表、元组、字典、集合等可迭代对象时，可以在实参名称前加一个星号 <code class="language-plaintext highlighter-rouge">*</code> 表示序列解包，Python 会自动将序列中的值依次传递给各个形参。若实参为字典，一个星号只能对其的键或值进行解包。若想要将字典的元素转换成类似于关键字参数的形式进行传递，则需要使用两个星号 <code class="language-plaintext highlighter-rouge">**</code> 进行解包。但是，对于这种形式的序列解包，要求<strong>实参字典中的所有键都必须是函数的形参名称</strong>，或者与函数中两个星号的可变参数相对应。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">student</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">age</span><span class="p">):</span>
	<span class="k">return</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s"> is </span><span class="si">{</span><span class="n">age</span><span class="si">}</span><span class="s"> years old, and </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s"> is </span><span class="si">{</span><span class="n">gender</span><span class="si">}</span><span class="s">.</span><span class="sh">'</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">leon</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span> <span class="mi">22</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">(</span><span class="o">*</span><span class="n">leon</span><span class="p">)</span>  <span class="c1"># 对列表进行解包
</span><span class="sh">'</span><span class="s">Leon is 22 years old, and Leon is male.</span><span class="sh">'</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">leon</span> <span class="o">=</span> <span class="p">(</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span> <span class="mi">22</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">(</span><span class="o">*</span><span class="n">leon</span><span class="p">)</span>  <span class="c1"># 对元组进行解包
</span><span class="sh">'</span><span class="s">Leon is 22 years old, and Leon is male.</span><span class="sh">'</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">leon</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">gender</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">:</span> <span class="mi">22</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">(</span><span class="o">*</span><span class="n">leon</span><span class="p">)</span>  <span class="c1"># 一个星号默认对字典的键进行解包
</span><span class="sh">'</span><span class="s">name is age years old, and name is gender.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">(</span><span class="o">*</span><span class="n">leon</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>  <span class="c1"># 对字典的值进行解包
</span><span class="sh">'</span><span class="s">Leon is 22 years old, and Leon is male.</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">student</span><span class="p">(</span><span class="o">**</span><span class="n">leon</span><span class="p">)</span>  <span class="c1"># 对字典的元素进行解包
</span><span class="sh">'</span><span class="s">Leon is 22 years old, and Leon is male.</span><span class="sh">'</span>
</code></pre></div></div> <p class="mywarning">在调用函数时，如果对实参使用一个星号进行序列解包，那么这些解包后的实参将会被当作普通的位置参数来对待，并且会在关键字参数和使用两个星号进行序列解包的参数之前进行处理。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
	<span class="nf">return </span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 正常序列解包
</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 优先处理使用一个星号的序列解包（2 -&gt; a，3 -&gt; b），再处理关键字参数（1 -&gt; a），所以会报错
</span><span class="nb">TypeError</span><span class="p">:</span> <span class="nf">demo</span><span class="p">()</span> <span class="n">got</span> <span class="n">multiple</span> <span class="n">values</span> <span class="k">for</span> <span class="n">argument</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># 正常序列解包
</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <h3 id="变量作用域">变量作用域</h3> <p>变量作用域是指变量起作用的代码范围，不同作用域内的同名变量之间互不影响。在函数内部定义的变量一般为局部变量，在函数外部定义的变量为全局变量。不管是局部变量还是全局变量，在其被定义之前都无法访问。</p> <p>当函数运行结束后，在函数内定义的局部变量将被自动删除而不可访问。在函数内使用 <code class="language-plaintext highlighter-rouge">global</code> 关键字声明的全局变量则仍然存在且可以访问。使用 <code class="language-plaintext highlighter-rouge">global</code> 声明的全局变量分为两种：</p> <ol> <li>一个变量已在函数外定义，如果在函数内需要修改这个变量的值，并将修改的结果反映到函数之外，可以在函数内使用 <code class="language-plaintext highlighter-rouge">global</code> 明确声明要使用的变量。</li> <li>在函数内直接使用 <code class="language-plaintext highlighter-rouge">global</code> 将一个变量声明为全局变量，如果在函数外没有定义该变量，在调用这个函数之后，会创建新的全局变量。</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">demo</span><span class="p">():</span>
	<span class="k">global</span> <span class="n">x</span>  <span class="c1"># 声明全局变量 x
</span>	<span class="n">x</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># 全局变量
</span>	<span class="n">y</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># 局部变量
</span>	<span class="nf">return </span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># 在函数外定义全局变量 x
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">()</span>  <span class="c1"># 调用函数修改了全局变量 x 的值
</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>  <span class="c1"># 局部变量 y 在函数执行之后自动删除
</span><span class="nb">NameError</span><span class="p">:</span> <span class="n">name</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">defined</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">del</span> <span class="n">x</span>  <span class="c1"># 删除全局变量 x
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="nb">NameError</span><span class="p">:</span> <span class="n">name</span> <span class="sh">'</span><span class="s">x</span><span class="sh">'</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">defined</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">demo</span><span class="p">()</span>  <span class="c1"># 此次调用函数创建了全局变量 x
</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="mi">3</span>
</code></pre></div></div> <p class="mynote">如果在某个作用域内有为变量赋值的操作，那么该变量将被认为是该作用域内的局部变量。如果局部变量与全局变量具有相同的名字，那么该局部变量会在自己的作用域内暂时隐藏同名的全局变量。</p> <h3 id="lambda-表达式"><code class="language-plaintext highlighter-rouge">lambda</code> 表达式</h3> <p><code class="language-plaintext highlighter-rouge">lambda</code> 表达式用于声明匿名函数，即没有函数名字且临时使用。它可以包含多个参数，但只能有一个表达式。在表达式中可以调用其他函数，该表达式的计算结果相当于函数的返回值。其基本语法如下：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 基本语法
</span><span class="k">lambda</span> <span class="n">arguments</span><span class="p">:</span> <span class="n">expression</span>

<span class="c1"># 等价于
</span><span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">arguments</span><span class="p">):</span>
	<span class="n">expression</span>

<span class="c1"># 也可以给 lambda 表达式起个名字
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">f</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="mi">12</span>

<span class="c1"># 也支持默认参数
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">g</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">5</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">g</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">g</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 调用时使用关键字参数
</span><span class="mi">6</span>
</code></pre></div></div> <p class="mywarning"><code class="language-plaintext highlighter-rouge">lambda</code> 表达式只能使用局部变量，若变量在外部作用域中定义，直接在表达式中使用时会出现错误，得不到预期的结果。</p> <h3 id="生成器函数">生成器函数</h3> <p>包含 <code class="language-plaintext highlighter-rouge">yield</code> 语句的函数可以用来创建生成器对象，这样的函数也称为生成器函数。<code class="language-plaintext highlighter-rouge">yield</code> 语句类似于 <code class="language-plaintext highlighter-rouge">return</code> 语句，都是用于从函数中返回值。<code class="language-plaintext highlighter-rouge">return</code> 语句一旦执行会立刻结束函数的运行，而 <code class="language-plaintext highlighter-rouge">yield</code> 语句执行后会返回一个值并暂停后续代码的执行，只有通过生成器对象的 <code class="language-plaintext highlighter-rouge">__next__()</code> 方法、内置函数 <code class="language-plaintext highlighter-rouge">next()</code>、<code class="language-plaintext highlighter-rouge">for</code> 循环遍历等方式显式”索要“数据时才能恢复执行。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 定义函数生成斐波那契数列
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">f</span><span class="p">():</span>
	<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
	<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
		<span class="k">yield</span> <span class="n">a</span>  <span class="c1"># 暂停执行，需要时再产生一个新元素
</span>		<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="nf">f</span><span class="p">()</span>  <span class="c1"># 创建生成器对象
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="o">&lt;</span><span class="n">generator</span> <span class="nb">object</span> <span class="n">f</span> <span class="n">at</span> <span class="mh">0x00000293920A5890</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
	<span class="nf">print</span><span class="p">(</span><span class="nf">next</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">)</span>
	
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">5</span> <span class="mi">8</span> <span class="mi">13</span> <span class="mi">21</span> <span class="mi">34</span> <span class="mi">55</span>
</code></pre></div></div> <h2 id="面向对象">面向对象</h2> <p>创建类时用<strong>变量形式</strong>表示对象特征的称为数据成员，用<strong>函数形式</strong>表示对象行为的称为成员方法，数据成员和成员方法统称为类的成员。</p> <p>Python 使用 <code class="language-plaintext highlighter-rouge">class</code> 关键字来定义类，类名的首字母习惯上大写。定义类之后，就可以用来实例化对象，并通过 <code class="language-plaintext highlighter-rouge">对象名.成员</code> 的方式来访问其中的数据成员或成员方法。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Car</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
	<span class="k">def</span> <span class="nf">infor</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
		<span class="k">return</span> <span class="sh">'</span><span class="s">infor</span><span class="sh">'</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">car</span> <span class="o">=</span> <span class="nc">Car</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="nf">infor</span><span class="p">()</span>
<span class="sh">'</span><span class="s">infor</span><span class="sh">'</span>
</code></pre></div></div> <p>可以使用内置函数 <code class="language-plaintext highlighter-rouge">isinstance()</code> 来测试一个对象是否是某个类的实例，或者使用 <code class="language-plaintext highlighter-rouge">type()</code> 查看对象类型。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">car</span><span class="p">,</span> <span class="n">Car</span><span class="p">)</span>
<span class="bp">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">type</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="o">&lt;</span><span class="k">class</span> <span class="err">'</span><span class="nc">__main__</span><span class="p">.</span><span class="n">Car</span><span class="sh">'</span><span class="s">&gt;  # __main__ 表示 Car 类的来源为主程序，即 car 对象是主程序中 Car 类的实例

# 如果是用 from test import Car 导入Car类
</span><span class="gp">&gt;&gt;&gt;</span> <span class="nf">type</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="o">&lt;</span><span class="k">class</span> <span class="err">'</span><span class="nc">test</span><span class="p">.</span><span class="n">Car</span><span class="sh">'</span><span class="s">&gt;
</span></code></pre></div></div> <p class="mynote">关键字 <code class="language-plaintext highlighter-rouge">pass</code> 用于表示空语句，常用于函数或类的定义、选择结构、循环结构和 <code class="language-plaintext highlighter-rouge">with</code> 块中，如果暂时没有确定如何实现某个功能，可以使用 <code class="language-plaintext highlighter-rouge">pass</code> 来占位。</p> <p>类同样使用三引号来进行必要的注释。</p> <h3 id="数据成员与成员方法">数据成员与成员方法</h3> <h4 id="私有成员与公有成员">私有成员与公有成员</h4> <p><strong>私有成员</strong>在类的外部不能直接访问，一般是在类的内部进行访问和操作，或在类的外部通过调用对象的公有成员方法来访问。<strong>公有成员</strong>既可以在类的内部也可以在外部中使用。在定义类的成员时，如果成员名以两个（或更多）下划线开头但是不以两个（或更多）下划线结束表示是私有成员，否则就不是。不过，Python 并没有对私有成员提供严格的访问保护机制，通过 <code class="language-plaintext highlighter-rouge">对象名._类名__私有成员名</code> 也可以在外部访问私有成员，但是不推荐。</p> <ol> <li><code class="language-plaintext highlighter-rouge">_xxx</code> 成员名以一个下划线开头，表示该成员是保护的，只有类对象和子类对象可以访问，应避免直接在外部访问，但 Python 不会阻止这个访问。使用一个或多个下划线开头的成员不能使用 <code class="language-plaintext highlighter-rouge">from module import *</code> 进行导入。</li> <li><code class="language-plaintext highlighter-rouge">__xxx</code> 表示私有成员，一般只有父类的对象自己能访问。</li> <li><code class="language-plaintext highlighter-rouge">__xxx__</code> 表示用于实现某些特殊行为的特殊成员方法，详见<a href="#特殊方法">特殊方法</a>。</li> </ol> <h4 id="数据成员">数据成员</h4> <p>数据成员可以分为<strong>属于类</strong>的数据成员和<strong>属于对象（实例）</strong>的数据成员。属于类的数据成员是该类中所有对象共享的，不属于任何一个对象，在定义属于类的数据成员时一般不在任何一个成员方法中定义。属于对象的数据成员一般在构造方法 <code class="language-plaintext highlighter-rouge">__init__()</code> 中定义，同一个类的不同对象的数据成员之间互不影响。在主程序中或类的外部，类的数据成员属于类，可以通过类名或对象名进行访问；对象的数据成员属于实例（对象），只能通过对象名进行访问。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Student</span><span class="p">:</span>
	<span class="n">address</span> <span class="o">=</span> <span class="sh">'</span><span class="s">ECUST</span><span class="sh">'</span>  <span class="c1"># 类的数据成员
</span>	
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>  <span class="c1"># 对象的数据成员
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="nc">Student</span><span class="p">(</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="n">address</span>  <span class="c1"># 类的数据成员通过对象名访问
</span><span class="sh">'</span><span class="s">ECUST</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">.</span><span class="n">name</span>  <span class="c1"># 对象的数据成员通过对象名访问
</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Student</span><span class="p">.</span><span class="n">address</span>  <span class="c1"># 类的数据成员通过类名访问
</span><span class="sh">'</span><span class="s">ECUST</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Student</span><span class="p">.</span><span class="n">name</span>  <span class="c1"># 对象的数据成员无法通过类名访问
</span><span class="nb">AttributeError</span><span class="p">:</span> <span class="nb">type</span> <span class="nb">object</span> <span class="sh">'</span><span class="s">Student</span><span class="sh">'</span> <span class="n">has</span> <span class="n">no</span> <span class="n">attribute</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span>
</code></pre></div></div> <h4 id="成员方法">成员方法</h4> <p>在面向对象中，方法一般指与特定对象（实例）绑定的函数，通过对象调用方法时，对象本身将被作为第一个参数（即 <code class="language-plaintext highlighter-rouge">self</code>）自动传递过去。Python 类的成员方法可分为公有方法、私有方法、类方法、静态方法和抽象方法等。公有方法、私有方法和抽象方法属于对象的<strong>实例方法</strong>，实例方法的第一个形参总是 <code class="language-plaintext highlighter-rouge">self</code> 以代表当前对象（实例）。在实例方法中访问实例成员时需要以 <code class="language-plaintext highlighter-rouge">self</code> 为前缀，但在外部通过对象名调用方法时不需要传递这个参数。</p> <p>类方法和静态方法都可以通过类名和对象名调用，但不能直接访问属于对象的成员，只能访问属于类的成员。并且这两种方法不属于任何实例，不会绑定的任何实例，也不依赖于任何实例的状态。类方法一般以 <code class="language-plaintext highlighter-rouge">cls</code> 作为第一个参数，表示该类本身。静态方法可以不接受任何参数（不需要用于代表类的实例的参数 <code class="language-plaintext highlighter-rouge">self</code> 和用于代表类的参数 <code class="language-plaintext highlighter-rouge">cls</code>）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Student</span><span class="p">:</span>
	<span class="n">address</span> <span class="o">=</span> <span class="sh">'</span><span class="s">ECUST</span><span class="sh">'</span>

	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Leon</span><span class="sh">'</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">22</span><span class="p">):</span>  <span class="c1"># __init__() 是私有方法，当然也属于特殊方法
</span>		<span class="n">self</span><span class="p">.</span><span class="n">s_id</span> <span class="o">=</span> <span class="bp">None</span>  <span class="c1"># 这里在 self 后的 s_id、name 和 __age 是数据成员，前两者是公有成员可以外部访问，后者是私有成员  
</span>		<span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
		<span class="n">self</span><span class="p">.</span><span class="n">__age</span> <span class="o">=</span> <span class="n">age</span>

	<span class="k">def</span> <span class="nf">set_id</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s_id</span><span class="p">):</span>  <span class="c1"># set_id() 是公有方法
</span>		<span class="n">self</span><span class="p">.</span><span class="n">s_id</span> <span class="o">=</span> <span class="n">s_id</span>
		<span class="k">return</span> <span class="n">s_id</span>

	<span class="k">def</span> <span class="nf">show_age</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
		<span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">__age</span>  <span class="c1"># 在实例方法中可以访问私有成员
</span>		
	<span class="nd">@classmethod</span>  <span class="c1"># 使用装饰器声明类方法
</span>	<span class="k">def</span> <span class="nf">class_show_address</span><span class="p">(</span><span class="n">cls</span><span class="p">):</span>
		<span class="k">return</span> <span class="n">cls</span><span class="p">.</span><span class="n">address</span>  <span class="c1"># 只能访问类的成员
</span>		
	<span class="nd">@staticmethod</span>  <span class="c1"># 使用装饰器声明静态方法
</span>	<span class="k">def</span> <span class="nf">static_show_address</span><span class="p">():</span>  <span class="c1"># 可以没有参数
</span>		<span class="k">return</span> <span class="n">Student</span><span class="p">.</span><span class="n">address</span>
</code></pre></div></div> <p class="mynote">如果方法不需要访问或修改任何状态（不依赖于当前类的实例或类本身），声明为静态方法更合适；如果需要访问或修改类的状态，声明为类方法更合适；如果需要访问或修改实例的状态，则声明为实例方法更合适。</p> <p>抽象方法一般在抽象类中定义，其在父类中声明但不实现，需要在继承的子类中实现，否则子类无法创建实例。可以通过 <code class="language-plaintext highlighter-rouge">abc</code> 模块来创建抽象类，抽象类不能用于创建实例，主要是作为其他类的父类而存在。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>

<span class="k">class</span> <span class="nc">Foo</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>  <span class="c1"># or ABC，定义抽象类
</span>	<span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>  <span class="c1"># 普通实例方法
</span>		<span class="k">pass</span>
		
	<span class="nd">@abstractmethod</span>  <span class="c1"># 抽象方法
</span>	<span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
		<span class="k">raise</span> <span class="nc">Exception</span><span class="p">(</span><span class="sh">'</span><span class="s">You must reimplement this method.</span><span class="sh">'</span><span class="p">)</span>
	
<span class="k">class</span> <span class="nc">Bar</span><span class="p">(</span><span class="n">Foo</span><span class="p">):</span>
	<span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>  <span class="c1"># 必须在子类中重新实现父类中的抽象方法
</span>		<span class="k">pass</span>
</code></pre></div></div> <h4 id="属性">属性</h4> <p>公开的数据成员可以在外部被随意的访问和修改，很难保证新数据的合法性，所以数据很容易被破坏，一般的解决方案为定义数据成员为私有，然后设计公开的成员方法来提供对私有成员进行访问和修改的操作。<strong>属性</strong>是一种特殊形式的成员方法，既可以像成员方法一样对值进行必要的检查，又可以<strong>像数据成员一样灵活地访问</strong>。通过使用装饰器 <code class="language-plaintext highlighter-rouge">@property</code> 可以创建只读属性。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Test</span><span class="p">:</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">__value</span> <span class="o">=</span> <span class="n">value</span>  <span class="c1"># 私有数据成员
</span>
	<span class="nd">@property</span>  <span class="c1"># 定义只读属性
</span>	<span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
		<span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">__value</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="nc">Test</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span>  <span class="c1"># value 被定义为属性后，访问的形式从成员方法（t.value()）变为数据成员（t.value）
</span><span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># 只读属性不允许修改值
</span><span class="nb">AttributeError</span><span class="p">:</span> <span class="n">can</span><span class="sh">'</span><span class="s">t set attribute
</span><span class="gp">&gt;&gt;&gt;</span> <span class="k">del</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span>  <span class="c1"># 也不允许删除属性
</span><span class="nb">AttributeError</span><span class="p">:</span> <span class="n">can</span><span class="sh">'</span><span class="s">t delete attribute
</span></code></pre></div></div> <p>通过 <code class="language-plaintext highlighter-rouge">@property</code> 的配套装饰器 <code class="language-plaintext highlighter-rouge">@&lt;attribute&gt;.setter</code> 和 <code class="language-plaintext highlighter-rouge">@&lt;attribute&gt;.deleter</code> 可以修改和删除属性（<code class="language-plaintext highlighter-rouge">&lt;attribute&gt;</code> 是指所定义的属性的名称，即成员方法的名称）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 修改上面的类
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Test</span><span class="p">:</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">__value</span> <span class="o">=</span> <span class="n">value</span>  <span class="c1"># 私有数据成员
</span>
	<span class="nd">@property</span>  <span class="c1"># 定义只读属性
</span>	<span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
		<span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">__value</span>

	<span class="nd">@value.setter</span>  <span class="c1"># 定义 value 属性的 setter 方法
</span>	<span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">__value</span> <span class="o">=</span> <span class="n">value</span>

	<span class="nd">@value.deleter</span>  <span class="c1"># 定义 value 属性的 deleter 方法
</span>	<span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
		<span class="k">del</span> <span class="n">self</span><span class="p">.</span><span class="n">__value</span>
		
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="nc">Test</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span>
<span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># 调用 setter 修改属性的值
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span>
<span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">del</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span>  <span class="c1"># 调用 deleter 删除属性
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span>  <span class="c1"># 属性已删除，访问失败
</span><span class="nb">AttributeError</span><span class="p">:</span> <span class="sh">'</span><span class="s">Test</span><span class="sh">'</span> <span class="nb">object</span> <span class="n">has</span> <span class="n">no</span> <span class="n">attribute</span> <span class="sh">'</span><span class="s">_Test__value</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># 动态增加属性
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">.</span><span class="n">value</span>
<span class="mi">1</span>
</code></pre></div></div> <h4 id="类与对象的动态性">类与对象的动态性</h4> <p>在 Python 中可以动态地为自定义类和对象增加数据成员和成员方法。在为类和对象增加成员方法时，需使用 <code class="language-plaintext highlighter-rouge">types.MethodType(func, class_name/instance_name)</code> 将函数绑定到类或对象上，这样函数才能正确地接收 <code class="language-plaintext highlighter-rouge">self</code> 参数。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Car</span><span class="p">:</span>
	<span class="n">price</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># 属于类的数据成员
</span>	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">color</span> <span class="o">=</span> <span class="n">c</span>  <span class="c1"># 属于对象的数据成员
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">car</span> <span class="o">=</span> <span class="nc">Car</span><span class="p">(</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Car</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Benz</span><span class="sh">'</span>  <span class="c1"># 动态增加类的数据成员
</span><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">Car</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="n">car</span><span class="p">.</span><span class="n">name</span><span class="p">)</span>
<span class="n">Benz</span> <span class="n">Benz</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="n">speed</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># 动态增加对象的数据成员
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="n">speed</span>
<span class="mi">50</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">set_length</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
	<span class="n">self</span><span class="p">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">l</span>

<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">types</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="n">set_length</span> <span class="o">=</span> <span class="n">types</span><span class="p">.</span><span class="nc">MethodType</span><span class="p">(</span><span class="n">set_length</span><span class="p">,</span> <span class="n">car</span><span class="p">)</span>  <span class="c1"># 动态增加对象的成员方法
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="nf">set_length</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="n">length</span>
<span class="mi">150</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">set_width</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
	<span class="n">self</span><span class="p">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">w</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">Car</span><span class="p">.</span><span class="n">set_width</span> <span class="o">=</span> <span class="n">types</span><span class="p">.</span><span class="nc">MethodType</span><span class="p">(</span><span class="n">set_width</span><span class="p">,</span> <span class="n">Car</span><span class="p">)</span>  <span class="c1"># 动态增加类的成员方法
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="nf">set_width</span><span class="p">(</span><span class="mi">80</span><span class="p">)</span>  <span class="c1"># 对象调用类的新增加的方法
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">car</span><span class="p">.</span><span class="n">width</span>
<span class="mi">20</span>
</code></pre></div></div> <p>可以通过内置函数 <code class="language-plaintext highlighter-rouge">dir()</code> 来查看一个对象的所有属性（即数据成员）和方法，会返回一个列表，其中包含了属性和方法的名称，也包含了一些以双下划线开头和结尾的特殊方法。若只想查看一个对象的自定义属性，可以使用内置函数 <code class="language-plaintext highlighter-rouge">vars()</code>，会返回一个字典，其中包含了属性的名称和对应的值，不过它只能返回对象的实例属性，不能返回对象的类属性。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">dir</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>  <span class="c1"># 会返回定义的类属性 price 和动态增加的类属性 name 和 width，以及动态增加的类方法 set_width
</span><span class="p">[</span><span class="sh">'</span><span class="s">__class__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__delattr__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__dict__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__dir__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__doc__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__eq__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__format__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__ge__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__getattribute__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__gt__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__hash__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__init__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__init_subclass__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__le__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__lt__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__module__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__ne__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__new__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__reduce__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__reduce_ex__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__repr__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__setattr__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__sizeof__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__str__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__subclasshook__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">__weakref__</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">color</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">length</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">set_speed</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">set_width</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">speed</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">width</span><span class="sh">'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">vars</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>  <span class="c1"># 只返回对象的实例属性
</span><span class="p">{</span><span class="sh">'</span><span class="s">color</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">length</span><span class="sh">'</span><span class="p">:</span> <span class="mi">150</span><span class="p">,</span> <span class="sh">'</span><span class="s">set_speed</span><span class="sh">'</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">bound</span> <span class="n">method</span> <span class="n">set_speed</span> <span class="n">of</span> <span class="o">&lt;</span><span class="n">__main__</span><span class="p">.</span><span class="n">Car</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x00000293925A31C0</span><span class="o">&gt;&gt;</span><span class="p">,</span> <span class="sh">'</span><span class="s">speed</span><span class="sh">'</span><span class="p">:</span> <span class="mi">50</span><span class="p">}</span>
</code></pre></div></div> <h3 id="继承与多态">继承与多态</h3> <h4 id="继承">继承</h4> <p>子类可以继承父类的公有成员，但不能继承其私有成员。如果需要在子类中调用父类的方法，可以使用内置函数 <code class="language-plaintext highlighter-rouge">super().method(arguments)</code>。<code class="language-plaintext highlighter-rouge">super(__class__, &lt;first argument&gt;)</code> 具有两个参数，第一个参数通常是子类名，第二个参数通常是子类的一个实例。如果不提供任何参数，等价于 <code class="language-plaintext highlighter-rouge">super(当前类, 当前实例对象（self）)</code>。Python 也支持多继承，即一个子类可以继承多个父类。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Person</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">''</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">__name</span> <span class="o">=</span> <span class="bp">None</span>
		<span class="n">self</span><span class="p">.</span><span class="nf">set_name</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

	<span class="k">def</span> <span class="nf">set_name</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
			<span class="k">raise</span> <span class="nc">TypeError</span><span class="p">(</span><span class="sh">'</span><span class="s">name must be a string.</span><span class="sh">'</span><span class="p">)</span>
		<span class="n">self</span><span class="p">.</span><span class="n">__name</span> <span class="o">=</span> <span class="n">name</span>

<span class="k">class</span> <span class="nc">Teacher</span><span class="p">(</span><span class="n">Person</span><span class="p">):</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">22</span><span class="p">):</span>
		<span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>  <span class="c1"># 调用父类的构造方法 __init__()，也可以用super(Teacher, self).__init__(name)
</span>		<span class="n">self</span><span class="p">.</span><span class="n">__age</span> <span class="o">=</span> <span class="bp">None</span>
		<span class="n">self</span><span class="p">.</span><span class="nf">set_age</span><span class="p">(</span><span class="n">age</span><span class="p">)</span>

	<span class="k">def</span> <span class="nf">set_age</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">age</span><span class="p">):</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">age</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
			<span class="k">raise</span> <span class="nc">TypeError</span><span class="p">(</span><span class="sh">'</span><span class="s">age must be an integer.</span><span class="sh">'</span><span class="p">)</span>
		<span class="n">self</span><span class="p">.</span><span class="n">__age</span> <span class="o">=</span> <span class="n">age</span>
</code></pre></div></div> <h4 id="多态">多态</h4> <p>多态是指父类的同一个方法在不同子类的对象中具有不同的表现和行为。</p> <h3 id="特殊方法">特殊方法</h3> <p>Python 中最常用的特殊方法是构造方法 <code class="language-plaintext highlighter-rouge">__init__()</code>，用于初始化工作，在实例化对象时被自动调用和执行。如果没有设计构造方法，Python 会提供一个默认的构造方法用于必要的初始化。自定义的特殊方法可覆盖对应的运算符或内置函数的功能。如在自定义类时重写了 <code class="language-plaintext highlighter-rouge">__add__()</code> 方法，那么在对当前对象使用加号 <code class="language-plaintext highlighter-rouge">+</code> 时，Python 会自动调用 <code class="language-plaintext highlighter-rouge">__add__()</code> 方法所定义的功能，而不是原来 <code class="language-plaintext highlighter-rouge">+</code> 的功能。更多特殊方法详见 <a href="https://docs.python.org/3/reference/datamodel.html#special-method-names">https://docs.python.org/3/reference/datamodel.html#special-method-names</a>。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">Test</span><span class="p">:</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
		<span class="n">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>

	<span class="k">def</span> <span class="nf">__add__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
		<span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Test</span><span class="p">):</span>  <span class="c1"># 如果 other 也属于 Test 类
</span>			<span class="k">return</span> <span class="nc">Test</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">value</span> <span class="o">-</span> <span class="n">other</span><span class="p">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># 重写加号 + 定义的方法
</span>		<span class="k">else</span><span class="p">:</span>
			<span class="k">return</span> <span class="nc">Test</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">value</span> <span class="o">-</span> <span class="n">other</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="nc">Test</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">2</span>  <span class="c1"># 实际运算为 3 - 2
</span><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">value</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">value</span><span class="p">)</span>
<span class="mi">3</span> <span class="mi">1</span>
</code></pre></div></div> <h2 id="文件操作">文件操作</h2> <p>按照数据的组织形式，可以把文件分为<strong>文本文件</strong>和<strong>二进制文件</strong>两大类。文本文件存储的是常规字符串，通常每行以换行符 <code class="language-plaintext highlighter-rouge">\n</code> 结尾。扩展名为 txt、log、ini 的文本都属于文本文件。二进制文件把信息以字节串的形式进行存储。</p> <h3 id="open"><code class="language-plaintext highlighter-rouge">open()</code></h3> <p>内置函数 <code class="language-plaintext highlighter-rouge">open()</code> 可以用指定模式打开指定文件并创建文件对象，其语法为 <code class="language-plaintext highlighter-rouge">open(file, mode='r', buffering=None, encoding=None, errors=None, newline=None, closefd=True)</code>。</p> <ul> <li> <p>参数 <code class="language-plaintext highlighter-rouge">file</code> 用于指定要打开或创建的文件的名称，如果文件不在当前目录，可以使用相对路径（同级目录：<code class="language-plaintext highlighter-rouge">./</code>；上级目录：<code class="language-plaintext highlighter-rouge">../</code>；上两级目录：<code class="language-plaintext highlighter-rouge">../../</code>）或绝对路径（示例：<code class="language-plaintext highlighter-rouge">r'C:\Users\Username\Documents\file.txt'</code>）。</p> </li> <li> <p>参数 <code class="language-plaintext highlighter-rouge">mode</code> 用于指定打开文件后的处理方式。</p> </li> </ul> <table> <thead> <tr> <th style="text-align: left">模式</th> <th style="text-align: left">说明</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">'r'</code></td> <td style="text-align: left">只读模式（默认模式），如果文件不存在会抛出异常</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">'w'</code></td> <td style="text-align: left">写模式，如果文件已存在，自动清空原有内容</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">'x'</code></td> <td style="text-align: left">写模式，创建新文件，如果文件已存在会抛出异常</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">'a'</code></td> <td style="text-align: left">追加模式，从文件末尾追加新内容，不会覆盖文件中原有内容</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">'b'</code></td> <td style="text-align: left">二进制模式，<strong>一般搭配其他模式组合使用</strong>，如 <code class="language-plaintext highlighter-rouge">'rb'</code>、<code class="language-plaintext highlighter-rouge">'wb'</code>等，不允许指定 <code class="language-plaintext highlighter-rouge">encoding</code> 参数</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">'t'</code></td> <td style="text-align: left">文本模式（默认模式，可省略）</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">'+'</code></td> <td style="text-align: left">同时读写模式，<strong>一般搭配其他模式组合使用</strong>，如 <code class="language-plaintext highlighter-rouge">'r+'</code>、<code class="language-plaintext highlighter-rouge">'rb+'</code>等</td> </tr> </tbody> </table> <p><code class="language-plaintext highlighter-rouge">'r+'</code> 模式光标在开头，不会创建新文件，也不会覆盖文件原有内容，用于想要读取内容时也可以添加新内容；<code class="language-plaintext highlighter-rouge">'w+'</code> 和 <code class="language-plaintext highlighter-rouge">'a+'</code> 模式光标在末尾，文件不存在会创建新文件，不同处在于前者会覆盖文件原有内容，而后者不会。</p> <ul> <li>参数 <code class="language-plaintext highlighter-rouge">encoding</code> 用于指定文件的字符编码方式，默认为 <code class="language-plaintext highlighter-rouge">utf-8</code>。</li> </ul> <h3 id="文件对象的属性与方法">文件对象的属性与方法</h3> <p><code class="language-plaintext highlighter-rouge">open()</code> 会返回一个可迭代的文件对象，通过该文件对象可以对文件进行读写操作。</p> <table> <thead> <tr> <th style="text-align: left">常用属性</th> <th style="text-align: left">说明</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">closed</code></td> <td style="text-align: left">判断文件是否关闭，若文件已关闭则返回 True</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">mode</code></td> <td style="text-align: left">返回文件的打开模式</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">name</code></td> <td style="text-align: left">返回文件的名称</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">buffer</code></td> <td style="text-align: left">返回当前文件的缓冲区对象</td> </tr> </tbody> </table> <p>文件读写操作相关的方法都会自动改变文件光标的位置。例如，读取一个文件的 10 个字符后，再次读取字符的时候会从第 11 个字符的位置开始。</p> <table> <thead> <tr> <th style="text-align: left">常用方法</th> <th style="text-align: left">说明</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">close()</code></td> <td style="text-align: left">把缓冲区的内容写入文件，同时关闭文件，并释放文件对象</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">flush()</code></td> <td style="text-align: left">把缓冲区的内容写入文件，但不关闭文件</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">read([size])</code></td> <td style="text-align: left">从文本文件中读取 <code class="language-plaintext highlighter-rouge">size</code> 个字符的内容作为结果返回，或从二进制文件中读取字节并返回。若省略 <code class="language-plaintext highlighter-rouge">size</code> 则表示读取所有内容，若 <code class="language-plaintext highlighter-rouge">size</code> 大于实际有效内容长度则在文件尾自动结束</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">readline()</code></td> <td style="text-align: left">读取一行内容作为结果返回</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">readlines()</code></td> <td style="text-align: left">把文本文件中的每行文本作为一个字符串存入列表中并返回，大文件不建议使用</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">seek(offset[, whence])</code></td> <td style="text-align: left">把文件光标移动到新位置，<code class="language-plaintext highlighter-rouge">offset</code> 表示相对于 <code class="language-plaintext highlighter-rouge">whence</code> 的位置，即光标要移动的字符数（正数表示向文件尾方向移动，负数则相反）。<code class="language-plaintext highlighter-rouge">whence</code> 为 0 表示从文件头开始计算，<code class="language-plaintext highlighter-rouge">whence</code> 为 1 表示从当前位置开始计算，<code class="language-plaintext highlighter-rouge">whence</code> 为 2 表示从文件尾开始计算，默认为 0</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">seekable()</code></td> <td style="text-align: left">测试当前文件是否支持随机访问，若不支持则无法调用 <code class="language-plaintext highlighter-rouge">seek()</code> 和 <code class="language-plaintext highlighter-rouge">tell()</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">tell()</code></td> <td style="text-align: left">返回文件光标当前的位置</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">write(s)</code></td> <td style="text-align: left">把字符串 <code class="language-plaintext highlighter-rouge">s</code> 的内容写入文件中，若要换行，则需在字符串中添加换行符 <code class="language-plaintext highlighter-rouge">xxx\n</code></td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">writelines(s)</code></td> <td style="text-align: left">把字符串列表写入文件中</td> </tr> </tbody> </table> <p><code class="language-plaintext highlighter-rouge">seek(0)</code> 将光标移到文件头，<code class="language-plaintext highlighter-rouge">seek(0, 2)</code> 将光标移到文件尾。此外，<code class="language-plaintext highlighter-rouge">seek()</code> 后再 <code class="language-plaintext highlighter-rouge">read()</code> 可能得不到期望的结果，是因为缓存的原因。</p> <h3 id="上下文管理语句-with">上下文管理语句 <code class="language-plaintext highlighter-rouge">with</code></h3> <p>关键字 <code class="language-plaintext highlighter-rouge">with</code> 可以自动管理资源，不论因为什么原因跳出 <code class="language-plaintext highlighter-rouge">with</code> 块，总能保证文件被正确关闭，不需要再用 <code class="language-plaintext highlighter-rouge">close()</code> 方法来关闭文件。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
	<span class="c1"># 通过文件对象 f 进行文件的读写
</span></code></pre></div></div> <h3 id="json-格式文本文件的读写">JSON 格式文本文件的读写</h3> <p>JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，一般用于提升网络传输速率。Python 的标准库 <code class="language-plaintext highlighter-rouge">json</code> 提供对 JSON 的支持。通过 <code class="language-plaintext highlighter-rouge">json.dumps()</code> 和 <code class="language-plaintext highlighter-rouge">json.loads()</code> 将 Python 对象转换成 JSON 格式的字符串。通过 <code class="language-plaintext highlighter-rouge">json.dump()</code> 和 <code class="language-plaintext highlighter-rouge">json.load()</code> 将 Python 对象转换成 JSON 格式的字符串并写入到文件中或从文件中读取 JSON 格式的字符串。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="n">json</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 对列表进行 JSON 格式的编码
</span><span class="sh">'</span><span class="s">[1, 2, 3]</span><span class="sh">'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">json</span><span class="p">.</span><span class="nf">loads</span><span class="p">(</span><span class="n">_</span><span class="p">)</span>  <span class="c1"># 解码，单个下划线 _ 在交互式环境中表示上一次操作的结果
</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">test.txt</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
	<span class="n">json</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>  <span class="c1"># 写入文件
</span><span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">test.txt</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
	<span class="nf">print</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>  <span class="c1"># 从文件中读取
</span></code></pre></div></div> <h3 id="二进制文件的读写">二进制文件的读写</h3> <p><code class="language-plaintext highlighter-rouge">pass</code></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:book" role="doc-endnote"> <p>本教程参考书目：Python 程序设计基础（第 2 版） - 清华大学出版社 - 董付国 编著。 <a href="#fnref:book" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:args" role="doc-endnote"> <p><code class="language-plaintext highlighter-rouge">[, start[, end]]</code> 方括号中的参数表示该参数是可选的，而非必需的。其中 <code class="language-plaintext highlighter-rouge">end</code> 参数在 <code class="language-plaintext highlighter-rouge">start</code> 参数的方括号中，表示只有提供了 <code class="language-plaintext highlighter-rouge">start</code> 参数才能提供 <code class="language-plaintext highlighter-rouge">end</code> 参数。 <a href="#fnref:args" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="Python"/><summary type="html"><![CDATA[Python Tutorial]]></summary></entry></feed>